{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reconnaissance de chiffre en language des signes avec pytorch\n",
    "\n",
    "Dans cette exemple d'utilisation de deep learning, nous allons utiliser une base de donnée de 2061 images de mains faisant un chiffre en language des signes. Ces images sont en nuances de gris et dans une de plage de 0 à 1.\n",
    "Nous disposons également des vérités terrains associés à chaque image sous forme d'un tableau de taille 10 avec un 1 à l'index de la classe correspondante.\n",
    "\n",
    "Pour effectuer l'apprentissage nous allons utiliser pytorch.\n",
    "\n",
    "## Chargement des images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Seed:  1042\n"
     ]
    }
   ],
   "source": [
    "#Import des modules pythons nécessaires\n",
    "import random\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.utils.data\n",
    "import torchvision.datasets as dset\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn.functional as F\n",
    "import torchvision.utils as vutils\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import torch.utils.data as utils\n",
    "from random import shuffle\n",
    "import matplotlib.pyplot as plt\n",
    "#Affichage de la graine d'aléatoire actuelle (afin de reproduire des résultats si nécessaire)\n",
    "manualSeed = random.randint(1, 10000)\n",
    "print(\"Random Seed: \", manualSeed)\n",
    "random.seed(manualSeed)\n",
    "torch.manual_seed(manualSeed)\n",
    "#Chargement de cuda\n",
    "device = torch.device(\"cuda:0\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Avant d'aller plus en profondeur avec des réseaux de neurone il faut tout d'abord charger les données.\n",
    "Pour cela nous chargons directement les images via numpy et pour et les vérités terrains nous avons décider de ramener le tableau à 1 unique valeur représentant l'axe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<PIL.Image.Image image mode=L size=32x32 at 0x7FD93BA115C0>\n",
      "Classes :  0.0\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Chargement des images\n",
    "#L'image est d'abord redimmensionnée\n",
    "#Puis noramlisé entre -0.5 et 0.5\n",
    "Trans = transforms.Compose([\n",
    "            transforms.Resize(32),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize((0.5,), (0.5,)),\n",
    "        ])\n",
    "images = [Trans(Image.fromarray(im)) for im in np.load(\"./datas/X.npy\")]\n",
    "#Chargement des classes\n",
    "temp = np.load(\"./datas/Y.npy\")\n",
    "classes = np.zeros(len(images))\n",
    "for i in range(len(classes)):\n",
    "    classes[i] = temp[i].nonzero()[0][0]\n",
    "plt.imshow(transforms.ToPILImage()(images[0]))\n",
    "print(transforms.ToPILImage()(images[0]))\n",
    "print(\"Classes : \",classes[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour avoir des datasets cohérents il faut aussi mélanger les données de bases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Mélange du dataset\n",
    "temp_s = []\n",
    "for i in range(len(classes)):\n",
    "    temp_s.append([images[i],classes[i] ])\n",
    "shuffle(temp_s)\n",
    "for i in range(len(classes)):\n",
    "    [im,c] = temp_s[i]\n",
    "    images[i] = im\n",
    "    classes[i] = c"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Maintenant que nous avons nore dataset il faut le partitionner pour avoir un ensemble pour l'entraînement\n",
    "et un pour les tests (afin de vérifier que notre réseau n'apprend pas par coeur)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Définition des partitions du dataset\n",
    "#Nous choisissons de prendre un dataset d'entrainement représentant 80% des données\n",
    "prc_train = int(0.80*len(images))\n",
    "prc_test = prc_train + int(0.2*len(images))\n",
    "#Chargement des partitions\n",
    "def load():\n",
    "    out = []\n",
    "    prc = [prc_train,prc_test]\n",
    "    for i in range(len(prc)):\n",
    "        if i == 0:\n",
    "            images_train = [(im) for im in images[:prc[i]]]\n",
    "            classes_train = classes[:prc_train]\n",
    "        #elif i == len(prc)-1:\n",
    "        #    images_train = [(im) for im in images[prc[i]:]]\n",
    "        #    classes_train = classes[prc[i]:]\n",
    "        else:\n",
    "            images_train = [(im) for im  in images[prc[i-1]:prc[i]]]\n",
    "            classes_train = classes[prc_train:prc_test]\n",
    "        tensor_x_train = torch.stack([torch.Tensor(i) for i in images_train])\n",
    "        tensor_y_train = torch.from_numpy(classes_train).long()\n",
    "        datas_train = utils.TensorDataset(tensor_x_train,tensor_y_train)\n",
    "        dataloader_train = utils.DataLoader(datas_train,50, shuffle=True)\n",
    "        out.append(dataloader_train)\n",
    "    return out\n",
    "[dataloader_train,dataloader_test] = load()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ensuite il faut définir les fonctions d'entraînements et de test associé pour entraîner nos réseaux"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, dataloader_train, optimizer, epoch, criterion):\n",
    "    model.train()\n",
    "    sum_loss = 0\n",
    "    for i, (data,target) in enumerate(dataloader_train, 0):\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        #print(target)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = criterion(output, target)\n",
    "        #print(output)\n",
    "        loss.backward()\n",
    "        sum_loss += loss.item()\n",
    "        optimizer.step()\n",
    "        if i % 10 == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch, i * len(data), len(dataloader_train.dataset),\n",
    "                100. * i / len(dataloader_train), loss.item()))\n",
    "        return loss.item()\n",
    "def test(model, test_loader):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for i, (data,target) in enumerate(test_loader, 0):\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "            test_loss += F.nll_loss(output, target, reduction='sum').item() # sum up batch loss\n",
    "            pred = output.argmax(dim=1, keepdim=True) # get the index of the max log-probability\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "        test_loss, correct, len(test_loader.dataset),\n",
    "            100. * correct / len(test_loader.dataset)))\n",
    "    return test_loss, 100. * correct / len(test_loader.dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Réseau full connected\n",
    "\n",
    "Maintenant nous pouvons passer à la définition de notre réseau, nous allons tout d'abord commencer avec un perceptron multicouche."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net_FC(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net_FC, self).__init__()\n",
    "        self.fc1 = nn.Linear(32*32,200)\n",
    "        self.fc2 = nn.Linear(200, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(-1,32*32)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        return F.log_softmax(x, dim=1)\n",
    "criterion = nn.NLLLoss()\n",
    "model = Net_FC().to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.003)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Il est maintenant temps de lancer notre premier apprentissage et voir les résultats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 0 [0/1649 (0%)]\tLoss: 2.303326\n",
      "\n",
      "Test set: Average loss: 2.3267, Accuracy: 57/412 (14%)\n",
      "\n",
      "Train Epoch: 1 [0/1649 (0%)]\tLoss: 2.253472\n",
      "\n",
      "Test set: Average loss: 2.3496, Accuracy: 45/412 (11%)\n",
      "\n",
      "Train Epoch: 2 [0/1649 (0%)]\tLoss: 2.280328\n",
      "\n",
      "Test set: Average loss: 2.2265, Accuracy: 89/412 (22%)\n",
      "\n",
      "Train Epoch: 3 [0/1649 (0%)]\tLoss: 2.224065\n",
      "\n",
      "Test set: Average loss: 2.1955, Accuracy: 87/412 (21%)\n",
      "\n",
      "Train Epoch: 4 [0/1649 (0%)]\tLoss: 2.215297\n",
      "\n",
      "Test set: Average loss: 2.2254, Accuracy: 64/412 (16%)\n",
      "\n",
      "Train Epoch: 5 [0/1649 (0%)]\tLoss: 2.294441\n",
      "\n",
      "Test set: Average loss: 2.1721, Accuracy: 89/412 (22%)\n",
      "\n",
      "Train Epoch: 6 [0/1649 (0%)]\tLoss: 2.155055\n",
      "\n",
      "Test set: Average loss: 2.1566, Accuracy: 98/412 (24%)\n",
      "\n",
      "Train Epoch: 7 [0/1649 (0%)]\tLoss: 2.196112\n",
      "\n",
      "Test set: Average loss: 2.1388, Accuracy: 96/412 (23%)\n",
      "\n",
      "Train Epoch: 8 [0/1649 (0%)]\tLoss: 2.089194\n",
      "\n",
      "Test set: Average loss: 2.1060, Accuracy: 85/412 (21%)\n",
      "\n",
      "Train Epoch: 9 [0/1649 (0%)]\tLoss: 2.059728\n",
      "\n",
      "Test set: Average loss: 2.0962, Accuracy: 83/412 (20%)\n",
      "\n",
      "Train Epoch: 10 [0/1649 (0%)]\tLoss: 2.143975\n",
      "\n",
      "Test set: Average loss: 2.0672, Accuracy: 92/412 (22%)\n",
      "\n",
      "Train Epoch: 11 [0/1649 (0%)]\tLoss: 2.196558\n",
      "\n",
      "Test set: Average loss: 2.0507, Accuracy: 97/412 (24%)\n",
      "\n",
      "Train Epoch: 12 [0/1649 (0%)]\tLoss: 2.066987\n",
      "\n",
      "Test set: Average loss: 2.0399, Accuracy: 101/412 (25%)\n",
      "\n",
      "Train Epoch: 13 [0/1649 (0%)]\tLoss: 2.077828\n",
      "\n",
      "Test set: Average loss: 2.0306, Accuracy: 100/412 (24%)\n",
      "\n",
      "Train Epoch: 14 [0/1649 (0%)]\tLoss: 2.194437\n",
      "\n",
      "Test set: Average loss: 2.0246, Accuracy: 109/412 (26%)\n",
      "\n",
      "Train Epoch: 15 [0/1649 (0%)]\tLoss: 2.193441\n",
      "\n",
      "Test set: Average loss: 2.0780, Accuracy: 98/412 (24%)\n",
      "\n",
      "Train Epoch: 16 [0/1649 (0%)]\tLoss: 2.370327\n",
      "\n",
      "Test set: Average loss: 2.0109, Accuracy: 114/412 (28%)\n",
      "\n",
      "Train Epoch: 17 [0/1649 (0%)]\tLoss: 2.066920\n",
      "\n",
      "Test set: Average loss: 2.0089, Accuracy: 111/412 (27%)\n",
      "\n",
      "Train Epoch: 18 [0/1649 (0%)]\tLoss: 2.130696\n",
      "\n",
      "Test set: Average loss: 2.0169, Accuracy: 104/412 (25%)\n",
      "\n",
      "Train Epoch: 19 [0/1649 (0%)]\tLoss: 2.034024\n",
      "\n",
      "Test set: Average loss: 2.0337, Accuracy: 99/412 (24%)\n",
      "\n",
      "Train Epoch: 20 [0/1649 (0%)]\tLoss: 2.121364\n",
      "\n",
      "Test set: Average loss: 2.0473, Accuracy: 96/412 (23%)\n",
      "\n",
      "Train Epoch: 21 [0/1649 (0%)]\tLoss: 2.067785\n",
      "\n",
      "Test set: Average loss: 2.0637, Accuracy: 91/412 (22%)\n",
      "\n",
      "Train Epoch: 22 [0/1649 (0%)]\tLoss: 2.034672\n",
      "\n",
      "Test set: Average loss: 2.0413, Accuracy: 93/412 (23%)\n",
      "\n",
      "Train Epoch: 23 [0/1649 (0%)]\tLoss: 2.010224\n",
      "\n",
      "Test set: Average loss: 2.0126, Accuracy: 96/412 (23%)\n",
      "\n",
      "Train Epoch: 24 [0/1649 (0%)]\tLoss: 1.875048\n",
      "\n",
      "Test set: Average loss: 1.9974, Accuracy: 97/412 (24%)\n",
      "\n",
      "Train Epoch: 25 [0/1649 (0%)]\tLoss: 1.985842\n",
      "\n",
      "Test set: Average loss: 1.9830, Accuracy: 102/412 (25%)\n",
      "\n",
      "Train Epoch: 26 [0/1649 (0%)]\tLoss: 2.128755\n",
      "\n",
      "Test set: Average loss: 2.0035, Accuracy: 103/412 (25%)\n",
      "\n",
      "Train Epoch: 27 [0/1649 (0%)]\tLoss: 2.037295\n",
      "\n",
      "Test set: Average loss: 2.0135, Accuracy: 99/412 (24%)\n",
      "\n",
      "Train Epoch: 28 [0/1649 (0%)]\tLoss: 2.083181\n",
      "\n",
      "Test set: Average loss: 2.0187, Accuracy: 101/412 (25%)\n",
      "\n",
      "Train Epoch: 29 [0/1649 (0%)]\tLoss: 1.968489\n",
      "\n",
      "Test set: Average loss: 1.9917, Accuracy: 105/412 (25%)\n",
      "\n",
      "Train Epoch: 30 [0/1649 (0%)]\tLoss: 2.112072\n",
      "\n",
      "Test set: Average loss: 1.9710, Accuracy: 102/412 (25%)\n",
      "\n",
      "Train Epoch: 31 [0/1649 (0%)]\tLoss: 2.184319\n",
      "\n",
      "Test set: Average loss: 1.9777, Accuracy: 100/412 (24%)\n",
      "\n",
      "Train Epoch: 32 [0/1649 (0%)]\tLoss: 2.079635\n",
      "\n",
      "Test set: Average loss: 1.9750, Accuracy: 106/412 (26%)\n",
      "\n",
      "Train Epoch: 33 [0/1649 (0%)]\tLoss: 1.909887\n",
      "\n",
      "Test set: Average loss: 2.0035, Accuracy: 103/412 (25%)\n",
      "\n",
      "Train Epoch: 34 [0/1649 (0%)]\tLoss: 2.006514\n",
      "\n",
      "Test set: Average loss: 2.0214, Accuracy: 102/412 (25%)\n",
      "\n",
      "Train Epoch: 35 [0/1649 (0%)]\tLoss: 2.005088\n",
      "\n",
      "Test set: Average loss: 2.0158, Accuracy: 103/412 (25%)\n",
      "\n",
      "Train Epoch: 36 [0/1649 (0%)]\tLoss: 2.089097\n",
      "\n",
      "Test set: Average loss: 1.9998, Accuracy: 107/412 (26%)\n",
      "\n",
      "Train Epoch: 37 [0/1649 (0%)]\tLoss: 1.996243\n",
      "\n",
      "Test set: Average loss: 1.9678, Accuracy: 108/412 (26%)\n",
      "\n",
      "Train Epoch: 38 [0/1649 (0%)]\tLoss: 2.141299\n",
      "\n",
      "Test set: Average loss: 1.9521, Accuracy: 108/412 (26%)\n",
      "\n",
      "Train Epoch: 39 [0/1649 (0%)]\tLoss: 1.915912\n",
      "\n",
      "Test set: Average loss: 1.9461, Accuracy: 107/412 (26%)\n",
      "\n",
      "Train Epoch: 40 [0/1649 (0%)]\tLoss: 2.063421\n",
      "\n",
      "Test set: Average loss: 1.9474, Accuracy: 109/412 (26%)\n",
      "\n",
      "Train Epoch: 41 [0/1649 (0%)]\tLoss: 1.861220\n",
      "\n",
      "Test set: Average loss: 1.9554, Accuracy: 109/412 (26%)\n",
      "\n",
      "Train Epoch: 42 [0/1649 (0%)]\tLoss: 2.015702\n",
      "\n",
      "Test set: Average loss: 1.9747, Accuracy: 111/412 (27%)\n",
      "\n",
      "Train Epoch: 43 [0/1649 (0%)]\tLoss: 1.954861\n",
      "\n",
      "Test set: Average loss: 1.9616, Accuracy: 111/412 (27%)\n",
      "\n",
      "Train Epoch: 44 [0/1649 (0%)]\tLoss: 1.964021\n",
      "\n",
      "Test set: Average loss: 1.9423, Accuracy: 109/412 (26%)\n",
      "\n",
      "Train Epoch: 45 [0/1649 (0%)]\tLoss: 2.028618\n",
      "\n",
      "Test set: Average loss: 1.9369, Accuracy: 107/412 (26%)\n",
      "\n",
      "Train Epoch: 46 [0/1649 (0%)]\tLoss: 1.951704\n",
      "\n",
      "Test set: Average loss: 1.9345, Accuracy: 107/412 (26%)\n",
      "\n",
      "Train Epoch: 47 [0/1649 (0%)]\tLoss: 1.807771\n",
      "\n",
      "Test set: Average loss: 1.9320, Accuracy: 107/412 (26%)\n",
      "\n",
      "Train Epoch: 48 [0/1649 (0%)]\tLoss: 2.087997\n",
      "\n",
      "Test set: Average loss: 1.9323, Accuracy: 107/412 (26%)\n",
      "\n",
      "Train Epoch: 49 [0/1649 (0%)]\tLoss: 1.978772\n",
      "\n",
      "Test set: Average loss: 1.9375, Accuracy: 107/412 (26%)\n",
      "\n",
      "Train Epoch: 50 [0/1649 (0%)]\tLoss: 1.848858\n",
      "\n",
      "Test set: Average loss: 1.9315, Accuracy: 106/412 (26%)\n",
      "\n",
      "Train Epoch: 51 [0/1649 (0%)]\tLoss: 1.780777\n",
      "\n",
      "Test set: Average loss: 1.9260, Accuracy: 107/412 (26%)\n",
      "\n",
      "Train Epoch: 52 [0/1649 (0%)]\tLoss: 1.998007\n",
      "\n",
      "Test set: Average loss: 1.9267, Accuracy: 108/412 (26%)\n",
      "\n",
      "Train Epoch: 53 [0/1649 (0%)]\tLoss: 2.170038\n",
      "\n",
      "Test set: Average loss: 1.9534, Accuracy: 111/412 (27%)\n",
      "\n",
      "Train Epoch: 54 [0/1649 (0%)]\tLoss: 1.964646\n",
      "\n",
      "Test set: Average loss: 1.9686, Accuracy: 109/412 (26%)\n",
      "\n",
      "Train Epoch: 55 [0/1649 (0%)]\tLoss: 2.039047\n",
      "\n",
      "Test set: Average loss: 1.9722, Accuracy: 109/412 (26%)\n",
      "\n",
      "Train Epoch: 56 [0/1649 (0%)]\tLoss: 1.888208\n",
      "\n",
      "Test set: Average loss: 1.9584, Accuracy: 111/412 (27%)\n",
      "\n",
      "Train Epoch: 57 [0/1649 (0%)]\tLoss: 2.094545\n",
      "\n",
      "Test set: Average loss: 1.9488, Accuracy: 112/412 (27%)\n",
      "\n",
      "Train Epoch: 58 [0/1649 (0%)]\tLoss: 1.647640\n",
      "\n",
      "Test set: Average loss: 1.9349, Accuracy: 105/412 (25%)\n",
      "\n",
      "Train Epoch: 59 [0/1649 (0%)]\tLoss: 2.095306\n",
      "\n",
      "Test set: Average loss: 1.9293, Accuracy: 104/412 (25%)\n",
      "\n",
      "Train Epoch: 60 [0/1649 (0%)]\tLoss: 2.118106\n",
      "\n",
      "Test set: Average loss: 1.9169, Accuracy: 107/412 (26%)\n",
      "\n",
      "Train Epoch: 61 [0/1649 (0%)]\tLoss: 2.014538\n",
      "\n",
      "Test set: Average loss: 1.9308, Accuracy: 113/412 (27%)\n",
      "\n",
      "Train Epoch: 62 [0/1649 (0%)]\tLoss: 1.931301\n",
      "\n",
      "Test set: Average loss: 1.9566, Accuracy: 108/412 (26%)\n",
      "\n",
      "Train Epoch: 63 [0/1649 (0%)]\tLoss: 1.825856\n",
      "\n",
      "Test set: Average loss: 1.9838, Accuracy: 106/412 (26%)\n",
      "\n",
      "Train Epoch: 64 [0/1649 (0%)]\tLoss: 2.061237\n",
      "\n",
      "Test set: Average loss: 1.9818, Accuracy: 107/412 (26%)\n",
      "\n",
      "Train Epoch: 65 [0/1649 (0%)]\tLoss: 2.080821\n",
      "\n",
      "Test set: Average loss: 1.9724, Accuracy: 106/412 (26%)\n",
      "\n",
      "Train Epoch: 66 [0/1649 (0%)]\tLoss: 1.962473\n",
      "\n",
      "Test set: Average loss: 1.9517, Accuracy: 107/412 (26%)\n",
      "\n",
      "Train Epoch: 67 [0/1649 (0%)]\tLoss: 1.968748\n",
      "\n",
      "Test set: Average loss: 1.9298, Accuracy: 111/412 (27%)\n",
      "\n",
      "Train Epoch: 68 [0/1649 (0%)]\tLoss: 1.960034\n",
      "\n",
      "Test set: Average loss: 1.9188, Accuracy: 112/412 (27%)\n",
      "\n",
      "Train Epoch: 69 [0/1649 (0%)]\tLoss: 2.005242\n",
      "\n",
      "Test set: Average loss: 1.9171, Accuracy: 108/412 (26%)\n",
      "\n",
      "Train Epoch: 70 [0/1649 (0%)]\tLoss: 2.036483\n",
      "\n",
      "Test set: Average loss: 1.9273, Accuracy: 110/412 (27%)\n",
      "\n",
      "Train Epoch: 71 [0/1649 (0%)]\tLoss: 1.796900\n",
      "\n",
      "Test set: Average loss: 1.9340, Accuracy: 112/412 (27%)\n",
      "\n",
      "Train Epoch: 72 [0/1649 (0%)]\tLoss: 2.037566\n",
      "\n",
      "Test set: Average loss: 1.9264, Accuracy: 114/412 (28%)\n",
      "\n",
      "Train Epoch: 73 [0/1649 (0%)]\tLoss: 2.155694\n",
      "\n",
      "Test set: Average loss: 1.9298, Accuracy: 111/412 (27%)\n",
      "\n",
      "Train Epoch: 74 [0/1649 (0%)]\tLoss: 1.981402\n",
      "\n",
      "Test set: Average loss: 1.9297, Accuracy: 111/412 (27%)\n",
      "\n",
      "Train Epoch: 75 [0/1649 (0%)]\tLoss: 2.019729\n",
      "\n",
      "Test set: Average loss: 1.9319, Accuracy: 111/412 (27%)\n",
      "\n",
      "Train Epoch: 76 [0/1649 (0%)]\tLoss: 1.983784\n",
      "\n",
      "Test set: Average loss: 1.9326, Accuracy: 113/412 (27%)\n",
      "\n",
      "Train Epoch: 77 [0/1649 (0%)]\tLoss: 1.899599\n",
      "\n",
      "Test set: Average loss: 1.9234, Accuracy: 114/412 (28%)\n",
      "\n",
      "Train Epoch: 78 [0/1649 (0%)]\tLoss: 2.194709\n",
      "\n",
      "Test set: Average loss: 1.9212, Accuracy: 112/412 (27%)\n",
      "\n",
      "Train Epoch: 79 [0/1649 (0%)]\tLoss: 1.899475\n",
      "\n",
      "Test set: Average loss: 1.9366, Accuracy: 110/412 (27%)\n",
      "\n",
      "Train Epoch: 80 [0/1649 (0%)]\tLoss: 1.929403\n",
      "\n",
      "Test set: Average loss: 1.9858, Accuracy: 108/412 (26%)\n",
      "\n",
      "Train Epoch: 81 [0/1649 (0%)]\tLoss: 2.159981\n",
      "\n",
      "Test set: Average loss: 1.9944, Accuracy: 108/412 (26%)\n",
      "\n",
      "Train Epoch: 82 [0/1649 (0%)]\tLoss: 2.166881\n",
      "\n",
      "Test set: Average loss: 1.9489, Accuracy: 110/412 (27%)\n",
      "\n",
      "Train Epoch: 83 [0/1649 (0%)]\tLoss: 1.944151\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 1.9185, Accuracy: 112/412 (27%)\n",
      "\n",
      "Train Epoch: 84 [0/1649 (0%)]\tLoss: 1.831355\n",
      "\n",
      "Test set: Average loss: 1.9091, Accuracy: 111/412 (27%)\n",
      "\n",
      "Train Epoch: 85 [0/1649 (0%)]\tLoss: 2.030544\n",
      "\n",
      "Test set: Average loss: 1.9074, Accuracy: 111/412 (27%)\n",
      "\n",
      "Train Epoch: 86 [0/1649 (0%)]\tLoss: 2.009948\n",
      "\n",
      "Test set: Average loss: 1.9057, Accuracy: 114/412 (28%)\n",
      "\n",
      "Train Epoch: 87 [0/1649 (0%)]\tLoss: 1.871239\n",
      "\n",
      "Test set: Average loss: 1.9218, Accuracy: 113/412 (27%)\n",
      "\n",
      "Train Epoch: 88 [0/1649 (0%)]\tLoss: 1.795794\n",
      "\n",
      "Test set: Average loss: 1.9520, Accuracy: 110/412 (27%)\n",
      "\n",
      "Train Epoch: 89 [0/1649 (0%)]\tLoss: 2.038154\n",
      "\n",
      "Test set: Average loss: 1.9660, Accuracy: 111/412 (27%)\n",
      "\n",
      "Train Epoch: 90 [0/1649 (0%)]\tLoss: 2.220897\n",
      "\n",
      "Test set: Average loss: 1.9562, Accuracy: 110/412 (27%)\n",
      "\n",
      "Train Epoch: 91 [0/1649 (0%)]\tLoss: 1.976546\n",
      "\n",
      "Test set: Average loss: 1.9322, Accuracy: 110/412 (27%)\n",
      "\n",
      "Train Epoch: 92 [0/1649 (0%)]\tLoss: 1.825426\n",
      "\n",
      "Test set: Average loss: 1.9206, Accuracy: 111/412 (27%)\n",
      "\n",
      "Train Epoch: 93 [0/1649 (0%)]\tLoss: 1.993208\n",
      "\n",
      "Test set: Average loss: 1.9092, Accuracy: 114/412 (28%)\n",
      "\n",
      "Train Epoch: 94 [0/1649 (0%)]\tLoss: 2.068264\n",
      "\n",
      "Test set: Average loss: 1.9055, Accuracy: 114/412 (28%)\n",
      "\n",
      "Train Epoch: 95 [0/1649 (0%)]\tLoss: 2.119762\n",
      "\n",
      "Test set: Average loss: 1.9089, Accuracy: 115/412 (28%)\n",
      "\n",
      "Train Epoch: 96 [0/1649 (0%)]\tLoss: 1.865581\n",
      "\n",
      "Test set: Average loss: 1.9125, Accuracy: 113/412 (27%)\n",
      "\n",
      "Train Epoch: 97 [0/1649 (0%)]\tLoss: 2.057128\n",
      "\n",
      "Test set: Average loss: 1.9230, Accuracy: 113/412 (27%)\n",
      "\n",
      "Train Epoch: 98 [0/1649 (0%)]\tLoss: 2.073575\n",
      "\n",
      "Test set: Average loss: 1.9448, Accuracy: 111/412 (27%)\n",
      "\n",
      "Train Epoch: 99 [0/1649 (0%)]\tLoss: 2.067230\n",
      "\n",
      "Test set: Average loss: 1.9671, Accuracy: 109/412 (26%)\n",
      "\n",
      "Train Epoch: 100 [0/1649 (0%)]\tLoss: 2.056906\n",
      "\n",
      "Test set: Average loss: 1.9556, Accuracy: 111/412 (27%)\n",
      "\n",
      "Train Epoch: 101 [0/1649 (0%)]\tLoss: 1.943829\n",
      "\n",
      "Test set: Average loss: 1.9392, Accuracy: 112/412 (27%)\n",
      "\n",
      "Train Epoch: 102 [0/1649 (0%)]\tLoss: 1.931442\n",
      "\n",
      "Test set: Average loss: 1.9385, Accuracy: 111/412 (27%)\n",
      "\n",
      "Train Epoch: 103 [0/1649 (0%)]\tLoss: 1.927310\n",
      "\n",
      "Test set: Average loss: 1.9290, Accuracy: 113/412 (27%)\n",
      "\n",
      "Train Epoch: 104 [0/1649 (0%)]\tLoss: 1.783644\n",
      "\n",
      "Test set: Average loss: 1.9241, Accuracy: 113/412 (27%)\n",
      "\n",
      "Train Epoch: 105 [0/1649 (0%)]\tLoss: 2.023160\n",
      "\n",
      "Test set: Average loss: 1.9168, Accuracy: 112/412 (27%)\n",
      "\n",
      "Train Epoch: 106 [0/1649 (0%)]\tLoss: 2.057257\n",
      "\n",
      "Test set: Average loss: 1.9087, Accuracy: 113/412 (27%)\n",
      "\n",
      "Train Epoch: 107 [0/1649 (0%)]\tLoss: 1.827160\n",
      "\n",
      "Test set: Average loss: 1.9035, Accuracy: 113/412 (27%)\n",
      "\n",
      "Train Epoch: 108 [0/1649 (0%)]\tLoss: 2.236288\n",
      "\n",
      "Test set: Average loss: 1.9169, Accuracy: 112/412 (27%)\n",
      "\n",
      "Train Epoch: 109 [0/1649 (0%)]\tLoss: 2.103826\n",
      "\n",
      "Test set: Average loss: 1.9309, Accuracy: 111/412 (27%)\n",
      "\n",
      "Train Epoch: 110 [0/1649 (0%)]\tLoss: 1.922515\n",
      "\n",
      "Test set: Average loss: 1.9368, Accuracy: 110/412 (27%)\n",
      "\n",
      "Train Epoch: 111 [0/1649 (0%)]\tLoss: 1.988363\n",
      "\n",
      "Test set: Average loss: 1.9275, Accuracy: 113/412 (27%)\n",
      "\n",
      "Train Epoch: 112 [0/1649 (0%)]\tLoss: 2.055391\n",
      "\n",
      "Test set: Average loss: 1.9202, Accuracy: 113/412 (27%)\n",
      "\n",
      "Train Epoch: 113 [0/1649 (0%)]\tLoss: 1.874690\n",
      "\n",
      "Test set: Average loss: 1.9178, Accuracy: 113/412 (27%)\n",
      "\n",
      "Train Epoch: 114 [0/1649 (0%)]\tLoss: 2.133884\n",
      "\n",
      "Test set: Average loss: 1.9158, Accuracy: 113/412 (27%)\n",
      "\n",
      "Train Epoch: 115 [0/1649 (0%)]\tLoss: 1.851162\n",
      "\n",
      "Test set: Average loss: 1.9093, Accuracy: 111/412 (27%)\n",
      "\n",
      "Train Epoch: 116 [0/1649 (0%)]\tLoss: 2.058262\n",
      "\n",
      "Test set: Average loss: 1.9085, Accuracy: 111/412 (27%)\n",
      "\n",
      "Train Epoch: 117 [0/1649 (0%)]\tLoss: 1.790560\n",
      "\n",
      "Test set: Average loss: 1.8989, Accuracy: 114/412 (28%)\n",
      "\n",
      "Train Epoch: 118 [0/1649 (0%)]\tLoss: 1.830807\n",
      "\n",
      "Test set: Average loss: 1.8989, Accuracy: 113/412 (27%)\n",
      "\n",
      "Train Epoch: 119 [0/1649 (0%)]\tLoss: 1.855114\n",
      "\n",
      "Test set: Average loss: 1.8988, Accuracy: 114/412 (28%)\n",
      "\n",
      "Train Epoch: 120 [0/1649 (0%)]\tLoss: 1.928053\n",
      "\n",
      "Test set: Average loss: 1.8989, Accuracy: 113/412 (27%)\n",
      "\n",
      "Train Epoch: 121 [0/1649 (0%)]\tLoss: 2.141298\n",
      "\n",
      "Test set: Average loss: 1.9037, Accuracy: 114/412 (28%)\n",
      "\n",
      "Train Epoch: 122 [0/1649 (0%)]\tLoss: 2.024817\n",
      "\n",
      "Test set: Average loss: 1.9163, Accuracy: 112/412 (27%)\n",
      "\n",
      "Train Epoch: 123 [0/1649 (0%)]\tLoss: 1.817193\n",
      "\n",
      "Test set: Average loss: 1.9250, Accuracy: 111/412 (27%)\n",
      "\n",
      "Train Epoch: 124 [0/1649 (0%)]\tLoss: 2.079552\n",
      "\n",
      "Test set: Average loss: 1.9332, Accuracy: 107/412 (26%)\n",
      "\n",
      "Train Epoch: 125 [0/1649 (0%)]\tLoss: 1.918059\n",
      "\n",
      "Test set: Average loss: 1.9227, Accuracy: 110/412 (27%)\n",
      "\n",
      "Train Epoch: 126 [0/1649 (0%)]\tLoss: 1.843277\n",
      "\n",
      "Test set: Average loss: 1.9057, Accuracy: 109/412 (26%)\n",
      "\n",
      "Train Epoch: 127 [0/1649 (0%)]\tLoss: 1.908607\n",
      "\n",
      "Test set: Average loss: 1.8937, Accuracy: 112/412 (27%)\n",
      "\n",
      "Train Epoch: 128 [0/1649 (0%)]\tLoss: 2.089702\n",
      "\n",
      "Test set: Average loss: 1.9007, Accuracy: 111/412 (27%)\n",
      "\n",
      "Train Epoch: 129 [0/1649 (0%)]\tLoss: 1.972032\n",
      "\n",
      "Test set: Average loss: 1.8984, Accuracy: 111/412 (27%)\n",
      "\n",
      "Train Epoch: 130 [0/1649 (0%)]\tLoss: 1.892207\n",
      "\n",
      "Test set: Average loss: 1.9002, Accuracy: 115/412 (28%)\n",
      "\n",
      "Train Epoch: 131 [0/1649 (0%)]\tLoss: 1.922909\n",
      "\n",
      "Test set: Average loss: 1.9198, Accuracy: 111/412 (27%)\n",
      "\n",
      "Train Epoch: 132 [0/1649 (0%)]\tLoss: 2.013814\n",
      "\n",
      "Test set: Average loss: 1.9469, Accuracy: 111/412 (27%)\n",
      "\n",
      "Train Epoch: 133 [0/1649 (0%)]\tLoss: 2.132599\n",
      "\n",
      "Test set: Average loss: 1.9522, Accuracy: 108/412 (26%)\n",
      "\n",
      "Train Epoch: 134 [0/1649 (0%)]\tLoss: 1.939286\n",
      "\n",
      "Test set: Average loss: 1.9441, Accuracy: 115/412 (28%)\n",
      "\n",
      "Train Epoch: 135 [0/1649 (0%)]\tLoss: 2.055010\n",
      "\n",
      "Test set: Average loss: 1.9144, Accuracy: 121/412 (29%)\n",
      "\n",
      "Train Epoch: 136 [0/1649 (0%)]\tLoss: 2.047600\n",
      "\n",
      "Test set: Average loss: 1.8829, Accuracy: 122/412 (30%)\n",
      "\n",
      "Train Epoch: 137 [0/1649 (0%)]\tLoss: 1.923846\n",
      "\n",
      "Test set: Average loss: 1.8740, Accuracy: 117/412 (28%)\n",
      "\n",
      "Train Epoch: 138 [0/1649 (0%)]\tLoss: 1.945297\n",
      "\n",
      "Test set: Average loss: 1.9407, Accuracy: 117/412 (28%)\n",
      "\n",
      "Train Epoch: 139 [0/1649 (0%)]\tLoss: 1.922428\n",
      "\n",
      "Test set: Average loss: 1.8535, Accuracy: 124/412 (30%)\n",
      "\n",
      "Train Epoch: 140 [0/1649 (0%)]\tLoss: 1.550016\n",
      "\n",
      "Test set: Average loss: 1.8747, Accuracy: 130/412 (32%)\n",
      "\n",
      "Train Epoch: 141 [0/1649 (0%)]\tLoss: 1.970077\n",
      "\n",
      "Test set: Average loss: 1.8842, Accuracy: 129/412 (31%)\n",
      "\n",
      "Train Epoch: 142 [0/1649 (0%)]\tLoss: 1.938590\n",
      "\n",
      "Test set: Average loss: 1.8713, Accuracy: 129/412 (31%)\n",
      "\n",
      "Train Epoch: 143 [0/1649 (0%)]\tLoss: 1.859528\n",
      "\n",
      "Test set: Average loss: 1.8555, Accuracy: 128/412 (31%)\n",
      "\n",
      "Train Epoch: 144 [0/1649 (0%)]\tLoss: 1.835686\n",
      "\n",
      "Test set: Average loss: 1.8686, Accuracy: 114/412 (28%)\n",
      "\n",
      "Train Epoch: 145 [0/1649 (0%)]\tLoss: 2.007298\n",
      "\n",
      "Test set: Average loss: 1.8774, Accuracy: 115/412 (28%)\n",
      "\n",
      "Train Epoch: 146 [0/1649 (0%)]\tLoss: 1.950926\n",
      "\n",
      "Test set: Average loss: 1.8564, Accuracy: 117/412 (28%)\n",
      "\n",
      "Train Epoch: 147 [0/1649 (0%)]\tLoss: 1.848703\n",
      "\n",
      "Test set: Average loss: 1.8299, Accuracy: 129/412 (31%)\n",
      "\n",
      "Train Epoch: 148 [0/1649 (0%)]\tLoss: 1.808290\n",
      "\n",
      "Test set: Average loss: 1.8336, Accuracy: 133/412 (32%)\n",
      "\n",
      "Train Epoch: 149 [0/1649 (0%)]\tLoss: 1.998882\n",
      "\n",
      "Test set: Average loss: 1.8350, Accuracy: 132/412 (32%)\n",
      "\n",
      "Train Epoch: 150 [0/1649 (0%)]\tLoss: 1.897326\n",
      "\n",
      "Test set: Average loss: 1.8373, Accuracy: 129/412 (31%)\n",
      "\n",
      "Train Epoch: 151 [0/1649 (0%)]\tLoss: 1.628631\n",
      "\n",
      "Test set: Average loss: 1.8317, Accuracy: 124/412 (30%)\n",
      "\n",
      "Train Epoch: 152 [0/1649 (0%)]\tLoss: 1.777561\n",
      "\n",
      "Test set: Average loss: 1.8424, Accuracy: 122/412 (30%)\n",
      "\n",
      "Train Epoch: 153 [0/1649 (0%)]\tLoss: 1.747785\n",
      "\n",
      "Test set: Average loss: 1.8660, Accuracy: 118/412 (29%)\n",
      "\n",
      "Train Epoch: 154 [0/1649 (0%)]\tLoss: 1.621300\n",
      "\n",
      "Test set: Average loss: 1.8547, Accuracy: 120/412 (29%)\n",
      "\n",
      "Train Epoch: 155 [0/1649 (0%)]\tLoss: 1.913607\n",
      "\n",
      "Test set: Average loss: 1.8101, Accuracy: 134/412 (33%)\n",
      "\n",
      "Train Epoch: 156 [0/1649 (0%)]\tLoss: 1.807365\n",
      "\n",
      "Test set: Average loss: 1.8150, Accuracy: 132/412 (32%)\n",
      "\n",
      "Train Epoch: 157 [0/1649 (0%)]\tLoss: 1.689950\n",
      "\n",
      "Test set: Average loss: 1.8207, Accuracy: 134/412 (33%)\n",
      "\n",
      "Train Epoch: 158 [0/1649 (0%)]\tLoss: 1.829053\n",
      "\n",
      "Test set: Average loss: 1.8081, Accuracy: 133/412 (32%)\n",
      "\n",
      "Train Epoch: 159 [0/1649 (0%)]\tLoss: 1.688589\n",
      "\n",
      "Test set: Average loss: 1.8555, Accuracy: 122/412 (30%)\n",
      "\n",
      "Train Epoch: 160 [0/1649 (0%)]\tLoss: 2.035321\n",
      "\n",
      "Test set: Average loss: 1.8265, Accuracy: 131/412 (32%)\n",
      "\n",
      "Train Epoch: 161 [0/1649 (0%)]\tLoss: 1.961668\n",
      "\n",
      "Test set: Average loss: 1.8346, Accuracy: 131/412 (32%)\n",
      "\n",
      "Train Epoch: 162 [0/1649 (0%)]\tLoss: 1.695587\n",
      "\n",
      "Test set: Average loss: 1.8446, Accuracy: 133/412 (32%)\n",
      "\n",
      "Train Epoch: 163 [0/1649 (0%)]\tLoss: 1.838558\n",
      "\n",
      "Test set: Average loss: 1.8143, Accuracy: 138/412 (33%)\n",
      "\n",
      "Train Epoch: 164 [0/1649 (0%)]\tLoss: 2.178576\n",
      "\n",
      "Test set: Average loss: 1.8183, Accuracy: 136/412 (33%)\n",
      "\n",
      "Train Epoch: 165 [0/1649 (0%)]\tLoss: 1.740887\n",
      "\n",
      "Test set: Average loss: 1.8215, Accuracy: 138/412 (33%)\n",
      "\n",
      "Train Epoch: 166 [0/1649 (0%)]\tLoss: 1.933988\n",
      "\n",
      "Test set: Average loss: 1.8222, Accuracy: 137/412 (33%)\n",
      "\n",
      "Train Epoch: 167 [0/1649 (0%)]\tLoss: 2.010160\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 1.8354, Accuracy: 135/412 (33%)\n",
      "\n",
      "Train Epoch: 168 [0/1649 (0%)]\tLoss: 1.806566\n",
      "\n",
      "Test set: Average loss: 1.8442, Accuracy: 128/412 (31%)\n",
      "\n",
      "Train Epoch: 169 [0/1649 (0%)]\tLoss: 1.773153\n",
      "\n",
      "Test set: Average loss: 1.9269, Accuracy: 115/412 (28%)\n",
      "\n",
      "Train Epoch: 170 [0/1649 (0%)]\tLoss: 1.794892\n",
      "\n",
      "Test set: Average loss: 1.9260, Accuracy: 114/412 (28%)\n",
      "\n",
      "Train Epoch: 171 [0/1649 (0%)]\tLoss: 1.964898\n",
      "\n",
      "Test set: Average loss: 1.8614, Accuracy: 128/412 (31%)\n",
      "\n",
      "Train Epoch: 172 [0/1649 (0%)]\tLoss: 1.784596\n",
      "\n",
      "Test set: Average loss: 1.8943, Accuracy: 130/412 (32%)\n",
      "\n",
      "Train Epoch: 173 [0/1649 (0%)]\tLoss: 1.990551\n",
      "\n",
      "Test set: Average loss: 1.8959, Accuracy: 130/412 (32%)\n",
      "\n",
      "Train Epoch: 174 [0/1649 (0%)]\tLoss: 2.056072\n",
      "\n",
      "Test set: Average loss: 1.8608, Accuracy: 133/412 (32%)\n",
      "\n",
      "Train Epoch: 175 [0/1649 (0%)]\tLoss: 1.691118\n",
      "\n",
      "Test set: Average loss: 1.8293, Accuracy: 135/412 (33%)\n",
      "\n",
      "Train Epoch: 176 [0/1649 (0%)]\tLoss: 1.795705\n",
      "\n",
      "Test set: Average loss: 1.8003, Accuracy: 135/412 (33%)\n",
      "\n",
      "Train Epoch: 177 [0/1649 (0%)]\tLoss: 1.874411\n",
      "\n",
      "Test set: Average loss: 1.8243, Accuracy: 131/412 (32%)\n",
      "\n",
      "Train Epoch: 178 [0/1649 (0%)]\tLoss: 1.671462\n",
      "\n",
      "Test set: Average loss: 1.8628, Accuracy: 125/412 (30%)\n",
      "\n",
      "Train Epoch: 179 [0/1649 (0%)]\tLoss: 1.915509\n",
      "\n",
      "Test set: Average loss: 1.8540, Accuracy: 126/412 (31%)\n",
      "\n",
      "Train Epoch: 180 [0/1649 (0%)]\tLoss: 1.715067\n",
      "\n",
      "Test set: Average loss: 1.8273, Accuracy: 132/412 (32%)\n",
      "\n",
      "Train Epoch: 181 [0/1649 (0%)]\tLoss: 1.807914\n",
      "\n",
      "Test set: Average loss: 1.8154, Accuracy: 134/412 (33%)\n",
      "\n",
      "Train Epoch: 182 [0/1649 (0%)]\tLoss: 1.605758\n",
      "\n",
      "Test set: Average loss: 1.8143, Accuracy: 135/412 (33%)\n",
      "\n",
      "Train Epoch: 183 [0/1649 (0%)]\tLoss: 1.858474\n",
      "\n",
      "Test set: Average loss: 1.8048, Accuracy: 135/412 (33%)\n",
      "\n",
      "Train Epoch: 184 [0/1649 (0%)]\tLoss: 1.967066\n",
      "\n",
      "Test set: Average loss: 1.8052, Accuracy: 137/412 (33%)\n",
      "\n",
      "Train Epoch: 185 [0/1649 (0%)]\tLoss: 1.819113\n",
      "\n",
      "Test set: Average loss: 1.8093, Accuracy: 136/412 (33%)\n",
      "\n",
      "Train Epoch: 186 [0/1649 (0%)]\tLoss: 1.806942\n",
      "\n",
      "Test set: Average loss: 1.8411, Accuracy: 130/412 (32%)\n",
      "\n",
      "Train Epoch: 187 [0/1649 (0%)]\tLoss: 1.677419\n",
      "\n",
      "Test set: Average loss: 1.8960, Accuracy: 126/412 (31%)\n",
      "\n",
      "Train Epoch: 188 [0/1649 (0%)]\tLoss: 1.730715\n",
      "\n",
      "Test set: Average loss: 1.8485, Accuracy: 127/412 (31%)\n",
      "\n",
      "Train Epoch: 189 [0/1649 (0%)]\tLoss: 1.878656\n",
      "\n",
      "Test set: Average loss: 1.8159, Accuracy: 137/412 (33%)\n",
      "\n",
      "Train Epoch: 190 [0/1649 (0%)]\tLoss: 1.805192\n",
      "\n",
      "Test set: Average loss: 1.8299, Accuracy: 138/412 (33%)\n",
      "\n",
      "Train Epoch: 191 [0/1649 (0%)]\tLoss: 1.825932\n",
      "\n",
      "Test set: Average loss: 1.8506, Accuracy: 135/412 (33%)\n",
      "\n",
      "Train Epoch: 192 [0/1649 (0%)]\tLoss: 1.886939\n",
      "\n",
      "Test set: Average loss: 1.8573, Accuracy: 133/412 (32%)\n",
      "\n",
      "Train Epoch: 193 [0/1649 (0%)]\tLoss: 1.989108\n",
      "\n",
      "Test set: Average loss: 1.8652, Accuracy: 134/412 (33%)\n",
      "\n",
      "Train Epoch: 194 [0/1649 (0%)]\tLoss: 1.825196\n",
      "\n",
      "Test set: Average loss: 1.8573, Accuracy: 134/412 (33%)\n",
      "\n",
      "Train Epoch: 195 [0/1649 (0%)]\tLoss: 1.780650\n",
      "\n",
      "Test set: Average loss: 1.8388, Accuracy: 133/412 (32%)\n",
      "\n",
      "Train Epoch: 196 [0/1649 (0%)]\tLoss: 1.940990\n",
      "\n",
      "Test set: Average loss: 1.8107, Accuracy: 136/412 (33%)\n",
      "\n",
      "Train Epoch: 197 [0/1649 (0%)]\tLoss: 1.910256\n",
      "\n",
      "Test set: Average loss: 1.7921, Accuracy: 137/412 (33%)\n",
      "\n",
      "Train Epoch: 198 [0/1649 (0%)]\tLoss: 1.763995\n",
      "\n",
      "Test set: Average loss: 1.8619, Accuracy: 127/412 (31%)\n",
      "\n",
      "Train Epoch: 199 [0/1649 (0%)]\tLoss: 1.863453\n",
      "\n",
      "Test set: Average loss: 1.9357, Accuracy: 126/412 (31%)\n",
      "\n",
      "Train Epoch: 200 [0/1649 (0%)]\tLoss: 1.866129\n",
      "\n",
      "Test set: Average loss: 1.9116, Accuracy: 129/412 (31%)\n",
      "\n",
      "Train Epoch: 201 [0/1649 (0%)]\tLoss: 1.866480\n",
      "\n",
      "Test set: Average loss: 1.8509, Accuracy: 133/412 (32%)\n",
      "\n",
      "Train Epoch: 202 [0/1649 (0%)]\tLoss: 2.005171\n",
      "\n",
      "Test set: Average loss: 1.8157, Accuracy: 134/412 (33%)\n",
      "\n",
      "Train Epoch: 203 [0/1649 (0%)]\tLoss: 1.745026\n",
      "\n",
      "Test set: Average loss: 1.8079, Accuracy: 131/412 (32%)\n",
      "\n",
      "Train Epoch: 204 [0/1649 (0%)]\tLoss: 1.734340\n",
      "\n",
      "Test set: Average loss: 1.8086, Accuracy: 132/412 (32%)\n",
      "\n",
      "Train Epoch: 205 [0/1649 (0%)]\tLoss: 1.854475\n",
      "\n",
      "Test set: Average loss: 1.8191, Accuracy: 130/412 (32%)\n",
      "\n",
      "Train Epoch: 206 [0/1649 (0%)]\tLoss: 1.843257\n",
      "\n",
      "Test set: Average loss: 1.8278, Accuracy: 133/412 (32%)\n",
      "\n",
      "Train Epoch: 207 [0/1649 (0%)]\tLoss: 1.788444\n",
      "\n",
      "Test set: Average loss: 1.8376, Accuracy: 130/412 (32%)\n",
      "\n",
      "Train Epoch: 208 [0/1649 (0%)]\tLoss: 1.953703\n",
      "\n",
      "Test set: Average loss: 1.8100, Accuracy: 134/412 (33%)\n",
      "\n",
      "Train Epoch: 209 [0/1649 (0%)]\tLoss: 1.807347\n",
      "\n",
      "Test set: Average loss: 1.8097, Accuracy: 137/412 (33%)\n",
      "\n",
      "Train Epoch: 210 [0/1649 (0%)]\tLoss: 1.758970\n",
      "\n",
      "Test set: Average loss: 1.8092, Accuracy: 136/412 (33%)\n",
      "\n",
      "Train Epoch: 211 [0/1649 (0%)]\tLoss: 1.766654\n",
      "\n",
      "Test set: Average loss: 1.8137, Accuracy: 135/412 (33%)\n",
      "\n",
      "Train Epoch: 212 [0/1649 (0%)]\tLoss: 1.866385\n",
      "\n",
      "Test set: Average loss: 1.8106, Accuracy: 135/412 (33%)\n",
      "\n",
      "Train Epoch: 213 [0/1649 (0%)]\tLoss: 2.022047\n",
      "\n",
      "Test set: Average loss: 1.8031, Accuracy: 136/412 (33%)\n",
      "\n",
      "Train Epoch: 214 [0/1649 (0%)]\tLoss: 1.871765\n",
      "\n",
      "Test set: Average loss: 1.7987, Accuracy: 137/412 (33%)\n",
      "\n",
      "Train Epoch: 215 [0/1649 (0%)]\tLoss: 1.692080\n",
      "\n",
      "Test set: Average loss: 1.7985, Accuracy: 138/412 (33%)\n",
      "\n",
      "Train Epoch: 216 [0/1649 (0%)]\tLoss: 1.928673\n",
      "\n",
      "Test set: Average loss: 1.8015, Accuracy: 137/412 (33%)\n",
      "\n",
      "Train Epoch: 217 [0/1649 (0%)]\tLoss: 1.688448\n",
      "\n",
      "Test set: Average loss: 1.8000, Accuracy: 133/412 (32%)\n",
      "\n",
      "Train Epoch: 218 [0/1649 (0%)]\tLoss: 2.140593\n",
      "\n",
      "Test set: Average loss: 1.7993, Accuracy: 132/412 (32%)\n",
      "\n",
      "Train Epoch: 219 [0/1649 (0%)]\tLoss: 1.669225\n",
      "\n",
      "Test set: Average loss: 1.7954, Accuracy: 132/412 (32%)\n",
      "\n",
      "Train Epoch: 220 [0/1649 (0%)]\tLoss: 1.955942\n",
      "\n",
      "Test set: Average loss: 1.7930, Accuracy: 131/412 (32%)\n",
      "\n",
      "Train Epoch: 221 [0/1649 (0%)]\tLoss: 1.908105\n",
      "\n",
      "Test set: Average loss: 1.7963, Accuracy: 133/412 (32%)\n",
      "\n",
      "Train Epoch: 222 [0/1649 (0%)]\tLoss: 1.946700\n",
      "\n",
      "Test set: Average loss: 1.7917, Accuracy: 135/412 (33%)\n",
      "\n",
      "Train Epoch: 223 [0/1649 (0%)]\tLoss: 1.571505\n",
      "\n",
      "Test set: Average loss: 1.7987, Accuracy: 133/412 (32%)\n",
      "\n",
      "Train Epoch: 224 [0/1649 (0%)]\tLoss: 1.666926\n",
      "\n",
      "Test set: Average loss: 1.8031, Accuracy: 135/412 (33%)\n",
      "\n",
      "Train Epoch: 225 [0/1649 (0%)]\tLoss: 1.515524\n",
      "\n",
      "Test set: Average loss: 1.8017, Accuracy: 134/412 (33%)\n",
      "\n",
      "Train Epoch: 226 [0/1649 (0%)]\tLoss: 1.618402\n",
      "\n",
      "Test set: Average loss: 1.7911, Accuracy: 136/412 (33%)\n",
      "\n",
      "Train Epoch: 227 [0/1649 (0%)]\tLoss: 1.566482\n",
      "\n",
      "Test set: Average loss: 1.7751, Accuracy: 150/412 (36%)\n",
      "\n",
      "Train Epoch: 228 [0/1649 (0%)]\tLoss: 1.731200\n",
      "\n",
      "Test set: Average loss: 1.7603, Accuracy: 161/412 (39%)\n",
      "\n",
      "Train Epoch: 229 [0/1649 (0%)]\tLoss: 1.806577\n",
      "\n",
      "Test set: Average loss: 1.7448, Accuracy: 158/412 (38%)\n",
      "\n",
      "Train Epoch: 230 [0/1649 (0%)]\tLoss: 1.559953\n",
      "\n",
      "Test set: Average loss: 1.7594, Accuracy: 151/412 (37%)\n",
      "\n",
      "Train Epoch: 231 [0/1649 (0%)]\tLoss: 1.844126\n",
      "\n",
      "Test set: Average loss: 1.8578, Accuracy: 141/412 (34%)\n",
      "\n",
      "Train Epoch: 232 [0/1649 (0%)]\tLoss: 1.725948\n",
      "\n",
      "Test set: Average loss: 1.7045, Accuracy: 160/412 (39%)\n",
      "\n",
      "Train Epoch: 233 [0/1649 (0%)]\tLoss: 1.444088\n",
      "\n",
      "Test set: Average loss: 1.7195, Accuracy: 163/412 (40%)\n",
      "\n",
      "Train Epoch: 234 [0/1649 (0%)]\tLoss: 1.844715\n",
      "\n",
      "Test set: Average loss: 1.7942, Accuracy: 148/412 (36%)\n",
      "\n",
      "Train Epoch: 235 [0/1649 (0%)]\tLoss: 1.624952\n",
      "\n",
      "Test set: Average loss: 1.8102, Accuracy: 145/412 (35%)\n",
      "\n",
      "Train Epoch: 236 [0/1649 (0%)]\tLoss: 1.944482\n",
      "\n",
      "Test set: Average loss: 1.7336, Accuracy: 160/412 (39%)\n",
      "\n",
      "Train Epoch: 237 [0/1649 (0%)]\tLoss: 1.597734\n",
      "\n",
      "Test set: Average loss: 1.7082, Accuracy: 158/412 (38%)\n",
      "\n",
      "Train Epoch: 238 [0/1649 (0%)]\tLoss: 1.510887\n",
      "\n",
      "Test set: Average loss: 1.7393, Accuracy: 153/412 (37%)\n",
      "\n",
      "Train Epoch: 239 [0/1649 (0%)]\tLoss: 1.827652\n",
      "\n",
      "Test set: Average loss: 1.7868, Accuracy: 140/412 (34%)\n",
      "\n",
      "Train Epoch: 240 [0/1649 (0%)]\tLoss: 1.799831\n",
      "\n",
      "Test set: Average loss: 1.8188, Accuracy: 134/412 (33%)\n",
      "\n",
      "Train Epoch: 241 [0/1649 (0%)]\tLoss: 1.733644\n",
      "\n",
      "Test set: Average loss: 1.8218, Accuracy: 134/412 (33%)\n",
      "\n",
      "Train Epoch: 242 [0/1649 (0%)]\tLoss: 1.544319\n",
      "\n",
      "Test set: Average loss: 1.7880, Accuracy: 136/412 (33%)\n",
      "\n",
      "Train Epoch: 243 [0/1649 (0%)]\tLoss: 1.577110\n",
      "\n",
      "Test set: Average loss: 1.7659, Accuracy: 146/412 (35%)\n",
      "\n",
      "Train Epoch: 244 [0/1649 (0%)]\tLoss: 1.864928\n",
      "\n",
      "Test set: Average loss: 1.7303, Accuracy: 154/412 (37%)\n",
      "\n",
      "Train Epoch: 245 [0/1649 (0%)]\tLoss: 1.716587\n",
      "\n",
      "Test set: Average loss: 1.6789, Accuracy: 163/412 (40%)\n",
      "\n",
      "Train Epoch: 246 [0/1649 (0%)]\tLoss: 1.424260\n",
      "\n",
      "Test set: Average loss: 1.6683, Accuracy: 165/412 (40%)\n",
      "\n",
      "Train Epoch: 247 [0/1649 (0%)]\tLoss: 1.447186\n",
      "\n",
      "Test set: Average loss: 1.6787, Accuracy: 160/412 (39%)\n",
      "\n",
      "Train Epoch: 248 [0/1649 (0%)]\tLoss: 1.806831\n",
      "\n",
      "Test set: Average loss: 1.6864, Accuracy: 164/412 (40%)\n",
      "\n",
      "Train Epoch: 249 [0/1649 (0%)]\tLoss: 1.632501\n",
      "\n",
      "Test set: Average loss: 1.6760, Accuracy: 165/412 (40%)\n",
      "\n",
      "Train Epoch: 250 [0/1649 (0%)]\tLoss: 1.806030\n",
      "\n",
      "Test set: Average loss: 1.6620, Accuracy: 166/412 (40%)\n",
      "\n",
      "Train Epoch: 251 [0/1649 (0%)]\tLoss: 1.646066\n",
      "\n",
      "Test set: Average loss: 1.6565, Accuracy: 164/412 (40%)\n",
      "\n",
      "Train Epoch: 252 [0/1649 (0%)]\tLoss: 1.884481\n",
      "\n",
      "Test set: Average loss: 1.6596, Accuracy: 164/412 (40%)\n",
      "\n",
      "Train Epoch: 253 [0/1649 (0%)]\tLoss: 1.270037\n",
      "\n",
      "Test set: Average loss: 1.6688, Accuracy: 166/412 (40%)\n",
      "\n",
      "Train Epoch: 254 [0/1649 (0%)]\tLoss: 1.779767\n",
      "\n",
      "Test set: Average loss: 1.6695, Accuracy: 165/412 (40%)\n",
      "\n",
      "Train Epoch: 255 [0/1649 (0%)]\tLoss: 1.708527\n",
      "\n",
      "Test set: Average loss: 1.6684, Accuracy: 165/412 (40%)\n",
      "\n",
      "Train Epoch: 256 [0/1649 (0%)]\tLoss: 1.664780\n",
      "\n",
      "Test set: Average loss: 1.6510, Accuracy: 164/412 (40%)\n",
      "\n",
      "Train Epoch: 257 [0/1649 (0%)]\tLoss: 1.465933\n",
      "\n",
      "Test set: Average loss: 1.6510, Accuracy: 168/412 (41%)\n",
      "\n",
      "Train Epoch: 258 [0/1649 (0%)]\tLoss: 1.793114\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 1.6710, Accuracy: 168/412 (41%)\n",
      "\n",
      "Train Epoch: 259 [0/1649 (0%)]\tLoss: 1.626900\n",
      "\n",
      "Test set: Average loss: 1.6804, Accuracy: 164/412 (40%)\n",
      "\n",
      "Train Epoch: 260 [0/1649 (0%)]\tLoss: 1.583133\n",
      "\n",
      "Test set: Average loss: 1.6807, Accuracy: 164/412 (40%)\n",
      "\n",
      "Train Epoch: 261 [0/1649 (0%)]\tLoss: 1.238073\n",
      "\n",
      "Test set: Average loss: 1.6766, Accuracy: 164/412 (40%)\n",
      "\n",
      "Train Epoch: 262 [0/1649 (0%)]\tLoss: 1.658435\n",
      "\n",
      "Test set: Average loss: 1.6853, Accuracy: 160/412 (39%)\n",
      "\n",
      "Train Epoch: 263 [0/1649 (0%)]\tLoss: 1.587376\n",
      "\n",
      "Test set: Average loss: 1.6561, Accuracy: 165/412 (40%)\n",
      "\n",
      "Train Epoch: 264 [0/1649 (0%)]\tLoss: 1.813581\n",
      "\n",
      "Test set: Average loss: 1.6413, Accuracy: 166/412 (40%)\n",
      "\n",
      "Train Epoch: 265 [0/1649 (0%)]\tLoss: 1.589782\n",
      "\n",
      "Test set: Average loss: 1.6328, Accuracy: 166/412 (40%)\n",
      "\n",
      "Train Epoch: 266 [0/1649 (0%)]\tLoss: 1.633115\n",
      "\n",
      "Test set: Average loss: 1.6293, Accuracy: 166/412 (40%)\n",
      "\n",
      "Train Epoch: 267 [0/1649 (0%)]\tLoss: 1.835959\n",
      "\n",
      "Test set: Average loss: 1.6311, Accuracy: 170/412 (41%)\n",
      "\n",
      "Train Epoch: 268 [0/1649 (0%)]\tLoss: 1.611671\n",
      "\n",
      "Test set: Average loss: 1.6383, Accuracy: 169/412 (41%)\n",
      "\n",
      "Train Epoch: 269 [0/1649 (0%)]\tLoss: 1.176034\n",
      "\n",
      "Test set: Average loss: 1.6728, Accuracy: 163/412 (40%)\n",
      "\n",
      "Train Epoch: 270 [0/1649 (0%)]\tLoss: 1.932356\n",
      "\n",
      "Test set: Average loss: 1.6683, Accuracy: 159/412 (39%)\n",
      "\n",
      "Train Epoch: 271 [0/1649 (0%)]\tLoss: 1.913259\n",
      "\n",
      "Test set: Average loss: 1.6603, Accuracy: 161/412 (39%)\n",
      "\n",
      "Train Epoch: 272 [0/1649 (0%)]\tLoss: 1.657433\n",
      "\n",
      "Test set: Average loss: 1.6847, Accuracy: 163/412 (40%)\n",
      "\n",
      "Train Epoch: 273 [0/1649 (0%)]\tLoss: 1.722817\n",
      "\n",
      "Test set: Average loss: 1.7094, Accuracy: 157/412 (38%)\n",
      "\n",
      "Train Epoch: 274 [0/1649 (0%)]\tLoss: 1.811050\n",
      "\n",
      "Test set: Average loss: 1.7011, Accuracy: 162/412 (39%)\n",
      "\n",
      "Train Epoch: 275 [0/1649 (0%)]\tLoss: 1.885225\n",
      "\n",
      "Test set: Average loss: 1.6676, Accuracy: 163/412 (40%)\n",
      "\n",
      "Train Epoch: 276 [0/1649 (0%)]\tLoss: 1.546080\n",
      "\n",
      "Test set: Average loss: 1.6211, Accuracy: 167/412 (41%)\n",
      "\n",
      "Train Epoch: 277 [0/1649 (0%)]\tLoss: 1.871794\n",
      "\n",
      "Test set: Average loss: 1.6129, Accuracy: 164/412 (40%)\n",
      "\n",
      "Train Epoch: 278 [0/1649 (0%)]\tLoss: 1.625968\n",
      "\n",
      "Test set: Average loss: 1.6366, Accuracy: 163/412 (40%)\n",
      "\n",
      "Train Epoch: 279 [0/1649 (0%)]\tLoss: 1.810892\n",
      "\n",
      "Test set: Average loss: 1.6517, Accuracy: 163/412 (40%)\n",
      "\n",
      "Train Epoch: 280 [0/1649 (0%)]\tLoss: 1.561564\n",
      "\n",
      "Test set: Average loss: 1.6532, Accuracy: 163/412 (40%)\n",
      "\n",
      "Train Epoch: 281 [0/1649 (0%)]\tLoss: 1.579919\n",
      "\n",
      "Test set: Average loss: 1.6607, Accuracy: 161/412 (39%)\n",
      "\n",
      "Train Epoch: 282 [0/1649 (0%)]\tLoss: 1.610826\n",
      "\n",
      "Test set: Average loss: 1.6416, Accuracy: 162/412 (39%)\n",
      "\n",
      "Train Epoch: 283 [0/1649 (0%)]\tLoss: 1.626929\n",
      "\n",
      "Test set: Average loss: 1.6314, Accuracy: 164/412 (40%)\n",
      "\n",
      "Train Epoch: 284 [0/1649 (0%)]\tLoss: 1.572252\n",
      "\n",
      "Test set: Average loss: 1.6455, Accuracy: 168/412 (41%)\n",
      "\n",
      "Train Epoch: 285 [0/1649 (0%)]\tLoss: 1.640382\n",
      "\n",
      "Test set: Average loss: 1.6566, Accuracy: 167/412 (41%)\n",
      "\n",
      "Train Epoch: 286 [0/1649 (0%)]\tLoss: 1.799709\n",
      "\n",
      "Test set: Average loss: 1.6733, Accuracy: 164/412 (40%)\n",
      "\n",
      "Train Epoch: 287 [0/1649 (0%)]\tLoss: 1.528039\n",
      "\n",
      "Test set: Average loss: 1.6813, Accuracy: 167/412 (41%)\n",
      "\n",
      "Train Epoch: 288 [0/1649 (0%)]\tLoss: 1.843617\n",
      "\n",
      "Test set: Average loss: 1.6653, Accuracy: 167/412 (41%)\n",
      "\n",
      "Train Epoch: 289 [0/1649 (0%)]\tLoss: 1.512100\n",
      "\n",
      "Test set: Average loss: 1.6542, Accuracy: 168/412 (41%)\n",
      "\n",
      "Train Epoch: 290 [0/1649 (0%)]\tLoss: 1.734118\n",
      "\n",
      "Test set: Average loss: 1.6316, Accuracy: 168/412 (41%)\n",
      "\n",
      "Train Epoch: 291 [0/1649 (0%)]\tLoss: 1.560410\n",
      "\n",
      "Test set: Average loss: 1.6468, Accuracy: 162/412 (39%)\n",
      "\n",
      "Train Epoch: 292 [0/1649 (0%)]\tLoss: 1.754298\n",
      "\n",
      "Test set: Average loss: 1.6555, Accuracy: 161/412 (39%)\n",
      "\n",
      "Train Epoch: 293 [0/1649 (0%)]\tLoss: 1.766088\n",
      "\n",
      "Test set: Average loss: 1.6449, Accuracy: 162/412 (39%)\n",
      "\n",
      "Train Epoch: 294 [0/1649 (0%)]\tLoss: 1.555015\n",
      "\n",
      "Test set: Average loss: 1.6401, Accuracy: 165/412 (40%)\n",
      "\n",
      "Train Epoch: 295 [0/1649 (0%)]\tLoss: 1.446673\n",
      "\n",
      "Test set: Average loss: 1.6458, Accuracy: 164/412 (40%)\n",
      "\n",
      "Train Epoch: 296 [0/1649 (0%)]\tLoss: 1.894144\n",
      "\n",
      "Test set: Average loss: 1.6646, Accuracy: 164/412 (40%)\n",
      "\n",
      "Train Epoch: 297 [0/1649 (0%)]\tLoss: 1.700697\n",
      "\n",
      "Test set: Average loss: 1.6709, Accuracy: 161/412 (39%)\n",
      "\n",
      "Train Epoch: 298 [0/1649 (0%)]\tLoss: 1.671438\n",
      "\n",
      "Test set: Average loss: 1.6686, Accuracy: 162/412 (39%)\n",
      "\n",
      "Train Epoch: 299 [0/1649 (0%)]\tLoss: 1.653442\n",
      "\n",
      "Test set: Average loss: 1.6371, Accuracy: 166/412 (40%)\n",
      "\n",
      "Train Epoch: 300 [0/1649 (0%)]\tLoss: 1.978754\n",
      "\n",
      "Test set: Average loss: 1.6177, Accuracy: 169/412 (41%)\n",
      "\n",
      "Train Epoch: 301 [0/1649 (0%)]\tLoss: 1.454591\n",
      "\n",
      "Test set: Average loss: 1.6459, Accuracy: 167/412 (41%)\n",
      "\n",
      "Train Epoch: 302 [0/1649 (0%)]\tLoss: 1.487287\n",
      "\n",
      "Test set: Average loss: 1.6810, Accuracy: 162/412 (39%)\n",
      "\n",
      "Train Epoch: 303 [0/1649 (0%)]\tLoss: 1.694646\n",
      "\n",
      "Test set: Average loss: 1.7312, Accuracy: 160/412 (39%)\n",
      "\n",
      "Train Epoch: 304 [0/1649 (0%)]\tLoss: 1.606861\n",
      "\n",
      "Test set: Average loss: 1.7076, Accuracy: 160/412 (39%)\n",
      "\n",
      "Train Epoch: 305 [0/1649 (0%)]\tLoss: 1.811910\n",
      "\n",
      "Test set: Average loss: 1.6310, Accuracy: 167/412 (41%)\n",
      "\n",
      "Train Epoch: 306 [0/1649 (0%)]\tLoss: 1.670241\n",
      "\n",
      "Test set: Average loss: 1.6265, Accuracy: 165/412 (40%)\n",
      "\n",
      "Train Epoch: 307 [0/1649 (0%)]\tLoss: 1.693051\n",
      "\n",
      "Test set: Average loss: 1.6867, Accuracy: 158/412 (38%)\n",
      "\n",
      "Train Epoch: 308 [0/1649 (0%)]\tLoss: 1.814181\n",
      "\n",
      "Test set: Average loss: 1.7815, Accuracy: 148/412 (36%)\n",
      "\n",
      "Train Epoch: 309 [0/1649 (0%)]\tLoss: 1.550043\n",
      "\n",
      "Test set: Average loss: 1.7515, Accuracy: 154/412 (37%)\n",
      "\n",
      "Train Epoch: 310 [0/1649 (0%)]\tLoss: 2.007491\n",
      "\n",
      "Test set: Average loss: 1.6702, Accuracy: 159/412 (39%)\n",
      "\n",
      "Train Epoch: 311 [0/1649 (0%)]\tLoss: 1.699005\n",
      "\n",
      "Test set: Average loss: 1.6447, Accuracy: 164/412 (40%)\n",
      "\n",
      "Train Epoch: 312 [0/1649 (0%)]\tLoss: 1.615854\n",
      "\n",
      "Test set: Average loss: 1.6592, Accuracy: 162/412 (39%)\n",
      "\n",
      "Train Epoch: 313 [0/1649 (0%)]\tLoss: 1.753714\n",
      "\n",
      "Test set: Average loss: 1.6817, Accuracy: 161/412 (39%)\n",
      "\n",
      "Train Epoch: 314 [0/1649 (0%)]\tLoss: 1.633230\n",
      "\n",
      "Test set: Average loss: 1.6966, Accuracy: 162/412 (39%)\n",
      "\n",
      "Train Epoch: 315 [0/1649 (0%)]\tLoss: 1.637261\n",
      "\n",
      "Test set: Average loss: 1.7104, Accuracy: 159/412 (39%)\n",
      "\n",
      "Train Epoch: 316 [0/1649 (0%)]\tLoss: 1.729404\n",
      "\n",
      "Test set: Average loss: 1.7031, Accuracy: 161/412 (39%)\n",
      "\n",
      "Train Epoch: 317 [0/1649 (0%)]\tLoss: 1.775243\n",
      "\n",
      "Test set: Average loss: 1.6376, Accuracy: 164/412 (40%)\n",
      "\n",
      "Train Epoch: 318 [0/1649 (0%)]\tLoss: 1.531347\n",
      "\n",
      "Test set: Average loss: 1.6318, Accuracy: 163/412 (40%)\n",
      "\n",
      "Train Epoch: 319 [0/1649 (0%)]\tLoss: 1.515249\n",
      "\n",
      "Test set: Average loss: 1.6571, Accuracy: 162/412 (39%)\n",
      "\n",
      "Train Epoch: 320 [0/1649 (0%)]\tLoss: 1.630432\n",
      "\n",
      "Test set: Average loss: 1.6718, Accuracy: 167/412 (41%)\n",
      "\n",
      "Train Epoch: 321 [0/1649 (0%)]\tLoss: 1.742767\n",
      "\n",
      "Test set: Average loss: 1.6618, Accuracy: 165/412 (40%)\n",
      "\n",
      "Train Epoch: 322 [0/1649 (0%)]\tLoss: 1.741050\n",
      "\n",
      "Test set: Average loss: 1.6540, Accuracy: 164/412 (40%)\n",
      "\n",
      "Train Epoch: 323 [0/1649 (0%)]\tLoss: 1.602733\n",
      "\n",
      "Test set: Average loss: 1.6438, Accuracy: 166/412 (40%)\n",
      "\n",
      "Train Epoch: 324 [0/1649 (0%)]\tLoss: 1.441465\n",
      "\n",
      "Test set: Average loss: 1.6247, Accuracy: 166/412 (40%)\n",
      "\n",
      "Train Epoch: 325 [0/1649 (0%)]\tLoss: 1.489733\n",
      "\n",
      "Test set: Average loss: 1.6403, Accuracy: 168/412 (41%)\n",
      "\n",
      "Train Epoch: 326 [0/1649 (0%)]\tLoss: 1.588768\n",
      "\n",
      "Test set: Average loss: 1.6799, Accuracy: 161/412 (39%)\n",
      "\n",
      "Train Epoch: 327 [0/1649 (0%)]\tLoss: 1.531085\n",
      "\n",
      "Test set: Average loss: 1.7433, Accuracy: 159/412 (39%)\n",
      "\n",
      "Train Epoch: 328 [0/1649 (0%)]\tLoss: 1.543824\n",
      "\n",
      "Test set: Average loss: 1.7227, Accuracy: 161/412 (39%)\n",
      "\n",
      "Train Epoch: 329 [0/1649 (0%)]\tLoss: 1.783965\n",
      "\n",
      "Test set: Average loss: 1.6818, Accuracy: 162/412 (39%)\n",
      "\n",
      "Train Epoch: 330 [0/1649 (0%)]\tLoss: 1.728851\n",
      "\n",
      "Test set: Average loss: 1.6452, Accuracy: 160/412 (39%)\n",
      "\n",
      "Train Epoch: 331 [0/1649 (0%)]\tLoss: 1.609793\n",
      "\n",
      "Test set: Average loss: 1.6381, Accuracy: 161/412 (39%)\n",
      "\n",
      "Train Epoch: 332 [0/1649 (0%)]\tLoss: 1.563667\n",
      "\n",
      "Test set: Average loss: 1.6946, Accuracy: 164/412 (40%)\n",
      "\n",
      "Train Epoch: 333 [0/1649 (0%)]\tLoss: 1.447789\n",
      "\n",
      "Test set: Average loss: 1.7280, Accuracy: 166/412 (40%)\n",
      "\n",
      "Train Epoch: 334 [0/1649 (0%)]\tLoss: 1.624183\n",
      "\n",
      "Test set: Average loss: 1.6524, Accuracy: 170/412 (41%)\n",
      "\n",
      "Train Epoch: 335 [0/1649 (0%)]\tLoss: 1.561754\n",
      "\n",
      "Test set: Average loss: 1.6041, Accuracy: 169/412 (41%)\n",
      "\n",
      "Train Epoch: 336 [0/1649 (0%)]\tLoss: 1.732545\n",
      "\n",
      "Test set: Average loss: 1.6103, Accuracy: 169/412 (41%)\n",
      "\n",
      "Train Epoch: 337 [0/1649 (0%)]\tLoss: 1.590698\n",
      "\n",
      "Test set: Average loss: 1.6358, Accuracy: 163/412 (40%)\n",
      "\n",
      "Train Epoch: 338 [0/1649 (0%)]\tLoss: 1.788670\n",
      "\n",
      "Test set: Average loss: 1.6534, Accuracy: 164/412 (40%)\n",
      "\n",
      "Train Epoch: 339 [0/1649 (0%)]\tLoss: 1.494626\n",
      "\n",
      "Test set: Average loss: 1.6594, Accuracy: 162/412 (39%)\n",
      "\n",
      "Train Epoch: 340 [0/1649 (0%)]\tLoss: 1.541118\n",
      "\n",
      "Test set: Average loss: 1.6617, Accuracy: 162/412 (39%)\n",
      "\n",
      "Train Epoch: 341 [0/1649 (0%)]\tLoss: 1.605115\n",
      "\n",
      "Test set: Average loss: 1.6527, Accuracy: 162/412 (39%)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 342 [0/1649 (0%)]\tLoss: 1.489168\n",
      "\n",
      "Test set: Average loss: 1.6422, Accuracy: 164/412 (40%)\n",
      "\n",
      "Train Epoch: 343 [0/1649 (0%)]\tLoss: 1.641879\n",
      "\n",
      "Test set: Average loss: 1.6181, Accuracy: 168/412 (41%)\n",
      "\n",
      "Train Epoch: 344 [0/1649 (0%)]\tLoss: 1.591333\n",
      "\n",
      "Test set: Average loss: 1.6027, Accuracy: 168/412 (41%)\n",
      "\n",
      "Train Epoch: 345 [0/1649 (0%)]\tLoss: 1.722479\n",
      "\n",
      "Test set: Average loss: 1.6010, Accuracy: 168/412 (41%)\n",
      "\n",
      "Train Epoch: 346 [0/1649 (0%)]\tLoss: 1.360886\n",
      "\n",
      "Test set: Average loss: 1.6061, Accuracy: 168/412 (41%)\n",
      "\n",
      "Train Epoch: 347 [0/1649 (0%)]\tLoss: 1.450205\n",
      "\n",
      "Test set: Average loss: 1.6029, Accuracy: 167/412 (41%)\n",
      "\n",
      "Train Epoch: 348 [0/1649 (0%)]\tLoss: 1.737765\n",
      "\n",
      "Test set: Average loss: 1.6053, Accuracy: 168/412 (41%)\n",
      "\n",
      "Train Epoch: 349 [0/1649 (0%)]\tLoss: 1.705074\n",
      "\n",
      "Test set: Average loss: 1.6126, Accuracy: 169/412 (41%)\n",
      "\n",
      "Train Epoch: 350 [0/1649 (0%)]\tLoss: 1.461811\n",
      "\n",
      "Test set: Average loss: 1.6145, Accuracy: 169/412 (41%)\n",
      "\n",
      "Train Epoch: 351 [0/1649 (0%)]\tLoss: 1.620768\n",
      "\n",
      "Test set: Average loss: 1.6342, Accuracy: 165/412 (40%)\n",
      "\n",
      "Train Epoch: 352 [0/1649 (0%)]\tLoss: 1.549141\n",
      "\n",
      "Test set: Average loss: 1.6862, Accuracy: 166/412 (40%)\n",
      "\n",
      "Train Epoch: 353 [0/1649 (0%)]\tLoss: 1.746879\n",
      "\n",
      "Test set: Average loss: 1.6786, Accuracy: 165/412 (40%)\n",
      "\n",
      "Train Epoch: 354 [0/1649 (0%)]\tLoss: 1.724400\n",
      "\n",
      "Test set: Average loss: 1.6516, Accuracy: 165/412 (40%)\n",
      "\n",
      "Train Epoch: 355 [0/1649 (0%)]\tLoss: 1.491705\n",
      "\n",
      "Test set: Average loss: 1.6127, Accuracy: 168/412 (41%)\n",
      "\n",
      "Train Epoch: 356 [0/1649 (0%)]\tLoss: 1.778505\n",
      "\n",
      "Test set: Average loss: 1.5941, Accuracy: 169/412 (41%)\n",
      "\n",
      "Train Epoch: 357 [0/1649 (0%)]\tLoss: 1.591788\n",
      "\n",
      "Test set: Average loss: 1.5901, Accuracy: 173/412 (42%)\n",
      "\n",
      "Train Epoch: 358 [0/1649 (0%)]\tLoss: 1.444158\n",
      "\n",
      "Test set: Average loss: 1.5954, Accuracy: 169/412 (41%)\n",
      "\n",
      "Train Epoch: 359 [0/1649 (0%)]\tLoss: 1.505818\n",
      "\n",
      "Test set: Average loss: 1.5999, Accuracy: 171/412 (42%)\n",
      "\n",
      "Train Epoch: 360 [0/1649 (0%)]\tLoss: 1.384311\n",
      "\n",
      "Test set: Average loss: 1.6050, Accuracy: 170/412 (41%)\n",
      "\n",
      "Train Epoch: 361 [0/1649 (0%)]\tLoss: 1.845352\n",
      "\n",
      "Test set: Average loss: 1.6276, Accuracy: 171/412 (42%)\n",
      "\n",
      "Train Epoch: 362 [0/1649 (0%)]\tLoss: 1.704409\n",
      "\n",
      "Test set: Average loss: 1.7019, Accuracy: 165/412 (40%)\n",
      "\n",
      "Train Epoch: 363 [0/1649 (0%)]\tLoss: 1.641361\n",
      "\n",
      "Test set: Average loss: 1.7642, Accuracy: 154/412 (37%)\n",
      "\n",
      "Train Epoch: 364 [0/1649 (0%)]\tLoss: 1.556461\n",
      "\n",
      "Test set: Average loss: 1.8170, Accuracy: 148/412 (36%)\n",
      "\n",
      "Train Epoch: 365 [0/1649 (0%)]\tLoss: 1.589821\n",
      "\n",
      "Test set: Average loss: 1.7937, Accuracy: 149/412 (36%)\n",
      "\n",
      "Train Epoch: 366 [0/1649 (0%)]\tLoss: 1.549440\n",
      "\n",
      "Test set: Average loss: 1.7304, Accuracy: 151/412 (37%)\n",
      "\n",
      "Train Epoch: 367 [0/1649 (0%)]\tLoss: 1.678316\n",
      "\n",
      "Test set: Average loss: 1.6854, Accuracy: 157/412 (38%)\n",
      "\n",
      "Train Epoch: 368 [0/1649 (0%)]\tLoss: 1.557796\n",
      "\n",
      "Test set: Average loss: 1.6754, Accuracy: 155/412 (38%)\n",
      "\n",
      "Train Epoch: 369 [0/1649 (0%)]\tLoss: 1.743801\n",
      "\n",
      "Test set: Average loss: 1.6707, Accuracy: 163/412 (40%)\n",
      "\n",
      "Train Epoch: 370 [0/1649 (0%)]\tLoss: 1.780814\n",
      "\n",
      "Test set: Average loss: 1.6584, Accuracy: 160/412 (39%)\n",
      "\n",
      "Train Epoch: 371 [0/1649 (0%)]\tLoss: 1.571180\n",
      "\n",
      "Test set: Average loss: 1.6444, Accuracy: 165/412 (40%)\n",
      "\n",
      "Train Epoch: 372 [0/1649 (0%)]\tLoss: 1.723040\n",
      "\n",
      "Test set: Average loss: 1.6303, Accuracy: 164/412 (40%)\n",
      "\n",
      "Train Epoch: 373 [0/1649 (0%)]\tLoss: 1.546520\n",
      "\n",
      "Test set: Average loss: 1.6356, Accuracy: 168/412 (41%)\n",
      "\n",
      "Train Epoch: 374 [0/1649 (0%)]\tLoss: 1.593929\n",
      "\n",
      "Test set: Average loss: 1.6550, Accuracy: 170/412 (41%)\n",
      "\n",
      "Train Epoch: 375 [0/1649 (0%)]\tLoss: 1.832193\n",
      "\n",
      "Test set: Average loss: 1.6232, Accuracy: 175/412 (42%)\n",
      "\n",
      "Train Epoch: 376 [0/1649 (0%)]\tLoss: 1.740311\n",
      "\n",
      "Test set: Average loss: 1.6006, Accuracy: 172/412 (42%)\n",
      "\n",
      "Train Epoch: 377 [0/1649 (0%)]\tLoss: 1.097088\n",
      "\n",
      "Test set: Average loss: 1.6062, Accuracy: 171/412 (42%)\n",
      "\n",
      "Train Epoch: 378 [0/1649 (0%)]\tLoss: 1.721804\n",
      "\n",
      "Test set: Average loss: 1.6009, Accuracy: 172/412 (42%)\n",
      "\n",
      "Train Epoch: 379 [0/1649 (0%)]\tLoss: 1.845507\n",
      "\n",
      "Test set: Average loss: 1.5902, Accuracy: 175/412 (42%)\n",
      "\n",
      "Train Epoch: 380 [0/1649 (0%)]\tLoss: 1.784398\n",
      "\n",
      "Test set: Average loss: 1.5873, Accuracy: 176/412 (43%)\n",
      "\n",
      "Train Epoch: 381 [0/1649 (0%)]\tLoss: 1.689883\n",
      "\n",
      "Test set: Average loss: 1.5906, Accuracy: 176/412 (43%)\n",
      "\n",
      "Train Epoch: 382 [0/1649 (0%)]\tLoss: 1.363629\n",
      "\n",
      "Test set: Average loss: 1.5969, Accuracy: 172/412 (42%)\n",
      "\n",
      "Train Epoch: 383 [0/1649 (0%)]\tLoss: 1.381006\n",
      "\n",
      "Test set: Average loss: 1.5899, Accuracy: 171/412 (42%)\n",
      "\n",
      "Train Epoch: 384 [0/1649 (0%)]\tLoss: 1.805281\n",
      "\n",
      "Test set: Average loss: 1.5912, Accuracy: 172/412 (42%)\n",
      "\n",
      "Train Epoch: 385 [0/1649 (0%)]\tLoss: 1.879600\n",
      "\n",
      "Test set: Average loss: 1.6099, Accuracy: 168/412 (41%)\n",
      "\n",
      "Train Epoch: 386 [0/1649 (0%)]\tLoss: 1.628158\n",
      "\n",
      "Test set: Average loss: 1.6317, Accuracy: 165/412 (40%)\n",
      "\n",
      "Train Epoch: 387 [0/1649 (0%)]\tLoss: 1.725643\n",
      "\n",
      "Test set: Average loss: 1.6533, Accuracy: 162/412 (39%)\n",
      "\n",
      "Train Epoch: 388 [0/1649 (0%)]\tLoss: 1.606081\n",
      "\n",
      "Test set: Average loss: 1.6776, Accuracy: 159/412 (39%)\n",
      "\n",
      "Train Epoch: 389 [0/1649 (0%)]\tLoss: 1.596466\n",
      "\n",
      "Test set: Average loss: 1.6818, Accuracy: 161/412 (39%)\n",
      "\n",
      "Train Epoch: 390 [0/1649 (0%)]\tLoss: 1.348116\n",
      "\n",
      "Test set: Average loss: 1.6794, Accuracy: 159/412 (39%)\n",
      "\n",
      "Train Epoch: 391 [0/1649 (0%)]\tLoss: 1.498329\n",
      "\n",
      "Test set: Average loss: 1.6528, Accuracy: 165/412 (40%)\n",
      "\n",
      "Train Epoch: 392 [0/1649 (0%)]\tLoss: 1.432236\n",
      "\n",
      "Test set: Average loss: 1.6406, Accuracy: 167/412 (41%)\n",
      "\n",
      "Train Epoch: 393 [0/1649 (0%)]\tLoss: 1.569972\n",
      "\n",
      "Test set: Average loss: 1.6928, Accuracy: 169/412 (41%)\n",
      "\n",
      "Train Epoch: 394 [0/1649 (0%)]\tLoss: 1.780335\n",
      "\n",
      "Test set: Average loss: 1.6735, Accuracy: 173/412 (42%)\n",
      "\n",
      "Train Epoch: 395 [0/1649 (0%)]\tLoss: 1.804977\n",
      "\n",
      "Test set: Average loss: 1.6154, Accuracy: 169/412 (41%)\n",
      "\n",
      "Train Epoch: 396 [0/1649 (0%)]\tLoss: 1.743894\n",
      "\n",
      "Test set: Average loss: 1.6256, Accuracy: 169/412 (41%)\n",
      "\n",
      "Train Epoch: 397 [0/1649 (0%)]\tLoss: 1.420406\n",
      "\n",
      "Test set: Average loss: 1.6641, Accuracy: 167/412 (41%)\n",
      "\n",
      "Train Epoch: 398 [0/1649 (0%)]\tLoss: 1.601996\n",
      "\n",
      "Test set: Average loss: 1.7239, Accuracy: 159/412 (39%)\n",
      "\n",
      "Train Epoch: 399 [0/1649 (0%)]\tLoss: 1.886402\n",
      "\n",
      "Test set: Average loss: 1.7758, Accuracy: 150/412 (36%)\n",
      "\n",
      "Train Epoch: 400 [0/1649 (0%)]\tLoss: 1.472350\n",
      "\n",
      "Test set: Average loss: 1.7943, Accuracy: 143/412 (35%)\n",
      "\n",
      "Train Epoch: 401 [0/1649 (0%)]\tLoss: 1.654257\n",
      "\n",
      "Test set: Average loss: 1.7964, Accuracy: 143/412 (35%)\n",
      "\n",
      "Train Epoch: 402 [0/1649 (0%)]\tLoss: 1.768885\n",
      "\n",
      "Test set: Average loss: 1.7964, Accuracy: 146/412 (35%)\n",
      "\n",
      "Train Epoch: 403 [0/1649 (0%)]\tLoss: 1.742979\n",
      "\n",
      "Test set: Average loss: 1.7746, Accuracy: 152/412 (37%)\n",
      "\n",
      "Train Epoch: 404 [0/1649 (0%)]\tLoss: 1.853082\n",
      "\n",
      "Test set: Average loss: 1.7058, Accuracy: 164/412 (40%)\n",
      "\n",
      "Train Epoch: 405 [0/1649 (0%)]\tLoss: 1.536490\n",
      "\n",
      "Test set: Average loss: 1.6566, Accuracy: 167/412 (41%)\n",
      "\n",
      "Train Epoch: 406 [0/1649 (0%)]\tLoss: 1.445991\n",
      "\n",
      "Test set: Average loss: 1.6559, Accuracy: 171/412 (42%)\n",
      "\n",
      "Train Epoch: 407 [0/1649 (0%)]\tLoss: 1.779170\n",
      "\n",
      "Test set: Average loss: 1.6878, Accuracy: 171/412 (42%)\n",
      "\n",
      "Train Epoch: 408 [0/1649 (0%)]\tLoss: 1.928696\n",
      "\n",
      "Test set: Average loss: 1.7408, Accuracy: 166/412 (40%)\n",
      "\n",
      "Train Epoch: 409 [0/1649 (0%)]\tLoss: 1.633286\n",
      "\n",
      "Test set: Average loss: 1.6780, Accuracy: 172/412 (42%)\n",
      "\n",
      "Train Epoch: 410 [0/1649 (0%)]\tLoss: 1.419336\n",
      "\n",
      "Test set: Average loss: 1.6570, Accuracy: 167/412 (41%)\n",
      "\n",
      "Train Epoch: 411 [0/1649 (0%)]\tLoss: 1.888495\n",
      "\n",
      "Test set: Average loss: 1.6373, Accuracy: 169/412 (41%)\n",
      "\n",
      "Train Epoch: 412 [0/1649 (0%)]\tLoss: 1.430304\n",
      "\n",
      "Test set: Average loss: 1.6427, Accuracy: 163/412 (40%)\n",
      "\n",
      "Train Epoch: 413 [0/1649 (0%)]\tLoss: 1.466116\n",
      "\n",
      "Test set: Average loss: 1.6586, Accuracy: 162/412 (39%)\n",
      "\n",
      "Train Epoch: 414 [0/1649 (0%)]\tLoss: 1.640156\n",
      "\n",
      "Test set: Average loss: 1.6786, Accuracy: 161/412 (39%)\n",
      "\n",
      "Train Epoch: 415 [0/1649 (0%)]\tLoss: 1.620469\n",
      "\n",
      "Test set: Average loss: 1.6855, Accuracy: 160/412 (39%)\n",
      "\n",
      "Train Epoch: 416 [0/1649 (0%)]\tLoss: 1.276604\n",
      "\n",
      "Test set: Average loss: 1.6897, Accuracy: 160/412 (39%)\n",
      "\n",
      "Train Epoch: 417 [0/1649 (0%)]\tLoss: 1.643555\n",
      "\n",
      "Test set: Average loss: 1.6823, Accuracy: 162/412 (39%)\n",
      "\n",
      "Train Epoch: 418 [0/1649 (0%)]\tLoss: 1.424209\n",
      "\n",
      "Test set: Average loss: 1.6686, Accuracy: 162/412 (39%)\n",
      "\n",
      "Train Epoch: 419 [0/1649 (0%)]\tLoss: 1.544555\n",
      "\n",
      "Test set: Average loss: 1.6353, Accuracy: 168/412 (41%)\n",
      "\n",
      "Train Epoch: 420 [0/1649 (0%)]\tLoss: 1.456822\n",
      "\n",
      "Test set: Average loss: 1.6125, Accuracy: 172/412 (42%)\n",
      "\n",
      "Train Epoch: 421 [0/1649 (0%)]\tLoss: 1.683105\n",
      "\n",
      "Test set: Average loss: 1.6039, Accuracy: 171/412 (42%)\n",
      "\n",
      "Train Epoch: 422 [0/1649 (0%)]\tLoss: 1.517038\n",
      "\n",
      "Test set: Average loss: 1.6003, Accuracy: 173/412 (42%)\n",
      "\n",
      "Train Epoch: 423 [0/1649 (0%)]\tLoss: 1.545122\n",
      "\n",
      "Test set: Average loss: 1.5981, Accuracy: 174/412 (42%)\n",
      "\n",
      "Train Epoch: 424 [0/1649 (0%)]\tLoss: 1.509175\n",
      "\n",
      "Test set: Average loss: 1.6003, Accuracy: 175/412 (42%)\n",
      "\n",
      "Train Epoch: 425 [0/1649 (0%)]\tLoss: 1.503272\n",
      "\n",
      "Test set: Average loss: 1.6123, Accuracy: 172/412 (42%)\n",
      "\n",
      "Train Epoch: 426 [0/1649 (0%)]\tLoss: 1.610687\n",
      "\n",
      "Test set: Average loss: 1.6315, Accuracy: 170/412 (41%)\n",
      "\n",
      "Train Epoch: 427 [0/1649 (0%)]\tLoss: 1.569869\n",
      "\n",
      "Test set: Average loss: 1.6506, Accuracy: 169/412 (41%)\n",
      "\n",
      "Train Epoch: 428 [0/1649 (0%)]\tLoss: 1.424866\n",
      "\n",
      "Test set: Average loss: 1.6324, Accuracy: 168/412 (41%)\n",
      "\n",
      "Train Epoch: 429 [0/1649 (0%)]\tLoss: 1.615529\n",
      "\n",
      "Test set: Average loss: 1.6114, Accuracy: 171/412 (42%)\n",
      "\n",
      "Train Epoch: 430 [0/1649 (0%)]\tLoss: 1.838115\n",
      "\n",
      "Test set: Average loss: 1.6093, Accuracy: 170/412 (41%)\n",
      "\n",
      "Train Epoch: 431 [0/1649 (0%)]\tLoss: 1.450620\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 1.6241, Accuracy: 167/412 (41%)\n",
      "\n",
      "Train Epoch: 432 [0/1649 (0%)]\tLoss: 1.691857\n",
      "\n",
      "Test set: Average loss: 1.6141, Accuracy: 167/412 (41%)\n",
      "\n",
      "Train Epoch: 433 [0/1649 (0%)]\tLoss: 1.494244\n",
      "\n",
      "Test set: Average loss: 1.6088, Accuracy: 166/412 (40%)\n",
      "\n",
      "Train Epoch: 434 [0/1649 (0%)]\tLoss: 1.475935\n",
      "\n",
      "Test set: Average loss: 1.6116, Accuracy: 164/412 (40%)\n",
      "\n",
      "Train Epoch: 435 [0/1649 (0%)]\tLoss: 1.488417\n",
      "\n",
      "Test set: Average loss: 1.6147, Accuracy: 164/412 (40%)\n",
      "\n",
      "Train Epoch: 436 [0/1649 (0%)]\tLoss: 1.540918\n",
      "\n",
      "Test set: Average loss: 1.6215, Accuracy: 164/412 (40%)\n",
      "\n",
      "Train Epoch: 437 [0/1649 (0%)]\tLoss: 1.638036\n",
      "\n",
      "Test set: Average loss: 1.6199, Accuracy: 167/412 (41%)\n",
      "\n",
      "Train Epoch: 438 [0/1649 (0%)]\tLoss: 1.456524\n",
      "\n",
      "Test set: Average loss: 1.6254, Accuracy: 166/412 (40%)\n",
      "\n",
      "Train Epoch: 439 [0/1649 (0%)]\tLoss: 1.679954\n",
      "\n",
      "Test set: Average loss: 1.6227, Accuracy: 167/412 (41%)\n",
      "\n",
      "Train Epoch: 440 [0/1649 (0%)]\tLoss: 1.651738\n",
      "\n",
      "Test set: Average loss: 1.6257, Accuracy: 169/412 (41%)\n",
      "\n",
      "Train Epoch: 441 [0/1649 (0%)]\tLoss: 1.725278\n",
      "\n",
      "Test set: Average loss: 1.6141, Accuracy: 171/412 (42%)\n",
      "\n",
      "Train Epoch: 442 [0/1649 (0%)]\tLoss: 1.625267\n",
      "\n",
      "Test set: Average loss: 1.5965, Accuracy: 169/412 (41%)\n",
      "\n",
      "Train Epoch: 443 [0/1649 (0%)]\tLoss: 1.941524\n",
      "\n",
      "Test set: Average loss: 1.5944, Accuracy: 170/412 (41%)\n",
      "\n",
      "Train Epoch: 444 [0/1649 (0%)]\tLoss: 1.417255\n",
      "\n",
      "Test set: Average loss: 1.6113, Accuracy: 170/412 (41%)\n",
      "\n",
      "Train Epoch: 445 [0/1649 (0%)]\tLoss: 1.498632\n",
      "\n",
      "Test set: Average loss: 1.6387, Accuracy: 166/412 (40%)\n",
      "\n",
      "Train Epoch: 446 [0/1649 (0%)]\tLoss: 1.694196\n",
      "\n",
      "Test set: Average loss: 1.6810, Accuracy: 163/412 (40%)\n",
      "\n",
      "Train Epoch: 447 [0/1649 (0%)]\tLoss: 1.492141\n",
      "\n",
      "Test set: Average loss: 1.6618, Accuracy: 166/412 (40%)\n",
      "\n",
      "Train Epoch: 448 [0/1649 (0%)]\tLoss: 1.489453\n",
      "\n",
      "Test set: Average loss: 1.6715, Accuracy: 163/412 (40%)\n",
      "\n",
      "Train Epoch: 449 [0/1649 (0%)]\tLoss: 1.764588\n",
      "\n",
      "Test set: Average loss: 1.6855, Accuracy: 160/412 (39%)\n",
      "\n",
      "Train Epoch: 450 [0/1649 (0%)]\tLoss: 1.638388\n",
      "\n",
      "Test set: Average loss: 1.6745, Accuracy: 161/412 (39%)\n",
      "\n",
      "Train Epoch: 451 [0/1649 (0%)]\tLoss: 1.529530\n",
      "\n",
      "Test set: Average loss: 1.6690, Accuracy: 164/412 (40%)\n",
      "\n",
      "Train Epoch: 452 [0/1649 (0%)]\tLoss: 1.739673\n",
      "\n",
      "Test set: Average loss: 1.6725, Accuracy: 162/412 (39%)\n",
      "\n",
      "Train Epoch: 453 [0/1649 (0%)]\tLoss: 1.651224\n",
      "\n",
      "Test set: Average loss: 1.6608, Accuracy: 163/412 (40%)\n",
      "\n",
      "Train Epoch: 454 [0/1649 (0%)]\tLoss: 1.721943\n",
      "\n",
      "Test set: Average loss: 1.6505, Accuracy: 162/412 (39%)\n",
      "\n",
      "Train Epoch: 455 [0/1649 (0%)]\tLoss: 1.751900\n",
      "\n",
      "Test set: Average loss: 1.6464, Accuracy: 163/412 (40%)\n",
      "\n",
      "Train Epoch: 456 [0/1649 (0%)]\tLoss: 1.319699\n",
      "\n",
      "Test set: Average loss: 1.6603, Accuracy: 160/412 (39%)\n",
      "\n",
      "Train Epoch: 457 [0/1649 (0%)]\tLoss: 1.412071\n",
      "\n",
      "Test set: Average loss: 1.6880, Accuracy: 162/412 (39%)\n",
      "\n",
      "Train Epoch: 458 [0/1649 (0%)]\tLoss: 1.584432\n",
      "\n",
      "Test set: Average loss: 1.7002, Accuracy: 162/412 (39%)\n",
      "\n",
      "Train Epoch: 459 [0/1649 (0%)]\tLoss: 1.673315\n",
      "\n",
      "Test set: Average loss: 1.6759, Accuracy: 165/412 (40%)\n",
      "\n",
      "Train Epoch: 460 [0/1649 (0%)]\tLoss: 1.533675\n",
      "\n",
      "Test set: Average loss: 1.6221, Accuracy: 169/412 (41%)\n",
      "\n",
      "Train Epoch: 461 [0/1649 (0%)]\tLoss: 1.556233\n",
      "\n",
      "Test set: Average loss: 1.6482, Accuracy: 167/412 (41%)\n",
      "\n",
      "Train Epoch: 462 [0/1649 (0%)]\tLoss: 1.439313\n",
      "\n",
      "Test set: Average loss: 1.6886, Accuracy: 162/412 (39%)\n",
      "\n",
      "Train Epoch: 463 [0/1649 (0%)]\tLoss: 1.658467\n",
      "\n",
      "Test set: Average loss: 1.6661, Accuracy: 164/412 (40%)\n",
      "\n",
      "Train Epoch: 464 [0/1649 (0%)]\tLoss: 1.535207\n",
      "\n",
      "Test set: Average loss: 1.6364, Accuracy: 167/412 (41%)\n",
      "\n",
      "Train Epoch: 465 [0/1649 (0%)]\tLoss: 1.430931\n",
      "\n",
      "Test set: Average loss: 1.6157, Accuracy: 170/412 (41%)\n",
      "\n",
      "Train Epoch: 466 [0/1649 (0%)]\tLoss: 1.627816\n",
      "\n",
      "Test set: Average loss: 1.6155, Accuracy: 169/412 (41%)\n",
      "\n",
      "Train Epoch: 467 [0/1649 (0%)]\tLoss: 1.604071\n",
      "\n",
      "Test set: Average loss: 1.6181, Accuracy: 171/412 (42%)\n",
      "\n",
      "Train Epoch: 468 [0/1649 (0%)]\tLoss: 1.376375\n",
      "\n",
      "Test set: Average loss: 1.6274, Accuracy: 169/412 (41%)\n",
      "\n",
      "Train Epoch: 469 [0/1649 (0%)]\tLoss: 1.484481\n",
      "\n",
      "Test set: Average loss: 1.6369, Accuracy: 167/412 (41%)\n",
      "\n",
      "Train Epoch: 470 [0/1649 (0%)]\tLoss: 1.547871\n",
      "\n",
      "Test set: Average loss: 1.6214, Accuracy: 171/412 (42%)\n",
      "\n",
      "Train Epoch: 471 [0/1649 (0%)]\tLoss: 1.647214\n",
      "\n",
      "Test set: Average loss: 1.6048, Accuracy: 168/412 (41%)\n",
      "\n",
      "Train Epoch: 472 [0/1649 (0%)]\tLoss: 1.430349\n",
      "\n",
      "Test set: Average loss: 1.5988, Accuracy: 168/412 (41%)\n",
      "\n",
      "Train Epoch: 473 [0/1649 (0%)]\tLoss: 1.388707\n",
      "\n",
      "Test set: Average loss: 1.6019, Accuracy: 169/412 (41%)\n",
      "\n",
      "Train Epoch: 474 [0/1649 (0%)]\tLoss: 1.709520\n",
      "\n",
      "Test set: Average loss: 1.6030, Accuracy: 169/412 (41%)\n",
      "\n",
      "Train Epoch: 475 [0/1649 (0%)]\tLoss: 1.456941\n",
      "\n",
      "Test set: Average loss: 1.6018, Accuracy: 169/412 (41%)\n",
      "\n",
      "Train Epoch: 476 [0/1649 (0%)]\tLoss: 1.741795\n",
      "\n",
      "Test set: Average loss: 1.6066, Accuracy: 167/412 (41%)\n",
      "\n",
      "Train Epoch: 477 [0/1649 (0%)]\tLoss: 1.538492\n",
      "\n",
      "Test set: Average loss: 1.6170, Accuracy: 163/412 (40%)\n",
      "\n",
      "Train Epoch: 478 [0/1649 (0%)]\tLoss: 1.488115\n",
      "\n",
      "Test set: Average loss: 1.6135, Accuracy: 162/412 (39%)\n",
      "\n",
      "Train Epoch: 479 [0/1649 (0%)]\tLoss: 1.414901\n",
      "\n",
      "Test set: Average loss: 1.6083, Accuracy: 163/412 (40%)\n",
      "\n",
      "Train Epoch: 480 [0/1649 (0%)]\tLoss: 1.316379\n",
      "\n",
      "Test set: Average loss: 1.6040, Accuracy: 167/412 (41%)\n",
      "\n",
      "Train Epoch: 481 [0/1649 (0%)]\tLoss: 1.443050\n",
      "\n",
      "Test set: Average loss: 1.6037, Accuracy: 166/412 (40%)\n",
      "\n",
      "Train Epoch: 482 [0/1649 (0%)]\tLoss: 1.650498\n",
      "\n",
      "Test set: Average loss: 1.6001, Accuracy: 167/412 (41%)\n",
      "\n",
      "Train Epoch: 483 [0/1649 (0%)]\tLoss: 1.581681\n",
      "\n",
      "Test set: Average loss: 1.5974, Accuracy: 170/412 (41%)\n",
      "\n",
      "Train Epoch: 484 [0/1649 (0%)]\tLoss: 1.797814\n",
      "\n",
      "Test set: Average loss: 1.5942, Accuracy: 169/412 (41%)\n",
      "\n",
      "Train Epoch: 485 [0/1649 (0%)]\tLoss: 1.721430\n",
      "\n",
      "Test set: Average loss: 1.6000, Accuracy: 170/412 (41%)\n",
      "\n",
      "Train Epoch: 486 [0/1649 (0%)]\tLoss: 1.646951\n",
      "\n",
      "Test set: Average loss: 1.5970, Accuracy: 171/412 (42%)\n",
      "\n",
      "Train Epoch: 487 [0/1649 (0%)]\tLoss: 1.377432\n",
      "\n",
      "Test set: Average loss: 1.5937, Accuracy: 171/412 (42%)\n",
      "\n",
      "Train Epoch: 488 [0/1649 (0%)]\tLoss: 1.484579\n",
      "\n",
      "Test set: Average loss: 1.5911, Accuracy: 174/412 (42%)\n",
      "\n",
      "Train Epoch: 489 [0/1649 (0%)]\tLoss: 1.769749\n",
      "\n",
      "Test set: Average loss: 1.5883, Accuracy: 173/412 (42%)\n",
      "\n",
      "Train Epoch: 490 [0/1649 (0%)]\tLoss: 1.611613\n",
      "\n",
      "Test set: Average loss: 1.5897, Accuracy: 171/412 (42%)\n",
      "\n",
      "Train Epoch: 491 [0/1649 (0%)]\tLoss: 1.744298\n",
      "\n",
      "Test set: Average loss: 1.6003, Accuracy: 165/412 (40%)\n",
      "\n",
      "Train Epoch: 492 [0/1649 (0%)]\tLoss: 1.387251\n",
      "\n",
      "Test set: Average loss: 1.6252, Accuracy: 162/412 (39%)\n",
      "\n",
      "Train Epoch: 493 [0/1649 (0%)]\tLoss: 1.656032\n",
      "\n",
      "Test set: Average loss: 1.6454, Accuracy: 163/412 (40%)\n",
      "\n",
      "Train Epoch: 494 [0/1649 (0%)]\tLoss: 1.518603\n",
      "\n",
      "Test set: Average loss: 1.6646, Accuracy: 164/412 (40%)\n",
      "\n",
      "Train Epoch: 495 [0/1649 (0%)]\tLoss: 1.503434\n",
      "\n",
      "Test set: Average loss: 1.6507, Accuracy: 164/412 (40%)\n",
      "\n",
      "Train Epoch: 496 [0/1649 (0%)]\tLoss: 1.765748\n",
      "\n",
      "Test set: Average loss: 1.6279, Accuracy: 163/412 (40%)\n",
      "\n",
      "Train Epoch: 497 [0/1649 (0%)]\tLoss: 1.416003\n",
      "\n",
      "Test set: Average loss: 1.6152, Accuracy: 164/412 (40%)\n",
      "\n",
      "Train Epoch: 498 [0/1649 (0%)]\tLoss: 1.555739\n",
      "\n",
      "Test set: Average loss: 1.6208, Accuracy: 166/412 (40%)\n",
      "\n",
      "Train Epoch: 499 [0/1649 (0%)]\tLoss: 1.610731\n",
      "\n",
      "Test set: Average loss: 1.6246, Accuracy: 167/412 (41%)\n",
      "\n",
      "max acc :  42.71844660194175\n",
      "Used Seed:  1042\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "epoch_arr = range(500)\n",
    "train_loss = []\n",
    "test_loss = []\n",
    "max_test = 0\n",
    "\n",
    "#Entrainement\n",
    "for epoch in epoch_arr:\n",
    "    train_loss.append( train(model, dataloader_train, optimizer, epoch, F.nll_loss))\n",
    "    loss,test_prc = test(model, dataloader_test)\n",
    "    if test_prc > max_test:\n",
    "        max_test = test_prc\n",
    "        torch.save(model.state_dict(), './best.pth')\n",
    "    test_loss.append( loss )\n",
    "print(\"max acc : \",max_test)\n",
    "print(\"Used Seed: \", manualSeed)\n",
    "#Affichage des courbes de loss\n",
    "plt.plot(epoch_arr,train_loss,'b')\n",
    "plt.plot(epoch_arr,test_loss,'g')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Les résultats sont très peu concluant, on peut maintenant esasyer avec un réseau à convolution que l'on termine avec 2 couches full connected.\n",
    "\n",
    "## Réseau à convolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 64, 5, 1)\n",
    "        self.conv2 = nn.Conv2d(64, 128, 5, 1)\n",
    "        self.fc1 = nn.Linear(5*5*128, 1000)\n",
    "        self.fc2 = nn.Linear(1000, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x= self.conv1(x)\n",
    "        x = F.relu(x)\n",
    "        x = F.max_pool2d(x, 2, 2)\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = F.max_pool2d(x, 2, 2)\n",
    "        x = x.view(-1, 5*5*128)#Modification de la forme des donneés pour les faire rentrer dans les couches full connected\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.dropout(x, training=self.training) #Utilisation de dropout pour ajouter de l'aléatoire à l'entraienement\n",
    "        x = self.fc2(x)\n",
    "        return F.log_softmax(x, dim=1)\n",
    "criterion = nn.NLLLoss()\n",
    "model = Net().to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.003)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 0 [0/1649 (0%)]\tLoss: 2.302971\n",
      "\n",
      "Test set: Average loss: 5.0488, Accuracy: 56/412 (14%)\n",
      "\n",
      "Train Epoch: 1 [0/1649 (0%)]\tLoss: 5.151642\n",
      "\n",
      "Test set: Average loss: 2.5290, Accuracy: 45/412 (11%)\n",
      "\n",
      "Train Epoch: 2 [0/1649 (0%)]\tLoss: 2.584954\n",
      "\n",
      "Test set: Average loss: 2.3014, Accuracy: 43/412 (10%)\n",
      "\n",
      "Train Epoch: 3 [0/1649 (0%)]\tLoss: 2.297661\n",
      "\n",
      "Test set: Average loss: 2.2974, Accuracy: 43/412 (10%)\n",
      "\n",
      "Train Epoch: 4 [0/1649 (0%)]\tLoss: 2.317924\n",
      "\n",
      "Test set: Average loss: 2.2946, Accuracy: 56/412 (14%)\n",
      "\n",
      "Train Epoch: 5 [0/1649 (0%)]\tLoss: 2.295610\n",
      "\n",
      "Test set: Average loss: 2.2911, Accuracy: 50/412 (12%)\n",
      "\n",
      "Train Epoch: 6 [0/1649 (0%)]\tLoss: 2.290485\n",
      "\n",
      "Test set: Average loss: 2.2846, Accuracy: 39/412 (9%)\n",
      "\n",
      "Train Epoch: 7 [0/1649 (0%)]\tLoss: 2.299479\n",
      "\n",
      "Test set: Average loss: 2.2782, Accuracy: 39/412 (9%)\n",
      "\n",
      "Train Epoch: 8 [0/1649 (0%)]\tLoss: 2.277762\n",
      "\n",
      "Test set: Average loss: 2.2705, Accuracy: 68/412 (17%)\n",
      "\n",
      "Train Epoch: 9 [0/1649 (0%)]\tLoss: 2.279187\n",
      "\n",
      "Test set: Average loss: 2.2572, Accuracy: 85/412 (21%)\n",
      "\n",
      "Train Epoch: 10 [0/1649 (0%)]\tLoss: 2.248752\n",
      "\n",
      "Test set: Average loss: 2.2307, Accuracy: 84/412 (20%)\n",
      "\n",
      "Train Epoch: 11 [0/1649 (0%)]\tLoss: 2.243216\n",
      "\n",
      "Test set: Average loss: 2.2026, Accuracy: 96/412 (23%)\n",
      "\n",
      "Train Epoch: 12 [0/1649 (0%)]\tLoss: 2.202291\n",
      "\n",
      "Test set: Average loss: 2.1709, Accuracy: 102/412 (25%)\n",
      "\n",
      "Train Epoch: 13 [0/1649 (0%)]\tLoss: 2.137134\n",
      "\n",
      "Test set: Average loss: 2.1200, Accuracy: 113/412 (27%)\n",
      "\n",
      "Train Epoch: 14 [0/1649 (0%)]\tLoss: 2.167662\n",
      "\n",
      "Test set: Average loss: 2.0608, Accuracy: 113/412 (27%)\n",
      "\n",
      "Train Epoch: 15 [0/1649 (0%)]\tLoss: 2.114011\n",
      "\n",
      "Test set: Average loss: 1.9916, Accuracy: 132/412 (32%)\n",
      "\n",
      "Train Epoch: 16 [0/1649 (0%)]\tLoss: 1.956093\n",
      "\n",
      "Test set: Average loss: 1.9309, Accuracy: 132/412 (32%)\n",
      "\n",
      "Train Epoch: 17 [0/1649 (0%)]\tLoss: 1.929055\n",
      "\n",
      "Test set: Average loss: 1.8479, Accuracy: 165/412 (40%)\n",
      "\n",
      "Train Epoch: 18 [0/1649 (0%)]\tLoss: 1.764270\n",
      "\n",
      "Test set: Average loss: 1.7359, Accuracy: 209/412 (51%)\n",
      "\n",
      "Train Epoch: 19 [0/1649 (0%)]\tLoss: 1.687981\n",
      "\n",
      "Test set: Average loss: 1.6580, Accuracy: 200/412 (49%)\n",
      "\n",
      "Train Epoch: 20 [0/1649 (0%)]\tLoss: 1.668743\n",
      "\n",
      "Test set: Average loss: 1.5582, Accuracy: 234/412 (57%)\n",
      "\n",
      "Train Epoch: 21 [0/1649 (0%)]\tLoss: 1.737566\n",
      "\n",
      "Test set: Average loss: 1.4985, Accuracy: 206/412 (50%)\n",
      "\n",
      "Train Epoch: 22 [0/1649 (0%)]\tLoss: 1.606579\n",
      "\n",
      "Test set: Average loss: 1.4319, Accuracy: 221/412 (54%)\n",
      "\n",
      "Train Epoch: 23 [0/1649 (0%)]\tLoss: 1.429601\n",
      "\n",
      "Test set: Average loss: 1.3549, Accuracy: 229/412 (56%)\n",
      "\n",
      "Train Epoch: 24 [0/1649 (0%)]\tLoss: 1.398524\n",
      "\n",
      "Test set: Average loss: 1.2856, Accuracy: 236/412 (57%)\n",
      "\n",
      "Train Epoch: 25 [0/1649 (0%)]\tLoss: 1.714290\n",
      "\n",
      "Test set: Average loss: 1.2619, Accuracy: 232/412 (56%)\n",
      "\n",
      "Train Epoch: 26 [0/1649 (0%)]\tLoss: 1.356151\n",
      "\n",
      "Test set: Average loss: 1.2107, Accuracy: 250/412 (61%)\n",
      "\n",
      "Train Epoch: 27 [0/1649 (0%)]\tLoss: 1.218458\n",
      "\n",
      "Test set: Average loss: 1.2092, Accuracy: 254/412 (62%)\n",
      "\n",
      "Train Epoch: 28 [0/1649 (0%)]\tLoss: 1.513976\n",
      "\n",
      "Test set: Average loss: 1.1640, Accuracy: 251/412 (61%)\n",
      "\n",
      "Train Epoch: 29 [0/1649 (0%)]\tLoss: 1.106907\n",
      "\n",
      "Test set: Average loss: 1.1893, Accuracy: 236/412 (57%)\n",
      "\n",
      "Train Epoch: 30 [0/1649 (0%)]\tLoss: 1.292995\n",
      "\n",
      "Test set: Average loss: 1.0930, Accuracy: 261/412 (63%)\n",
      "\n",
      "Train Epoch: 31 [0/1649 (0%)]\tLoss: 1.355521\n",
      "\n",
      "Test set: Average loss: 0.9830, Accuracy: 289/412 (70%)\n",
      "\n",
      "Train Epoch: 32 [0/1649 (0%)]\tLoss: 0.954222\n",
      "\n",
      "Test set: Average loss: 0.9861, Accuracy: 282/412 (68%)\n",
      "\n",
      "Train Epoch: 33 [0/1649 (0%)]\tLoss: 1.184333\n",
      "\n",
      "Test set: Average loss: 0.9847, Accuracy: 274/412 (67%)\n",
      "\n",
      "Train Epoch: 34 [0/1649 (0%)]\tLoss: 1.042844\n",
      "\n",
      "Test set: Average loss: 0.9544, Accuracy: 277/412 (67%)\n",
      "\n",
      "Train Epoch: 35 [0/1649 (0%)]\tLoss: 1.012511\n",
      "\n",
      "Test set: Average loss: 0.9282, Accuracy: 282/412 (68%)\n",
      "\n",
      "Train Epoch: 36 [0/1649 (0%)]\tLoss: 1.305490\n",
      "\n",
      "Test set: Average loss: 0.8952, Accuracy: 287/412 (70%)\n",
      "\n",
      "Train Epoch: 37 [0/1649 (0%)]\tLoss: 0.898488\n",
      "\n",
      "Test set: Average loss: 0.9641, Accuracy: 275/412 (67%)\n",
      "\n",
      "Train Epoch: 38 [0/1649 (0%)]\tLoss: 0.982261\n",
      "\n",
      "Test set: Average loss: 0.9933, Accuracy: 271/412 (66%)\n",
      "\n",
      "Train Epoch: 39 [0/1649 (0%)]\tLoss: 0.801206\n",
      "\n",
      "Test set: Average loss: 0.9879, Accuracy: 256/412 (62%)\n",
      "\n",
      "Train Epoch: 40 [0/1649 (0%)]\tLoss: 0.806516\n",
      "\n",
      "Test set: Average loss: 0.9373, Accuracy: 271/412 (66%)\n",
      "\n",
      "Train Epoch: 41 [0/1649 (0%)]\tLoss: 0.759108\n",
      "\n",
      "Test set: Average loss: 0.8844, Accuracy: 295/412 (72%)\n",
      "\n",
      "Train Epoch: 42 [0/1649 (0%)]\tLoss: 0.992749\n",
      "\n",
      "Test set: Average loss: 0.8380, Accuracy: 291/412 (71%)\n",
      "\n",
      "Train Epoch: 43 [0/1649 (0%)]\tLoss: 1.402300\n",
      "\n",
      "Test set: Average loss: 0.7645, Accuracy: 304/412 (74%)\n",
      "\n",
      "Train Epoch: 44 [0/1649 (0%)]\tLoss: 0.608269\n",
      "\n",
      "Test set: Average loss: 0.7620, Accuracy: 304/412 (74%)\n",
      "\n",
      "Train Epoch: 45 [0/1649 (0%)]\tLoss: 0.709033\n",
      "\n",
      "Test set: Average loss: 0.7487, Accuracy: 303/412 (74%)\n",
      "\n",
      "Train Epoch: 46 [0/1649 (0%)]\tLoss: 1.015233\n",
      "\n",
      "Test set: Average loss: 0.7359, Accuracy: 301/412 (73%)\n",
      "\n",
      "Train Epoch: 47 [0/1649 (0%)]\tLoss: 0.988238\n",
      "\n",
      "Test set: Average loss: 0.7728, Accuracy: 302/412 (73%)\n",
      "\n",
      "Train Epoch: 48 [0/1649 (0%)]\tLoss: 0.999895\n",
      "\n",
      "Test set: Average loss: 0.7395, Accuracy: 309/412 (75%)\n",
      "\n",
      "Train Epoch: 49 [0/1649 (0%)]\tLoss: 0.768326\n",
      "\n",
      "Test set: Average loss: 0.6911, Accuracy: 318/412 (77%)\n",
      "\n",
      "Train Epoch: 50 [0/1649 (0%)]\tLoss: 0.683068\n",
      "\n",
      "Test set: Average loss: 0.6876, Accuracy: 315/412 (76%)\n",
      "\n",
      "Train Epoch: 51 [0/1649 (0%)]\tLoss: 0.858561\n",
      "\n",
      "Test set: Average loss: 0.7456, Accuracy: 308/412 (75%)\n",
      "\n",
      "Train Epoch: 52 [0/1649 (0%)]\tLoss: 0.767149\n",
      "\n",
      "Test set: Average loss: 0.7723, Accuracy: 302/412 (73%)\n",
      "\n",
      "Train Epoch: 53 [0/1649 (0%)]\tLoss: 0.816810\n",
      "\n",
      "Test set: Average loss: 0.7452, Accuracy: 309/412 (75%)\n",
      "\n",
      "Train Epoch: 54 [0/1649 (0%)]\tLoss: 0.942535\n",
      "\n",
      "Test set: Average loss: 0.7170, Accuracy: 318/412 (77%)\n",
      "\n",
      "Train Epoch: 55 [0/1649 (0%)]\tLoss: 0.662158\n",
      "\n",
      "Test set: Average loss: 0.7131, Accuracy: 319/412 (77%)\n",
      "\n",
      "Train Epoch: 56 [0/1649 (0%)]\tLoss: 0.544089\n",
      "\n",
      "Test set: Average loss: 0.7083, Accuracy: 321/412 (78%)\n",
      "\n",
      "Train Epoch: 57 [0/1649 (0%)]\tLoss: 0.852060\n",
      "\n",
      "Test set: Average loss: 0.6790, Accuracy: 322/412 (78%)\n",
      "\n",
      "Train Epoch: 58 [0/1649 (0%)]\tLoss: 0.598746\n",
      "\n",
      "Test set: Average loss: 0.6480, Accuracy: 325/412 (79%)\n",
      "\n",
      "Train Epoch: 59 [0/1649 (0%)]\tLoss: 0.693651\n",
      "\n",
      "Test set: Average loss: 0.6189, Accuracy: 332/412 (81%)\n",
      "\n",
      "Train Epoch: 60 [0/1649 (0%)]\tLoss: 0.736920\n",
      "\n",
      "Test set: Average loss: 0.5843, Accuracy: 335/412 (81%)\n",
      "\n",
      "Train Epoch: 61 [0/1649 (0%)]\tLoss: 0.711672\n",
      "\n",
      "Test set: Average loss: 0.5426, Accuracy: 341/412 (83%)\n",
      "\n",
      "Train Epoch: 62 [0/1649 (0%)]\tLoss: 0.497130\n",
      "\n",
      "Test set: Average loss: 0.5345, Accuracy: 343/412 (83%)\n",
      "\n",
      "Train Epoch: 63 [0/1649 (0%)]\tLoss: 0.645975\n",
      "\n",
      "Test set: Average loss: 0.5157, Accuracy: 345/412 (84%)\n",
      "\n",
      "Train Epoch: 64 [0/1649 (0%)]\tLoss: 0.384365\n",
      "\n",
      "Test set: Average loss: 0.5020, Accuracy: 341/412 (83%)\n",
      "\n",
      "Train Epoch: 65 [0/1649 (0%)]\tLoss: 0.408817\n",
      "\n",
      "Test set: Average loss: 0.5122, Accuracy: 342/412 (83%)\n",
      "\n",
      "Train Epoch: 66 [0/1649 (0%)]\tLoss: 0.655179\n",
      "\n",
      "Test set: Average loss: 0.5163, Accuracy: 342/412 (83%)\n",
      "\n",
      "Train Epoch: 67 [0/1649 (0%)]\tLoss: 0.677274\n",
      "\n",
      "Test set: Average loss: 0.5135, Accuracy: 345/412 (84%)\n",
      "\n",
      "Train Epoch: 68 [0/1649 (0%)]\tLoss: 0.582845\n",
      "\n",
      "Test set: Average loss: 0.5381, Accuracy: 345/412 (84%)\n",
      "\n",
      "Train Epoch: 69 [0/1649 (0%)]\tLoss: 0.298935\n",
      "\n",
      "Test set: Average loss: 0.5623, Accuracy: 335/412 (81%)\n",
      "\n",
      "Train Epoch: 70 [0/1649 (0%)]\tLoss: 0.549074\n",
      "\n",
      "Test set: Average loss: 0.5596, Accuracy: 338/412 (82%)\n",
      "\n",
      "Train Epoch: 71 [0/1649 (0%)]\tLoss: 0.567872\n",
      "\n",
      "Test set: Average loss: 0.5390, Accuracy: 342/412 (83%)\n",
      "\n",
      "Train Epoch: 72 [0/1649 (0%)]\tLoss: 0.735878\n",
      "\n",
      "Test set: Average loss: 0.5163, Accuracy: 343/412 (83%)\n",
      "\n",
      "Train Epoch: 73 [0/1649 (0%)]\tLoss: 0.614909\n",
      "\n",
      "Test set: Average loss: 0.5030, Accuracy: 346/412 (84%)\n",
      "\n",
      "Train Epoch: 74 [0/1649 (0%)]\tLoss: 0.334949\n",
      "\n",
      "Test set: Average loss: 0.5065, Accuracy: 346/412 (84%)\n",
      "\n",
      "Train Epoch: 75 [0/1649 (0%)]\tLoss: 0.334187\n",
      "\n",
      "Test set: Average loss: 0.5113, Accuracy: 347/412 (84%)\n",
      "\n",
      "Train Epoch: 76 [0/1649 (0%)]\tLoss: 0.717782\n",
      "\n",
      "Test set: Average loss: 0.4970, Accuracy: 343/412 (83%)\n",
      "\n",
      "Train Epoch: 77 [0/1649 (0%)]\tLoss: 0.570672\n",
      "\n",
      "Test set: Average loss: 0.4922, Accuracy: 342/412 (83%)\n",
      "\n",
      "Train Epoch: 78 [0/1649 (0%)]\tLoss: 0.584726\n",
      "\n",
      "Test set: Average loss: 0.4795, Accuracy: 348/412 (84%)\n",
      "\n",
      "Train Epoch: 79 [0/1649 (0%)]\tLoss: 0.539766\n",
      "\n",
      "Test set: Average loss: 0.4547, Accuracy: 351/412 (85%)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 80 [0/1649 (0%)]\tLoss: 0.335649\n",
      "\n",
      "Test set: Average loss: 0.4573, Accuracy: 348/412 (84%)\n",
      "\n",
      "Train Epoch: 81 [0/1649 (0%)]\tLoss: 0.225585\n",
      "\n",
      "Test set: Average loss: 0.4873, Accuracy: 342/412 (83%)\n",
      "\n",
      "Train Epoch: 82 [0/1649 (0%)]\tLoss: 0.582461\n",
      "\n",
      "Test set: Average loss: 0.5300, Accuracy: 342/412 (83%)\n",
      "\n",
      "Train Epoch: 83 [0/1649 (0%)]\tLoss: 0.376702\n",
      "\n",
      "Test set: Average loss: 0.5120, Accuracy: 344/412 (83%)\n",
      "\n",
      "Train Epoch: 84 [0/1649 (0%)]\tLoss: 0.824355\n",
      "\n",
      "Test set: Average loss: 0.4999, Accuracy: 347/412 (84%)\n",
      "\n",
      "Train Epoch: 85 [0/1649 (0%)]\tLoss: 0.539483\n",
      "\n",
      "Test set: Average loss: 0.4803, Accuracy: 348/412 (84%)\n",
      "\n",
      "Train Epoch: 86 [0/1649 (0%)]\tLoss: 0.373666\n",
      "\n",
      "Test set: Average loss: 0.5102, Accuracy: 341/412 (83%)\n",
      "\n",
      "Train Epoch: 87 [0/1649 (0%)]\tLoss: 0.382459\n",
      "\n",
      "Test set: Average loss: 0.5325, Accuracy: 338/412 (82%)\n",
      "\n",
      "Train Epoch: 88 [0/1649 (0%)]\tLoss: 0.548779\n",
      "\n",
      "Test set: Average loss: 0.5207, Accuracy: 341/412 (83%)\n",
      "\n",
      "Train Epoch: 89 [0/1649 (0%)]\tLoss: 0.422551\n",
      "\n",
      "Test set: Average loss: 0.5134, Accuracy: 343/412 (83%)\n",
      "\n",
      "Train Epoch: 90 [0/1649 (0%)]\tLoss: 0.564393\n",
      "\n",
      "Test set: Average loss: 0.5056, Accuracy: 346/412 (84%)\n",
      "\n",
      "Train Epoch: 91 [0/1649 (0%)]\tLoss: 0.321882\n",
      "\n",
      "Test set: Average loss: 0.4880, Accuracy: 343/412 (83%)\n",
      "\n",
      "Train Epoch: 92 [0/1649 (0%)]\tLoss: 0.335696\n",
      "\n",
      "Test set: Average loss: 0.4680, Accuracy: 343/412 (83%)\n",
      "\n",
      "Train Epoch: 93 [0/1649 (0%)]\tLoss: 0.320333\n",
      "\n",
      "Test set: Average loss: 0.4504, Accuracy: 348/412 (84%)\n",
      "\n",
      "Train Epoch: 94 [0/1649 (0%)]\tLoss: 0.354457\n",
      "\n",
      "Test set: Average loss: 0.4292, Accuracy: 352/412 (85%)\n",
      "\n",
      "Train Epoch: 95 [0/1649 (0%)]\tLoss: 0.373553\n",
      "\n",
      "Test set: Average loss: 0.4112, Accuracy: 352/412 (85%)\n",
      "\n",
      "Train Epoch: 96 [0/1649 (0%)]\tLoss: 0.432870\n",
      "\n",
      "Test set: Average loss: 0.4018, Accuracy: 348/412 (84%)\n",
      "\n",
      "Train Epoch: 97 [0/1649 (0%)]\tLoss: 0.422775\n",
      "\n",
      "Test set: Average loss: 0.4055, Accuracy: 351/412 (85%)\n",
      "\n",
      "Train Epoch: 98 [0/1649 (0%)]\tLoss: 0.356177\n",
      "\n",
      "Test set: Average loss: 0.4276, Accuracy: 353/412 (86%)\n",
      "\n",
      "Train Epoch: 99 [0/1649 (0%)]\tLoss: 0.290294\n",
      "\n",
      "Test set: Average loss: 0.4321, Accuracy: 355/412 (86%)\n",
      "\n",
      "Train Epoch: 100 [0/1649 (0%)]\tLoss: 0.507003\n",
      "\n",
      "Test set: Average loss: 0.4230, Accuracy: 356/412 (86%)\n",
      "\n",
      "Train Epoch: 101 [0/1649 (0%)]\tLoss: 0.293209\n",
      "\n",
      "Test set: Average loss: 0.4083, Accuracy: 357/412 (87%)\n",
      "\n",
      "Train Epoch: 102 [0/1649 (0%)]\tLoss: 0.433535\n",
      "\n",
      "Test set: Average loss: 0.3999, Accuracy: 354/412 (86%)\n",
      "\n",
      "Train Epoch: 103 [0/1649 (0%)]\tLoss: 0.240225\n",
      "\n",
      "Test set: Average loss: 0.3995, Accuracy: 354/412 (86%)\n",
      "\n",
      "Train Epoch: 104 [0/1649 (0%)]\tLoss: 0.578293\n",
      "\n",
      "Test set: Average loss: 0.3857, Accuracy: 355/412 (86%)\n",
      "\n",
      "Train Epoch: 105 [0/1649 (0%)]\tLoss: 0.393557\n",
      "\n",
      "Test set: Average loss: 0.3791, Accuracy: 360/412 (87%)\n",
      "\n",
      "Train Epoch: 106 [0/1649 (0%)]\tLoss: 0.280256\n",
      "\n",
      "Test set: Average loss: 0.3784, Accuracy: 360/412 (87%)\n",
      "\n",
      "Train Epoch: 107 [0/1649 (0%)]\tLoss: 0.462531\n",
      "\n",
      "Test set: Average loss: 0.3749, Accuracy: 361/412 (88%)\n",
      "\n",
      "Train Epoch: 108 [0/1649 (0%)]\tLoss: 0.559489\n",
      "\n",
      "Test set: Average loss: 0.3730, Accuracy: 360/412 (87%)\n",
      "\n",
      "Train Epoch: 109 [0/1649 (0%)]\tLoss: 0.209548\n",
      "\n",
      "Test set: Average loss: 0.3827, Accuracy: 358/412 (87%)\n",
      "\n",
      "Train Epoch: 110 [0/1649 (0%)]\tLoss: 0.325294\n",
      "\n",
      "Test set: Average loss: 0.3852, Accuracy: 357/412 (87%)\n",
      "\n",
      "Train Epoch: 111 [0/1649 (0%)]\tLoss: 0.351049\n",
      "\n",
      "Test set: Average loss: 0.3909, Accuracy: 356/412 (86%)\n",
      "\n",
      "Train Epoch: 112 [0/1649 (0%)]\tLoss: 0.205598\n",
      "\n",
      "Test set: Average loss: 0.3897, Accuracy: 358/412 (87%)\n",
      "\n",
      "Train Epoch: 113 [0/1649 (0%)]\tLoss: 0.284488\n",
      "\n",
      "Test set: Average loss: 0.3965, Accuracy: 359/412 (87%)\n",
      "\n",
      "Train Epoch: 114 [0/1649 (0%)]\tLoss: 0.407270\n",
      "\n",
      "Test set: Average loss: 0.3882, Accuracy: 360/412 (87%)\n",
      "\n",
      "Train Epoch: 115 [0/1649 (0%)]\tLoss: 0.381160\n",
      "\n",
      "Test set: Average loss: 0.3822, Accuracy: 360/412 (87%)\n",
      "\n",
      "Train Epoch: 116 [0/1649 (0%)]\tLoss: 0.354502\n",
      "\n",
      "Test set: Average loss: 0.3699, Accuracy: 360/412 (87%)\n",
      "\n",
      "Train Epoch: 117 [0/1649 (0%)]\tLoss: 0.195460\n",
      "\n",
      "Test set: Average loss: 0.3620, Accuracy: 365/412 (89%)\n",
      "\n",
      "Train Epoch: 118 [0/1649 (0%)]\tLoss: 0.394630\n",
      "\n",
      "Test set: Average loss: 0.3553, Accuracy: 365/412 (89%)\n",
      "\n",
      "Train Epoch: 119 [0/1649 (0%)]\tLoss: 0.388886\n",
      "\n",
      "Test set: Average loss: 0.3537, Accuracy: 363/412 (88%)\n",
      "\n",
      "Train Epoch: 120 [0/1649 (0%)]\tLoss: 0.274505\n",
      "\n",
      "Test set: Average loss: 0.3468, Accuracy: 361/412 (88%)\n",
      "\n",
      "Train Epoch: 121 [0/1649 (0%)]\tLoss: 0.369601\n",
      "\n",
      "Test set: Average loss: 0.3464, Accuracy: 363/412 (88%)\n",
      "\n",
      "Train Epoch: 122 [0/1649 (0%)]\tLoss: 0.207061\n",
      "\n",
      "Test set: Average loss: 0.3416, Accuracy: 362/412 (88%)\n",
      "\n",
      "Train Epoch: 123 [0/1649 (0%)]\tLoss: 0.357894\n",
      "\n",
      "Test set: Average loss: 0.3321, Accuracy: 365/412 (89%)\n",
      "\n",
      "Train Epoch: 124 [0/1649 (0%)]\tLoss: 0.519498\n",
      "\n",
      "Test set: Average loss: 0.3201, Accuracy: 366/412 (89%)\n",
      "\n",
      "Train Epoch: 125 [0/1649 (0%)]\tLoss: 0.136778\n",
      "\n",
      "Test set: Average loss: 0.3054, Accuracy: 368/412 (89%)\n",
      "\n",
      "Train Epoch: 126 [0/1649 (0%)]\tLoss: 0.172514\n",
      "\n",
      "Test set: Average loss: 0.2911, Accuracy: 370/412 (90%)\n",
      "\n",
      "Train Epoch: 127 [0/1649 (0%)]\tLoss: 0.359881\n",
      "\n",
      "Test set: Average loss: 0.2803, Accuracy: 367/412 (89%)\n",
      "\n",
      "Train Epoch: 128 [0/1649 (0%)]\tLoss: 0.327845\n",
      "\n",
      "Test set: Average loss: 0.2922, Accuracy: 366/412 (89%)\n",
      "\n",
      "Train Epoch: 129 [0/1649 (0%)]\tLoss: 0.202467\n",
      "\n",
      "Test set: Average loss: 0.2998, Accuracy: 368/412 (89%)\n",
      "\n",
      "Train Epoch: 130 [0/1649 (0%)]\tLoss: 0.120117\n",
      "\n",
      "Test set: Average loss: 0.3125, Accuracy: 368/412 (89%)\n",
      "\n",
      "Train Epoch: 131 [0/1649 (0%)]\tLoss: 0.256764\n",
      "\n",
      "Test set: Average loss: 0.3203, Accuracy: 365/412 (89%)\n",
      "\n",
      "Train Epoch: 132 [0/1649 (0%)]\tLoss: 0.333353\n",
      "\n",
      "Test set: Average loss: 0.3203, Accuracy: 367/412 (89%)\n",
      "\n",
      "Train Epoch: 133 [0/1649 (0%)]\tLoss: 0.196961\n",
      "\n",
      "Test set: Average loss: 0.3271, Accuracy: 369/412 (90%)\n",
      "\n",
      "Train Epoch: 134 [0/1649 (0%)]\tLoss: 0.197216\n",
      "\n",
      "Test set: Average loss: 0.3359, Accuracy: 370/412 (90%)\n",
      "\n",
      "Train Epoch: 135 [0/1649 (0%)]\tLoss: 0.255148\n",
      "\n",
      "Test set: Average loss: 0.3494, Accuracy: 368/412 (89%)\n",
      "\n",
      "Train Epoch: 136 [0/1649 (0%)]\tLoss: 0.324225\n",
      "\n",
      "Test set: Average loss: 0.3514, Accuracy: 364/412 (88%)\n",
      "\n",
      "Train Epoch: 137 [0/1649 (0%)]\tLoss: 0.338731\n",
      "\n",
      "Test set: Average loss: 0.3573, Accuracy: 364/412 (88%)\n",
      "\n",
      "Train Epoch: 138 [0/1649 (0%)]\tLoss: 0.189097\n",
      "\n",
      "Test set: Average loss: 0.3587, Accuracy: 361/412 (88%)\n",
      "\n",
      "Train Epoch: 139 [0/1649 (0%)]\tLoss: 0.179359\n",
      "\n",
      "Test set: Average loss: 0.3647, Accuracy: 360/412 (87%)\n",
      "\n",
      "Train Epoch: 140 [0/1649 (0%)]\tLoss: 0.191008\n",
      "\n",
      "Test set: Average loss: 0.3645, Accuracy: 366/412 (89%)\n",
      "\n",
      "Train Epoch: 141 [0/1649 (0%)]\tLoss: 0.167879\n",
      "\n",
      "Test set: Average loss: 0.3474, Accuracy: 370/412 (90%)\n",
      "\n",
      "Train Epoch: 142 [0/1649 (0%)]\tLoss: 0.244601\n",
      "\n",
      "Test set: Average loss: 0.3308, Accuracy: 370/412 (90%)\n",
      "\n",
      "Train Epoch: 143 [0/1649 (0%)]\tLoss: 0.120023\n",
      "\n",
      "Test set: Average loss: 0.3201, Accuracy: 370/412 (90%)\n",
      "\n",
      "Train Epoch: 144 [0/1649 (0%)]\tLoss: 0.189917\n",
      "\n",
      "Test set: Average loss: 0.3160, Accuracy: 367/412 (89%)\n",
      "\n",
      "Train Epoch: 145 [0/1649 (0%)]\tLoss: 0.162366\n",
      "\n",
      "Test set: Average loss: 0.3101, Accuracy: 370/412 (90%)\n",
      "\n",
      "Train Epoch: 146 [0/1649 (0%)]\tLoss: 0.253019\n",
      "\n",
      "Test set: Average loss: 0.3081, Accuracy: 368/412 (89%)\n",
      "\n",
      "Train Epoch: 147 [0/1649 (0%)]\tLoss: 0.187549\n",
      "\n",
      "Test set: Average loss: 0.3062, Accuracy: 372/412 (90%)\n",
      "\n",
      "Train Epoch: 148 [0/1649 (0%)]\tLoss: 0.323227\n",
      "\n",
      "Test set: Average loss: 0.2908, Accuracy: 372/412 (90%)\n",
      "\n",
      "Train Epoch: 149 [0/1649 (0%)]\tLoss: 0.207447\n",
      "\n",
      "Test set: Average loss: 0.2809, Accuracy: 374/412 (91%)\n",
      "\n",
      "Train Epoch: 150 [0/1649 (0%)]\tLoss: 0.072350\n",
      "\n",
      "Test set: Average loss: 0.2793, Accuracy: 373/412 (91%)\n",
      "\n",
      "Train Epoch: 151 [0/1649 (0%)]\tLoss: 0.412484\n",
      "\n",
      "Test set: Average loss: 0.2664, Accuracy: 377/412 (92%)\n",
      "\n",
      "Train Epoch: 152 [0/1649 (0%)]\tLoss: 0.216246\n",
      "\n",
      "Test set: Average loss: 0.2588, Accuracy: 377/412 (92%)\n",
      "\n",
      "Train Epoch: 153 [0/1649 (0%)]\tLoss: 0.269751\n",
      "\n",
      "Test set: Average loss: 0.2571, Accuracy: 376/412 (91%)\n",
      "\n",
      "Train Epoch: 154 [0/1649 (0%)]\tLoss: 0.170831\n",
      "\n",
      "Test set: Average loss: 0.2581, Accuracy: 373/412 (91%)\n",
      "\n",
      "Train Epoch: 155 [0/1649 (0%)]\tLoss: 0.145936\n",
      "\n",
      "Test set: Average loss: 0.2616, Accuracy: 374/412 (91%)\n",
      "\n",
      "Train Epoch: 156 [0/1649 (0%)]\tLoss: 0.121013\n",
      "\n",
      "Test set: Average loss: 0.2628, Accuracy: 373/412 (91%)\n",
      "\n",
      "Train Epoch: 157 [0/1649 (0%)]\tLoss: 0.081263\n",
      "\n",
      "Test set: Average loss: 0.2641, Accuracy: 374/412 (91%)\n",
      "\n",
      "Train Epoch: 158 [0/1649 (0%)]\tLoss: 0.113956\n",
      "\n",
      "Test set: Average loss: 0.2716, Accuracy: 373/412 (91%)\n",
      "\n",
      "Train Epoch: 159 [0/1649 (0%)]\tLoss: 0.159966\n",
      "\n",
      "Test set: Average loss: 0.2708, Accuracy: 373/412 (91%)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 160 [0/1649 (0%)]\tLoss: 0.125561\n",
      "\n",
      "Test set: Average loss: 0.2786, Accuracy: 374/412 (91%)\n",
      "\n",
      "Train Epoch: 161 [0/1649 (0%)]\tLoss: 0.087325\n",
      "\n",
      "Test set: Average loss: 0.2879, Accuracy: 374/412 (91%)\n",
      "\n",
      "Train Epoch: 162 [0/1649 (0%)]\tLoss: 0.380334\n",
      "\n",
      "Test set: Average loss: 0.2944, Accuracy: 374/412 (91%)\n",
      "\n",
      "Train Epoch: 163 [0/1649 (0%)]\tLoss: 0.178270\n",
      "\n",
      "Test set: Average loss: 0.2953, Accuracy: 374/412 (91%)\n",
      "\n",
      "Train Epoch: 164 [0/1649 (0%)]\tLoss: 0.261934\n",
      "\n",
      "Test set: Average loss: 0.2978, Accuracy: 375/412 (91%)\n",
      "\n",
      "Train Epoch: 165 [0/1649 (0%)]\tLoss: 0.089837\n",
      "\n",
      "Test set: Average loss: 0.3008, Accuracy: 375/412 (91%)\n",
      "\n",
      "Train Epoch: 166 [0/1649 (0%)]\tLoss: 0.108098\n",
      "\n",
      "Test set: Average loss: 0.3211, Accuracy: 367/412 (89%)\n",
      "\n",
      "Train Epoch: 167 [0/1649 (0%)]\tLoss: 0.244097\n",
      "\n",
      "Test set: Average loss: 0.3152, Accuracy: 372/412 (90%)\n",
      "\n",
      "Train Epoch: 168 [0/1649 (0%)]\tLoss: 0.254445\n",
      "\n",
      "Test set: Average loss: 0.2989, Accuracy: 371/412 (90%)\n",
      "\n",
      "Train Epoch: 169 [0/1649 (0%)]\tLoss: 0.273631\n",
      "\n",
      "Test set: Average loss: 0.2858, Accuracy: 375/412 (91%)\n",
      "\n",
      "Train Epoch: 170 [0/1649 (0%)]\tLoss: 0.356801\n",
      "\n",
      "Test set: Average loss: 0.2794, Accuracy: 376/412 (91%)\n",
      "\n",
      "Train Epoch: 171 [0/1649 (0%)]\tLoss: 0.189680\n",
      "\n",
      "Test set: Average loss: 0.2744, Accuracy: 374/412 (91%)\n",
      "\n",
      "Train Epoch: 172 [0/1649 (0%)]\tLoss: 0.099500\n",
      "\n",
      "Test set: Average loss: 0.2761, Accuracy: 375/412 (91%)\n",
      "\n",
      "Train Epoch: 173 [0/1649 (0%)]\tLoss: 0.088305\n",
      "\n",
      "Test set: Average loss: 0.2880, Accuracy: 372/412 (90%)\n",
      "\n",
      "Train Epoch: 174 [0/1649 (0%)]\tLoss: 0.167789\n",
      "\n",
      "Test set: Average loss: 0.2967, Accuracy: 369/412 (90%)\n",
      "\n",
      "Train Epoch: 175 [0/1649 (0%)]\tLoss: 0.213329\n",
      "\n",
      "Test set: Average loss: 0.2955, Accuracy: 372/412 (90%)\n",
      "\n",
      "Train Epoch: 176 [0/1649 (0%)]\tLoss: 0.051978\n",
      "\n",
      "Test set: Average loss: 0.2945, Accuracy: 375/412 (91%)\n",
      "\n",
      "Train Epoch: 177 [0/1649 (0%)]\tLoss: 0.142025\n",
      "\n",
      "Test set: Average loss: 0.2939, Accuracy: 375/412 (91%)\n",
      "\n",
      "Train Epoch: 178 [0/1649 (0%)]\tLoss: 0.059228\n",
      "\n",
      "Test set: Average loss: 0.3001, Accuracy: 374/412 (91%)\n",
      "\n",
      "Train Epoch: 179 [0/1649 (0%)]\tLoss: 0.406873\n",
      "\n",
      "Test set: Average loss: 0.3164, Accuracy: 375/412 (91%)\n",
      "\n",
      "Train Epoch: 180 [0/1649 (0%)]\tLoss: 0.304342\n",
      "\n",
      "Test set: Average loss: 0.3282, Accuracy: 374/412 (91%)\n",
      "\n",
      "Train Epoch: 181 [0/1649 (0%)]\tLoss: 0.152051\n",
      "\n",
      "Test set: Average loss: 0.3293, Accuracy: 373/412 (91%)\n",
      "\n",
      "Train Epoch: 182 [0/1649 (0%)]\tLoss: 0.113438\n",
      "\n",
      "Test set: Average loss: 0.3268, Accuracy: 372/412 (90%)\n",
      "\n",
      "Train Epoch: 183 [0/1649 (0%)]\tLoss: 0.142707\n",
      "\n",
      "Test set: Average loss: 0.3241, Accuracy: 373/412 (91%)\n",
      "\n",
      "Train Epoch: 184 [0/1649 (0%)]\tLoss: 0.191406\n",
      "\n",
      "Test set: Average loss: 0.3204, Accuracy: 370/412 (90%)\n",
      "\n",
      "Train Epoch: 185 [0/1649 (0%)]\tLoss: 0.318050\n",
      "\n",
      "Test set: Average loss: 0.3253, Accuracy: 369/412 (90%)\n",
      "\n",
      "Train Epoch: 186 [0/1649 (0%)]\tLoss: 0.086451\n",
      "\n",
      "Test set: Average loss: 0.3298, Accuracy: 368/412 (89%)\n",
      "\n",
      "Train Epoch: 187 [0/1649 (0%)]\tLoss: 0.074191\n",
      "\n",
      "Test set: Average loss: 0.3220, Accuracy: 369/412 (90%)\n",
      "\n",
      "Train Epoch: 188 [0/1649 (0%)]\tLoss: 0.166561\n",
      "\n",
      "Test set: Average loss: 0.2993, Accuracy: 373/412 (91%)\n",
      "\n",
      "Train Epoch: 189 [0/1649 (0%)]\tLoss: 0.083030\n",
      "\n",
      "Test set: Average loss: 0.2834, Accuracy: 373/412 (91%)\n",
      "\n",
      "Train Epoch: 190 [0/1649 (0%)]\tLoss: 0.156868\n",
      "\n",
      "Test set: Average loss: 0.2759, Accuracy: 374/412 (91%)\n",
      "\n",
      "Train Epoch: 191 [0/1649 (0%)]\tLoss: 0.236828\n",
      "\n",
      "Test set: Average loss: 0.2615, Accuracy: 375/412 (91%)\n",
      "\n",
      "Train Epoch: 192 [0/1649 (0%)]\tLoss: 0.169326\n",
      "\n",
      "Test set: Average loss: 0.2573, Accuracy: 377/412 (92%)\n",
      "\n",
      "Train Epoch: 193 [0/1649 (0%)]\tLoss: 0.122774\n",
      "\n",
      "Test set: Average loss: 0.2590, Accuracy: 373/412 (91%)\n",
      "\n",
      "Train Epoch: 194 [0/1649 (0%)]\tLoss: 0.085320\n",
      "\n",
      "Test set: Average loss: 0.2592, Accuracy: 374/412 (91%)\n",
      "\n",
      "Train Epoch: 195 [0/1649 (0%)]\tLoss: 0.114618\n",
      "\n",
      "Test set: Average loss: 0.2638, Accuracy: 371/412 (90%)\n",
      "\n",
      "Train Epoch: 196 [0/1649 (0%)]\tLoss: 0.126002\n",
      "\n",
      "Test set: Average loss: 0.2655, Accuracy: 373/412 (91%)\n",
      "\n",
      "Train Epoch: 197 [0/1649 (0%)]\tLoss: 0.214213\n",
      "\n",
      "Test set: Average loss: 0.2689, Accuracy: 375/412 (91%)\n",
      "\n",
      "Train Epoch: 198 [0/1649 (0%)]\tLoss: 0.082483\n",
      "\n",
      "Test set: Average loss: 0.2789, Accuracy: 371/412 (90%)\n",
      "\n",
      "Train Epoch: 199 [0/1649 (0%)]\tLoss: 0.252058\n",
      "\n",
      "Test set: Average loss: 0.2834, Accuracy: 373/412 (91%)\n",
      "\n",
      "Train Epoch: 200 [0/1649 (0%)]\tLoss: 0.105484\n",
      "\n",
      "Test set: Average loss: 0.2831, Accuracy: 370/412 (90%)\n",
      "\n",
      "Train Epoch: 201 [0/1649 (0%)]\tLoss: 0.066547\n",
      "\n",
      "Test set: Average loss: 0.2866, Accuracy: 371/412 (90%)\n",
      "\n",
      "Train Epoch: 202 [0/1649 (0%)]\tLoss: 0.114024\n",
      "\n",
      "Test set: Average loss: 0.2775, Accuracy: 373/412 (91%)\n",
      "\n",
      "Train Epoch: 203 [0/1649 (0%)]\tLoss: 0.229743\n",
      "\n",
      "Test set: Average loss: 0.2706, Accuracy: 374/412 (91%)\n",
      "\n",
      "Train Epoch: 204 [0/1649 (0%)]\tLoss: 0.056578\n",
      "\n",
      "Test set: Average loss: 0.2683, Accuracy: 376/412 (91%)\n",
      "\n",
      "Train Epoch: 205 [0/1649 (0%)]\tLoss: 0.170767\n",
      "\n",
      "Test set: Average loss: 0.2670, Accuracy: 375/412 (91%)\n",
      "\n",
      "Train Epoch: 206 [0/1649 (0%)]\tLoss: 0.120613\n",
      "\n",
      "Test set: Average loss: 0.2759, Accuracy: 377/412 (92%)\n",
      "\n",
      "Train Epoch: 207 [0/1649 (0%)]\tLoss: 0.157109\n",
      "\n",
      "Test set: Average loss: 0.2920, Accuracy: 378/412 (92%)\n",
      "\n",
      "Train Epoch: 208 [0/1649 (0%)]\tLoss: 0.149799\n",
      "\n",
      "Test set: Average loss: 0.3000, Accuracy: 373/412 (91%)\n",
      "\n",
      "Train Epoch: 209 [0/1649 (0%)]\tLoss: 0.181479\n",
      "\n",
      "Test set: Average loss: 0.3024, Accuracy: 372/412 (90%)\n",
      "\n",
      "Train Epoch: 210 [0/1649 (0%)]\tLoss: 0.405709\n",
      "\n",
      "Test set: Average loss: 0.2914, Accuracy: 373/412 (91%)\n",
      "\n",
      "Train Epoch: 211 [0/1649 (0%)]\tLoss: 0.222272\n",
      "\n",
      "Test set: Average loss: 0.2935, Accuracy: 370/412 (90%)\n",
      "\n",
      "Train Epoch: 212 [0/1649 (0%)]\tLoss: 0.048166\n",
      "\n",
      "Test set: Average loss: 0.3253, Accuracy: 368/412 (89%)\n",
      "\n",
      "Train Epoch: 213 [0/1649 (0%)]\tLoss: 0.127022\n",
      "\n",
      "Test set: Average loss: 0.3375, Accuracy: 369/412 (90%)\n",
      "\n",
      "Train Epoch: 214 [0/1649 (0%)]\tLoss: 0.123289\n",
      "\n",
      "Test set: Average loss: 0.3400, Accuracy: 366/412 (89%)\n",
      "\n",
      "Train Epoch: 215 [0/1649 (0%)]\tLoss: 0.180923\n",
      "\n",
      "Test set: Average loss: 0.3198, Accuracy: 367/412 (89%)\n",
      "\n",
      "Train Epoch: 216 [0/1649 (0%)]\tLoss: 0.222039\n",
      "\n",
      "Test set: Average loss: 0.2915, Accuracy: 371/412 (90%)\n",
      "\n",
      "Train Epoch: 217 [0/1649 (0%)]\tLoss: 0.117818\n",
      "\n",
      "Test set: Average loss: 0.2818, Accuracy: 373/412 (91%)\n",
      "\n",
      "Train Epoch: 218 [0/1649 (0%)]\tLoss: 0.114758\n",
      "\n",
      "Test set: Average loss: 0.2859, Accuracy: 373/412 (91%)\n",
      "\n",
      "Train Epoch: 219 [0/1649 (0%)]\tLoss: 0.191449\n",
      "\n",
      "Test set: Average loss: 0.2897, Accuracy: 377/412 (92%)\n",
      "\n",
      "Train Epoch: 220 [0/1649 (0%)]\tLoss: 0.085801\n",
      "\n",
      "Test set: Average loss: 0.2952, Accuracy: 377/412 (92%)\n",
      "\n",
      "Train Epoch: 221 [0/1649 (0%)]\tLoss: 0.145225\n",
      "\n",
      "Test set: Average loss: 0.2794, Accuracy: 377/412 (92%)\n",
      "\n",
      "Train Epoch: 222 [0/1649 (0%)]\tLoss: 0.217503\n",
      "\n",
      "Test set: Average loss: 0.2528, Accuracy: 378/412 (92%)\n",
      "\n",
      "Train Epoch: 223 [0/1649 (0%)]\tLoss: 0.062216\n",
      "\n",
      "Test set: Average loss: 0.2407, Accuracy: 376/412 (91%)\n",
      "\n",
      "Train Epoch: 224 [0/1649 (0%)]\tLoss: 0.062617\n",
      "\n",
      "Test set: Average loss: 0.2433, Accuracy: 374/412 (91%)\n",
      "\n",
      "Train Epoch: 225 [0/1649 (0%)]\tLoss: 0.143557\n",
      "\n",
      "Test set: Average loss: 0.2484, Accuracy: 372/412 (90%)\n",
      "\n",
      "Train Epoch: 226 [0/1649 (0%)]\tLoss: 0.069795\n",
      "\n",
      "Test set: Average loss: 0.2568, Accuracy: 369/412 (90%)\n",
      "\n",
      "Train Epoch: 227 [0/1649 (0%)]\tLoss: 0.064298\n",
      "\n",
      "Test set: Average loss: 0.2601, Accuracy: 371/412 (90%)\n",
      "\n",
      "Train Epoch: 228 [0/1649 (0%)]\tLoss: 0.177702\n",
      "\n",
      "Test set: Average loss: 0.2611, Accuracy: 371/412 (90%)\n",
      "\n",
      "Train Epoch: 229 [0/1649 (0%)]\tLoss: 0.117348\n",
      "\n",
      "Test set: Average loss: 0.2614, Accuracy: 374/412 (91%)\n",
      "\n",
      "Train Epoch: 230 [0/1649 (0%)]\tLoss: 0.239671\n",
      "\n",
      "Test set: Average loss: 0.2653, Accuracy: 373/412 (91%)\n",
      "\n",
      "Train Epoch: 231 [0/1649 (0%)]\tLoss: 0.183791\n",
      "\n",
      "Test set: Average loss: 0.2889, Accuracy: 372/412 (90%)\n",
      "\n",
      "Train Epoch: 232 [0/1649 (0%)]\tLoss: 0.062457\n",
      "\n",
      "Test set: Average loss: 0.3169, Accuracy: 368/412 (89%)\n",
      "\n",
      "Train Epoch: 233 [0/1649 (0%)]\tLoss: 0.059429\n",
      "\n",
      "Test set: Average loss: 0.3378, Accuracy: 369/412 (90%)\n",
      "\n",
      "Train Epoch: 234 [0/1649 (0%)]\tLoss: 0.124454\n",
      "\n",
      "Test set: Average loss: 0.3262, Accuracy: 369/412 (90%)\n",
      "\n",
      "Train Epoch: 235 [0/1649 (0%)]\tLoss: 0.122988\n",
      "\n",
      "Test set: Average loss: 0.2935, Accuracy: 375/412 (91%)\n",
      "\n",
      "Train Epoch: 236 [0/1649 (0%)]\tLoss: 0.203676\n",
      "\n",
      "Test set: Average loss: 0.2801, Accuracy: 378/412 (92%)\n",
      "\n",
      "Train Epoch: 237 [0/1649 (0%)]\tLoss: 0.074056\n",
      "\n",
      "Test set: Average loss: 0.2864, Accuracy: 379/412 (92%)\n",
      "\n",
      "Train Epoch: 238 [0/1649 (0%)]\tLoss: 0.390732\n",
      "\n",
      "Test set: Average loss: 0.2726, Accuracy: 379/412 (92%)\n",
      "\n",
      "Train Epoch: 239 [0/1649 (0%)]\tLoss: 0.236995\n",
      "\n",
      "Test set: Average loss: 0.2690, Accuracy: 379/412 (92%)\n",
      "\n",
      "Train Epoch: 240 [0/1649 (0%)]\tLoss: 0.140379\n",
      "\n",
      "Test set: Average loss: 0.2899, Accuracy: 372/412 (90%)\n",
      "\n",
      "Train Epoch: 241 [0/1649 (0%)]\tLoss: 0.054251\n",
      "\n",
      "Test set: Average loss: 0.3407, Accuracy: 363/412 (88%)\n",
      "\n",
      "Train Epoch: 242 [0/1649 (0%)]\tLoss: 0.149241\n",
      "\n",
      "Test set: Average loss: 0.3485, Accuracy: 364/412 (88%)\n",
      "\n",
      "Train Epoch: 243 [0/1649 (0%)]\tLoss: 0.242833\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.3045, Accuracy: 367/412 (89%)\n",
      "\n",
      "Train Epoch: 244 [0/1649 (0%)]\tLoss: 0.075156\n",
      "\n",
      "Test set: Average loss: 0.2826, Accuracy: 366/412 (89%)\n",
      "\n",
      "Train Epoch: 245 [0/1649 (0%)]\tLoss: 0.132574\n",
      "\n",
      "Test set: Average loss: 0.2692, Accuracy: 370/412 (90%)\n",
      "\n",
      "Train Epoch: 246 [0/1649 (0%)]\tLoss: 0.081038\n",
      "\n",
      "Test set: Average loss: 0.2626, Accuracy: 373/412 (91%)\n",
      "\n",
      "Train Epoch: 247 [0/1649 (0%)]\tLoss: 0.126541\n",
      "\n",
      "Test set: Average loss: 0.2589, Accuracy: 374/412 (91%)\n",
      "\n",
      "Train Epoch: 248 [0/1649 (0%)]\tLoss: 0.086021\n",
      "\n",
      "Test set: Average loss: 0.2609, Accuracy: 378/412 (92%)\n",
      "\n",
      "Train Epoch: 249 [0/1649 (0%)]\tLoss: 0.178066\n",
      "\n",
      "Test set: Average loss: 0.2662, Accuracy: 378/412 (92%)\n",
      "\n",
      "Train Epoch: 250 [0/1649 (0%)]\tLoss: 0.078716\n",
      "\n",
      "Test set: Average loss: 0.2780, Accuracy: 377/412 (92%)\n",
      "\n",
      "Train Epoch: 251 [0/1649 (0%)]\tLoss: 0.080267\n",
      "\n",
      "Test set: Average loss: 0.2989, Accuracy: 375/412 (91%)\n",
      "\n",
      "Train Epoch: 252 [0/1649 (0%)]\tLoss: 0.080593\n",
      "\n",
      "Test set: Average loss: 0.3116, Accuracy: 376/412 (91%)\n",
      "\n",
      "Train Epoch: 253 [0/1649 (0%)]\tLoss: 0.122554\n",
      "\n",
      "Test set: Average loss: 0.3189, Accuracy: 374/412 (91%)\n",
      "\n",
      "Train Epoch: 254 [0/1649 (0%)]\tLoss: 0.359754\n",
      "\n",
      "Test set: Average loss: 0.2899, Accuracy: 378/412 (92%)\n",
      "\n",
      "Train Epoch: 255 [0/1649 (0%)]\tLoss: 0.082410\n",
      "\n",
      "Test set: Average loss: 0.2706, Accuracy: 378/412 (92%)\n",
      "\n",
      "Train Epoch: 256 [0/1649 (0%)]\tLoss: 0.180889\n",
      "\n",
      "Test set: Average loss: 0.2584, Accuracy: 381/412 (92%)\n",
      "\n",
      "Train Epoch: 257 [0/1649 (0%)]\tLoss: 0.130335\n",
      "\n",
      "Test set: Average loss: 0.2559, Accuracy: 382/412 (93%)\n",
      "\n",
      "Train Epoch: 258 [0/1649 (0%)]\tLoss: 0.093548\n",
      "\n",
      "Test set: Average loss: 0.2569, Accuracy: 381/412 (92%)\n",
      "\n",
      "Train Epoch: 259 [0/1649 (0%)]\tLoss: 0.160304\n",
      "\n",
      "Test set: Average loss: 0.2620, Accuracy: 375/412 (91%)\n",
      "\n",
      "Train Epoch: 260 [0/1649 (0%)]\tLoss: 0.065082\n",
      "\n",
      "Test set: Average loss: 0.2687, Accuracy: 376/412 (91%)\n",
      "\n",
      "Train Epoch: 261 [0/1649 (0%)]\tLoss: 0.084106\n",
      "\n",
      "Test set: Average loss: 0.2778, Accuracy: 371/412 (90%)\n",
      "\n",
      "Train Epoch: 262 [0/1649 (0%)]\tLoss: 0.137343\n",
      "\n",
      "Test set: Average loss: 0.2796, Accuracy: 371/412 (90%)\n",
      "\n",
      "Train Epoch: 263 [0/1649 (0%)]\tLoss: 0.103256\n",
      "\n",
      "Test set: Average loss: 0.2764, Accuracy: 370/412 (90%)\n",
      "\n",
      "Train Epoch: 264 [0/1649 (0%)]\tLoss: 0.176773\n",
      "\n",
      "Test set: Average loss: 0.2651, Accuracy: 373/412 (91%)\n",
      "\n",
      "Train Epoch: 265 [0/1649 (0%)]\tLoss: 0.083983\n",
      "\n",
      "Test set: Average loss: 0.2582, Accuracy: 377/412 (92%)\n",
      "\n",
      "Train Epoch: 266 [0/1649 (0%)]\tLoss: 0.040386\n",
      "\n",
      "Test set: Average loss: 0.2517, Accuracy: 379/412 (92%)\n",
      "\n",
      "Train Epoch: 267 [0/1649 (0%)]\tLoss: 0.123527\n",
      "\n",
      "Test set: Average loss: 0.2515, Accuracy: 378/412 (92%)\n",
      "\n",
      "Train Epoch: 268 [0/1649 (0%)]\tLoss: 0.133810\n",
      "\n",
      "Test set: Average loss: 0.2542, Accuracy: 378/412 (92%)\n",
      "\n",
      "Train Epoch: 269 [0/1649 (0%)]\tLoss: 0.138885\n",
      "\n",
      "Test set: Average loss: 0.2595, Accuracy: 379/412 (92%)\n",
      "\n",
      "Train Epoch: 270 [0/1649 (0%)]\tLoss: 0.043953\n",
      "\n",
      "Test set: Average loss: 0.2688, Accuracy: 378/412 (92%)\n",
      "\n",
      "Train Epoch: 271 [0/1649 (0%)]\tLoss: 0.072609\n",
      "\n",
      "Test set: Average loss: 0.2810, Accuracy: 380/412 (92%)\n",
      "\n",
      "Train Epoch: 272 [0/1649 (0%)]\tLoss: 0.095967\n",
      "\n",
      "Test set: Average loss: 0.2933, Accuracy: 378/412 (92%)\n",
      "\n",
      "Train Epoch: 273 [0/1649 (0%)]\tLoss: 0.017734\n",
      "\n",
      "Test set: Average loss: 0.3096, Accuracy: 376/412 (91%)\n",
      "\n",
      "Train Epoch: 274 [0/1649 (0%)]\tLoss: 0.021255\n",
      "\n",
      "Test set: Average loss: 0.3268, Accuracy: 373/412 (91%)\n",
      "\n",
      "Train Epoch: 275 [0/1649 (0%)]\tLoss: 0.143111\n",
      "\n",
      "Test set: Average loss: 0.3311, Accuracy: 371/412 (90%)\n",
      "\n",
      "Train Epoch: 276 [0/1649 (0%)]\tLoss: 0.098934\n",
      "\n",
      "Test set: Average loss: 0.3376, Accuracy: 371/412 (90%)\n",
      "\n",
      "Train Epoch: 277 [0/1649 (0%)]\tLoss: 0.072864\n",
      "\n",
      "Test set: Average loss: 0.3426, Accuracy: 371/412 (90%)\n",
      "\n",
      "Train Epoch: 278 [0/1649 (0%)]\tLoss: 0.078182\n",
      "\n",
      "Test set: Average loss: 0.3485, Accuracy: 369/412 (90%)\n",
      "\n",
      "Train Epoch: 279 [0/1649 (0%)]\tLoss: 0.101906\n",
      "\n",
      "Test set: Average loss: 0.3477, Accuracy: 370/412 (90%)\n",
      "\n",
      "Train Epoch: 280 [0/1649 (0%)]\tLoss: 0.054995\n",
      "\n",
      "Test set: Average loss: 0.3413, Accuracy: 370/412 (90%)\n",
      "\n",
      "Train Epoch: 281 [0/1649 (0%)]\tLoss: 0.114244\n",
      "\n",
      "Test set: Average loss: 0.3276, Accuracy: 370/412 (90%)\n",
      "\n",
      "Train Epoch: 282 [0/1649 (0%)]\tLoss: 0.163855\n",
      "\n",
      "Test set: Average loss: 0.3057, Accuracy: 373/412 (91%)\n",
      "\n",
      "Train Epoch: 283 [0/1649 (0%)]\tLoss: 0.126156\n",
      "\n",
      "Test set: Average loss: 0.2829, Accuracy: 374/412 (91%)\n",
      "\n",
      "Train Epoch: 284 [0/1649 (0%)]\tLoss: 0.075450\n",
      "\n",
      "Test set: Average loss: 0.2728, Accuracy: 374/412 (91%)\n",
      "\n",
      "Train Epoch: 285 [0/1649 (0%)]\tLoss: 0.027811\n",
      "\n",
      "Test set: Average loss: 0.2707, Accuracy: 372/412 (90%)\n",
      "\n",
      "Train Epoch: 286 [0/1649 (0%)]\tLoss: 0.139653\n",
      "\n",
      "Test set: Average loss: 0.2673, Accuracy: 375/412 (91%)\n",
      "\n",
      "Train Epoch: 287 [0/1649 (0%)]\tLoss: 0.067616\n",
      "\n",
      "Test set: Average loss: 0.2677, Accuracy: 379/412 (92%)\n",
      "\n",
      "Train Epoch: 288 [0/1649 (0%)]\tLoss: 0.121586\n",
      "\n",
      "Test set: Average loss: 0.2662, Accuracy: 379/412 (92%)\n",
      "\n",
      "Train Epoch: 289 [0/1649 (0%)]\tLoss: 0.039995\n",
      "\n",
      "Test set: Average loss: 0.2765, Accuracy: 377/412 (92%)\n",
      "\n",
      "Train Epoch: 290 [0/1649 (0%)]\tLoss: 0.164017\n",
      "\n",
      "Test set: Average loss: 0.2790, Accuracy: 379/412 (92%)\n",
      "\n",
      "Train Epoch: 291 [0/1649 (0%)]\tLoss: 0.099696\n",
      "\n",
      "Test set: Average loss: 0.2891, Accuracy: 377/412 (92%)\n",
      "\n",
      "Train Epoch: 292 [0/1649 (0%)]\tLoss: 0.063383\n",
      "\n",
      "Test set: Average loss: 0.2917, Accuracy: 376/412 (91%)\n",
      "\n",
      "Train Epoch: 293 [0/1649 (0%)]\tLoss: 0.093983\n",
      "\n",
      "Test set: Average loss: 0.2963, Accuracy: 373/412 (91%)\n",
      "\n",
      "Train Epoch: 294 [0/1649 (0%)]\tLoss: 0.079423\n",
      "\n",
      "Test set: Average loss: 0.3048, Accuracy: 372/412 (90%)\n",
      "\n",
      "Train Epoch: 295 [0/1649 (0%)]\tLoss: 0.163994\n",
      "\n",
      "Test set: Average loss: 0.2915, Accuracy: 371/412 (90%)\n",
      "\n",
      "Train Epoch: 296 [0/1649 (0%)]\tLoss: 0.059833\n",
      "\n",
      "Test set: Average loss: 0.2760, Accuracy: 371/412 (90%)\n",
      "\n",
      "Train Epoch: 297 [0/1649 (0%)]\tLoss: 0.103461\n",
      "\n",
      "Test set: Average loss: 0.2568, Accuracy: 373/412 (91%)\n",
      "\n",
      "Train Epoch: 298 [0/1649 (0%)]\tLoss: 0.051807\n",
      "\n",
      "Test set: Average loss: 0.2442, Accuracy: 376/412 (91%)\n",
      "\n",
      "Train Epoch: 299 [0/1649 (0%)]\tLoss: 0.074320\n",
      "\n",
      "Test set: Average loss: 0.2372, Accuracy: 376/412 (91%)\n",
      "\n",
      "Train Epoch: 300 [0/1649 (0%)]\tLoss: 0.050875\n",
      "\n",
      "Test set: Average loss: 0.2341, Accuracy: 376/412 (91%)\n",
      "\n",
      "Train Epoch: 301 [0/1649 (0%)]\tLoss: 0.063951\n",
      "\n",
      "Test set: Average loss: 0.2326, Accuracy: 380/412 (92%)\n",
      "\n",
      "Train Epoch: 302 [0/1649 (0%)]\tLoss: 0.108846\n",
      "\n",
      "Test set: Average loss: 0.2352, Accuracy: 380/412 (92%)\n",
      "\n",
      "Train Epoch: 303 [0/1649 (0%)]\tLoss: 0.055111\n",
      "\n",
      "Test set: Average loss: 0.2407, Accuracy: 380/412 (92%)\n",
      "\n",
      "Train Epoch: 304 [0/1649 (0%)]\tLoss: 0.047597\n",
      "\n",
      "Test set: Average loss: 0.2436, Accuracy: 380/412 (92%)\n",
      "\n",
      "Train Epoch: 305 [0/1649 (0%)]\tLoss: 0.025672\n",
      "\n",
      "Test set: Average loss: 0.2485, Accuracy: 380/412 (92%)\n",
      "\n",
      "Train Epoch: 306 [0/1649 (0%)]\tLoss: 0.041952\n",
      "\n",
      "Test set: Average loss: 0.2533, Accuracy: 381/412 (92%)\n",
      "\n",
      "Train Epoch: 307 [0/1649 (0%)]\tLoss: 0.091718\n",
      "\n",
      "Test set: Average loss: 0.2492, Accuracy: 382/412 (93%)\n",
      "\n",
      "Train Epoch: 308 [0/1649 (0%)]\tLoss: 0.136424\n",
      "\n",
      "Test set: Average loss: 0.2435, Accuracy: 382/412 (93%)\n",
      "\n",
      "Train Epoch: 309 [0/1649 (0%)]\tLoss: 0.041676\n",
      "\n",
      "Test set: Average loss: 0.2452, Accuracy: 382/412 (93%)\n",
      "\n",
      "Train Epoch: 310 [0/1649 (0%)]\tLoss: 0.045336\n",
      "\n",
      "Test set: Average loss: 0.2475, Accuracy: 383/412 (93%)\n",
      "\n",
      "Train Epoch: 311 [0/1649 (0%)]\tLoss: 0.088757\n",
      "\n",
      "Test set: Average loss: 0.2592, Accuracy: 380/412 (92%)\n",
      "\n",
      "Train Epoch: 312 [0/1649 (0%)]\tLoss: 0.126747\n",
      "\n",
      "Test set: Average loss: 0.2823, Accuracy: 374/412 (91%)\n",
      "\n",
      "Train Epoch: 313 [0/1649 (0%)]\tLoss: 0.046706\n",
      "\n",
      "Test set: Average loss: 0.3138, Accuracy: 374/412 (91%)\n",
      "\n",
      "Train Epoch: 314 [0/1649 (0%)]\tLoss: 0.009802\n",
      "\n",
      "Test set: Average loss: 0.3487, Accuracy: 370/412 (90%)\n",
      "\n",
      "Train Epoch: 315 [0/1649 (0%)]\tLoss: 0.145649\n",
      "\n",
      "Test set: Average loss: 0.3690, Accuracy: 369/412 (90%)\n",
      "\n",
      "Train Epoch: 316 [0/1649 (0%)]\tLoss: 0.526585\n",
      "\n",
      "Test set: Average loss: 0.3760, Accuracy: 368/412 (89%)\n",
      "\n",
      "Train Epoch: 317 [0/1649 (0%)]\tLoss: 0.141437\n",
      "\n",
      "Test set: Average loss: 0.3363, Accuracy: 371/412 (90%)\n",
      "\n",
      "Train Epoch: 318 [0/1649 (0%)]\tLoss: 0.060370\n",
      "\n",
      "Test set: Average loss: 0.3112, Accuracy: 371/412 (90%)\n",
      "\n",
      "Train Epoch: 319 [0/1649 (0%)]\tLoss: 0.113354\n",
      "\n",
      "Test set: Average loss: 0.2775, Accuracy: 373/412 (91%)\n",
      "\n",
      "Train Epoch: 320 [0/1649 (0%)]\tLoss: 0.129516\n",
      "\n",
      "Test set: Average loss: 0.2693, Accuracy: 374/412 (91%)\n",
      "\n",
      "Train Epoch: 321 [0/1649 (0%)]\tLoss: 0.091692\n",
      "\n",
      "Test set: Average loss: 0.2620, Accuracy: 372/412 (90%)\n",
      "\n",
      "Train Epoch: 322 [0/1649 (0%)]\tLoss: 0.154821\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.2246, Accuracy: 377/412 (92%)\n",
      "\n",
      "Train Epoch: 323 [0/1649 (0%)]\tLoss: 0.070761\n",
      "\n",
      "Test set: Average loss: 0.2049, Accuracy: 375/412 (91%)\n",
      "\n",
      "Train Epoch: 324 [0/1649 (0%)]\tLoss: 0.154988\n",
      "\n",
      "Test set: Average loss: 0.2048, Accuracy: 379/412 (92%)\n",
      "\n",
      "Train Epoch: 325 [0/1649 (0%)]\tLoss: 0.022654\n",
      "\n",
      "Test set: Average loss: 0.2128, Accuracy: 379/412 (92%)\n",
      "\n",
      "Train Epoch: 326 [0/1649 (0%)]\tLoss: 0.279982\n",
      "\n",
      "Test set: Average loss: 0.2256, Accuracy: 376/412 (91%)\n",
      "\n",
      "Train Epoch: 327 [0/1649 (0%)]\tLoss: 0.112595\n",
      "\n",
      "Test set: Average loss: 0.2307, Accuracy: 375/412 (91%)\n",
      "\n",
      "Train Epoch: 328 [0/1649 (0%)]\tLoss: 0.038956\n",
      "\n",
      "Test set: Average loss: 0.2342, Accuracy: 375/412 (91%)\n",
      "\n",
      "Train Epoch: 329 [0/1649 (0%)]\tLoss: 0.042661\n",
      "\n",
      "Test set: Average loss: 0.2366, Accuracy: 375/412 (91%)\n",
      "\n",
      "Train Epoch: 330 [0/1649 (0%)]\tLoss: 0.069711\n",
      "\n",
      "Test set: Average loss: 0.2328, Accuracy: 377/412 (92%)\n",
      "\n",
      "Train Epoch: 331 [0/1649 (0%)]\tLoss: 0.066113\n",
      "\n",
      "Test set: Average loss: 0.2330, Accuracy: 379/412 (92%)\n",
      "\n",
      "Train Epoch: 332 [0/1649 (0%)]\tLoss: 0.071555\n",
      "\n",
      "Test set: Average loss: 0.2296, Accuracy: 381/412 (92%)\n",
      "\n",
      "Train Epoch: 333 [0/1649 (0%)]\tLoss: 0.042140\n",
      "\n",
      "Test set: Average loss: 0.2298, Accuracy: 379/412 (92%)\n",
      "\n",
      "Train Epoch: 334 [0/1649 (0%)]\tLoss: 0.082464\n",
      "\n",
      "Test set: Average loss: 0.2291, Accuracy: 379/412 (92%)\n",
      "\n",
      "Train Epoch: 335 [0/1649 (0%)]\tLoss: 0.072656\n",
      "\n",
      "Test set: Average loss: 0.2229, Accuracy: 379/412 (92%)\n",
      "\n",
      "Train Epoch: 336 [0/1649 (0%)]\tLoss: 0.189265\n",
      "\n",
      "Test set: Average loss: 0.2136, Accuracy: 378/412 (92%)\n",
      "\n",
      "Train Epoch: 337 [0/1649 (0%)]\tLoss: 0.022351\n",
      "\n",
      "Test set: Average loss: 0.2093, Accuracy: 379/412 (92%)\n",
      "\n",
      "Train Epoch: 338 [0/1649 (0%)]\tLoss: 0.068651\n",
      "\n",
      "Test set: Average loss: 0.2060, Accuracy: 383/412 (93%)\n",
      "\n",
      "Train Epoch: 339 [0/1649 (0%)]\tLoss: 0.054394\n",
      "\n",
      "Test set: Average loss: 0.2007, Accuracy: 383/412 (93%)\n",
      "\n",
      "Train Epoch: 340 [0/1649 (0%)]\tLoss: 0.043408\n",
      "\n",
      "Test set: Average loss: 0.1972, Accuracy: 382/412 (93%)\n",
      "\n",
      "Train Epoch: 341 [0/1649 (0%)]\tLoss: 0.040347\n",
      "\n",
      "Test set: Average loss: 0.1934, Accuracy: 385/412 (93%)\n",
      "\n",
      "Train Epoch: 342 [0/1649 (0%)]\tLoss: 0.061362\n",
      "\n",
      "Test set: Average loss: 0.1914, Accuracy: 384/412 (93%)\n",
      "\n",
      "Train Epoch: 343 [0/1649 (0%)]\tLoss: 0.042806\n",
      "\n",
      "Test set: Average loss: 0.1933, Accuracy: 384/412 (93%)\n",
      "\n",
      "Train Epoch: 344 [0/1649 (0%)]\tLoss: 0.102073\n",
      "\n",
      "Test set: Average loss: 0.1976, Accuracy: 385/412 (93%)\n",
      "\n",
      "Train Epoch: 345 [0/1649 (0%)]\tLoss: 0.068013\n",
      "\n",
      "Test set: Average loss: 0.2029, Accuracy: 384/412 (93%)\n",
      "\n",
      "Train Epoch: 346 [0/1649 (0%)]\tLoss: 0.042595\n",
      "\n",
      "Test set: Average loss: 0.2123, Accuracy: 384/412 (93%)\n",
      "\n",
      "Train Epoch: 347 [0/1649 (0%)]\tLoss: 0.069263\n",
      "\n",
      "Test set: Average loss: 0.2203, Accuracy: 382/412 (93%)\n",
      "\n",
      "Train Epoch: 348 [0/1649 (0%)]\tLoss: 0.058163\n",
      "\n",
      "Test set: Average loss: 0.2327, Accuracy: 380/412 (92%)\n",
      "\n",
      "Train Epoch: 349 [0/1649 (0%)]\tLoss: 0.052366\n",
      "\n",
      "Test set: Average loss: 0.2344, Accuracy: 380/412 (92%)\n",
      "\n",
      "Train Epoch: 350 [0/1649 (0%)]\tLoss: 0.035091\n",
      "\n",
      "Test set: Average loss: 0.2434, Accuracy: 381/412 (92%)\n",
      "\n",
      "Train Epoch: 351 [0/1649 (0%)]\tLoss: 0.027741\n",
      "\n",
      "Test set: Average loss: 0.2536, Accuracy: 379/412 (92%)\n",
      "\n",
      "Train Epoch: 352 [0/1649 (0%)]\tLoss: 0.035710\n",
      "\n",
      "Test set: Average loss: 0.2588, Accuracy: 380/412 (92%)\n",
      "\n",
      "Train Epoch: 353 [0/1649 (0%)]\tLoss: 0.056731\n",
      "\n",
      "Test set: Average loss: 0.2575, Accuracy: 379/412 (92%)\n",
      "\n",
      "Train Epoch: 354 [0/1649 (0%)]\tLoss: 0.026037\n",
      "\n",
      "Test set: Average loss: 0.2573, Accuracy: 378/412 (92%)\n",
      "\n",
      "Train Epoch: 355 [0/1649 (0%)]\tLoss: 0.027422\n",
      "\n",
      "Test set: Average loss: 0.2555, Accuracy: 380/412 (92%)\n",
      "\n",
      "Train Epoch: 356 [0/1649 (0%)]\tLoss: 0.028873\n",
      "\n",
      "Test set: Average loss: 0.2459, Accuracy: 379/412 (92%)\n",
      "\n",
      "Train Epoch: 357 [0/1649 (0%)]\tLoss: 0.053340\n",
      "\n",
      "Test set: Average loss: 0.2312, Accuracy: 379/412 (92%)\n",
      "\n",
      "Train Epoch: 358 [0/1649 (0%)]\tLoss: 0.191433\n",
      "\n",
      "Test set: Average loss: 0.2089, Accuracy: 379/412 (92%)\n",
      "\n",
      "Train Epoch: 359 [0/1649 (0%)]\tLoss: 0.299926\n",
      "\n",
      "Test set: Average loss: 0.2016, Accuracy: 380/412 (92%)\n",
      "\n",
      "Train Epoch: 360 [0/1649 (0%)]\tLoss: 0.067251\n",
      "\n",
      "Test set: Average loss: 0.2026, Accuracy: 381/412 (92%)\n",
      "\n",
      "Train Epoch: 361 [0/1649 (0%)]\tLoss: 0.062047\n",
      "\n",
      "Test set: Average loss: 0.2062, Accuracy: 382/412 (93%)\n",
      "\n",
      "Train Epoch: 362 [0/1649 (0%)]\tLoss: 0.056727\n",
      "\n",
      "Test set: Average loss: 0.2106, Accuracy: 383/412 (93%)\n",
      "\n",
      "Train Epoch: 363 [0/1649 (0%)]\tLoss: 0.058570\n",
      "\n",
      "Test set: Average loss: 0.2127, Accuracy: 384/412 (93%)\n",
      "\n",
      "Train Epoch: 364 [0/1649 (0%)]\tLoss: 0.178198\n",
      "\n",
      "Test set: Average loss: 0.2181, Accuracy: 383/412 (93%)\n",
      "\n",
      "Train Epoch: 365 [0/1649 (0%)]\tLoss: 0.069079\n",
      "\n",
      "Test set: Average loss: 0.2316, Accuracy: 379/412 (92%)\n",
      "\n",
      "Train Epoch: 366 [0/1649 (0%)]\tLoss: 0.092936\n",
      "\n",
      "Test set: Average loss: 0.2386, Accuracy: 377/412 (92%)\n",
      "\n",
      "Train Epoch: 367 [0/1649 (0%)]\tLoss: 0.071913\n",
      "\n",
      "Test set: Average loss: 0.2425, Accuracy: 376/412 (91%)\n",
      "\n",
      "Train Epoch: 368 [0/1649 (0%)]\tLoss: 0.132891\n",
      "\n",
      "Test set: Average loss: 0.2204, Accuracy: 377/412 (92%)\n",
      "\n",
      "Train Epoch: 369 [0/1649 (0%)]\tLoss: 0.111222\n",
      "\n",
      "Test set: Average loss: 0.2093, Accuracy: 380/412 (92%)\n",
      "\n",
      "Train Epoch: 370 [0/1649 (0%)]\tLoss: 0.020177\n",
      "\n",
      "Test set: Average loss: 0.2137, Accuracy: 380/412 (92%)\n",
      "\n",
      "Train Epoch: 371 [0/1649 (0%)]\tLoss: 0.232871\n",
      "\n",
      "Test set: Average loss: 0.2016, Accuracy: 385/412 (93%)\n",
      "\n",
      "Train Epoch: 372 [0/1649 (0%)]\tLoss: 0.125041\n",
      "\n",
      "Test set: Average loss: 0.1986, Accuracy: 385/412 (93%)\n",
      "\n",
      "Train Epoch: 373 [0/1649 (0%)]\tLoss: 0.080627\n",
      "\n",
      "Test set: Average loss: 0.2058, Accuracy: 385/412 (93%)\n",
      "\n",
      "Train Epoch: 374 [0/1649 (0%)]\tLoss: 0.107248\n",
      "\n",
      "Test set: Average loss: 0.2208, Accuracy: 384/412 (93%)\n",
      "\n",
      "Train Epoch: 375 [0/1649 (0%)]\tLoss: 0.051686\n",
      "\n",
      "Test set: Average loss: 0.2379, Accuracy: 379/412 (92%)\n",
      "\n",
      "Train Epoch: 376 [0/1649 (0%)]\tLoss: 0.028352\n",
      "\n",
      "Test set: Average loss: 0.2552, Accuracy: 380/412 (92%)\n",
      "\n",
      "Train Epoch: 377 [0/1649 (0%)]\tLoss: 0.044058\n",
      "\n",
      "Test set: Average loss: 0.2734, Accuracy: 377/412 (92%)\n",
      "\n",
      "Train Epoch: 378 [0/1649 (0%)]\tLoss: 0.017073\n",
      "\n",
      "Test set: Average loss: 0.2913, Accuracy: 375/412 (91%)\n",
      "\n",
      "Train Epoch: 379 [0/1649 (0%)]\tLoss: 0.035864\n",
      "\n",
      "Test set: Average loss: 0.2983, Accuracy: 376/412 (91%)\n",
      "\n",
      "Train Epoch: 380 [0/1649 (0%)]\tLoss: 0.130848\n",
      "\n",
      "Test set: Average loss: 0.2743, Accuracy: 379/412 (92%)\n",
      "\n",
      "Train Epoch: 381 [0/1649 (0%)]\tLoss: 0.053009\n",
      "\n",
      "Test set: Average loss: 0.2569, Accuracy: 379/412 (92%)\n",
      "\n",
      "Train Epoch: 382 [0/1649 (0%)]\tLoss: 0.055938\n",
      "\n",
      "Test set: Average loss: 0.2462, Accuracy: 379/412 (92%)\n",
      "\n",
      "Train Epoch: 383 [0/1649 (0%)]\tLoss: 0.026178\n",
      "\n",
      "Test set: Average loss: 0.2481, Accuracy: 378/412 (92%)\n",
      "\n",
      "Train Epoch: 384 [0/1649 (0%)]\tLoss: 0.030097\n",
      "\n",
      "Test set: Average loss: 0.2515, Accuracy: 377/412 (92%)\n",
      "\n",
      "Train Epoch: 385 [0/1649 (0%)]\tLoss: 0.390046\n",
      "\n",
      "Test set: Average loss: 0.2466, Accuracy: 376/412 (91%)\n",
      "\n",
      "Train Epoch: 386 [0/1649 (0%)]\tLoss: 0.098443\n",
      "\n",
      "Test set: Average loss: 0.2466, Accuracy: 376/412 (91%)\n",
      "\n",
      "Train Epoch: 387 [0/1649 (0%)]\tLoss: 0.008678\n",
      "\n",
      "Test set: Average loss: 0.2574, Accuracy: 377/412 (92%)\n",
      "\n",
      "Train Epoch: 388 [0/1649 (0%)]\tLoss: 0.025668\n",
      "\n",
      "Test set: Average loss: 0.2715, Accuracy: 377/412 (92%)\n",
      "\n",
      "Train Epoch: 389 [0/1649 (0%)]\tLoss: 0.051941\n",
      "\n",
      "Test set: Average loss: 0.2661, Accuracy: 376/412 (91%)\n",
      "\n",
      "Train Epoch: 390 [0/1649 (0%)]\tLoss: 0.032190\n",
      "\n",
      "Test set: Average loss: 0.2626, Accuracy: 374/412 (91%)\n",
      "\n",
      "Train Epoch: 391 [0/1649 (0%)]\tLoss: 0.152400\n",
      "\n",
      "Test set: Average loss: 0.2561, Accuracy: 375/412 (91%)\n",
      "\n",
      "Train Epoch: 392 [0/1649 (0%)]\tLoss: 0.126026\n",
      "\n",
      "Test set: Average loss: 0.2439, Accuracy: 380/412 (92%)\n",
      "\n",
      "Train Epoch: 393 [0/1649 (0%)]\tLoss: 0.302114\n",
      "\n",
      "Test set: Average loss: 0.2408, Accuracy: 380/412 (92%)\n",
      "\n",
      "Train Epoch: 394 [0/1649 (0%)]\tLoss: 0.201642\n",
      "\n",
      "Test set: Average loss: 0.2369, Accuracy: 379/412 (92%)\n",
      "\n",
      "Train Epoch: 395 [0/1649 (0%)]\tLoss: 0.111078\n",
      "\n",
      "Test set: Average loss: 0.2392, Accuracy: 377/412 (92%)\n",
      "\n",
      "Train Epoch: 396 [0/1649 (0%)]\tLoss: 0.035142\n",
      "\n",
      "Test set: Average loss: 0.2435, Accuracy: 377/412 (92%)\n",
      "\n",
      "Train Epoch: 397 [0/1649 (0%)]\tLoss: 0.061079\n",
      "\n",
      "Test set: Average loss: 0.2456, Accuracy: 376/412 (91%)\n",
      "\n",
      "Train Epoch: 398 [0/1649 (0%)]\tLoss: 0.016035\n",
      "\n",
      "Test set: Average loss: 0.2497, Accuracy: 376/412 (91%)\n",
      "\n",
      "Train Epoch: 399 [0/1649 (0%)]\tLoss: 0.062553\n",
      "\n",
      "Test set: Average loss: 0.2463, Accuracy: 376/412 (91%)\n",
      "\n",
      "Train Epoch: 400 [0/1649 (0%)]\tLoss: 0.006679\n",
      "\n",
      "Test set: Average loss: 0.2474, Accuracy: 373/412 (91%)\n",
      "\n",
      "Train Epoch: 401 [0/1649 (0%)]\tLoss: 0.023242\n",
      "\n",
      "Test set: Average loss: 0.2511, Accuracy: 373/412 (91%)\n",
      "\n",
      "Train Epoch: 402 [0/1649 (0%)]\tLoss: 0.109642\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.2489, Accuracy: 376/412 (91%)\n",
      "\n",
      "Train Epoch: 403 [0/1649 (0%)]\tLoss: 0.072415\n",
      "\n",
      "Test set: Average loss: 0.2460, Accuracy: 381/412 (92%)\n",
      "\n",
      "Train Epoch: 404 [0/1649 (0%)]\tLoss: 0.057969\n",
      "\n",
      "Test set: Average loss: 0.2454, Accuracy: 383/412 (93%)\n",
      "\n",
      "Train Epoch: 405 [0/1649 (0%)]\tLoss: 0.135727\n",
      "\n",
      "Test set: Average loss: 0.2521, Accuracy: 380/412 (92%)\n",
      "\n",
      "Train Epoch: 406 [0/1649 (0%)]\tLoss: 0.040497\n",
      "\n",
      "Test set: Average loss: 0.2647, Accuracy: 379/412 (92%)\n",
      "\n",
      "Train Epoch: 407 [0/1649 (0%)]\tLoss: 0.029439\n",
      "\n",
      "Test set: Average loss: 0.2808, Accuracy: 378/412 (92%)\n",
      "\n",
      "Train Epoch: 408 [0/1649 (0%)]\tLoss: 0.069212\n",
      "\n",
      "Test set: Average loss: 0.2807, Accuracy: 377/412 (92%)\n",
      "\n",
      "Train Epoch: 409 [0/1649 (0%)]\tLoss: 0.055118\n",
      "\n",
      "Test set: Average loss: 0.2726, Accuracy: 376/412 (91%)\n",
      "\n",
      "Train Epoch: 410 [0/1649 (0%)]\tLoss: 0.221478\n",
      "\n",
      "Test set: Average loss: 0.2705, Accuracy: 379/412 (92%)\n",
      "\n",
      "Train Epoch: 411 [0/1649 (0%)]\tLoss: 0.109376\n",
      "\n",
      "Test set: Average loss: 0.2772, Accuracy: 377/412 (92%)\n",
      "\n",
      "Train Epoch: 412 [0/1649 (0%)]\tLoss: 0.029859\n",
      "\n",
      "Test set: Average loss: 0.3041, Accuracy: 374/412 (91%)\n",
      "\n",
      "Train Epoch: 413 [0/1649 (0%)]\tLoss: 0.097043\n",
      "\n",
      "Test set: Average loss: 0.3235, Accuracy: 375/412 (91%)\n",
      "\n",
      "Train Epoch: 414 [0/1649 (0%)]\tLoss: 0.080730\n",
      "\n",
      "Test set: Average loss: 0.3172, Accuracy: 374/412 (91%)\n",
      "\n",
      "Train Epoch: 415 [0/1649 (0%)]\tLoss: 0.100766\n",
      "\n",
      "Test set: Average loss: 0.2980, Accuracy: 376/412 (91%)\n",
      "\n",
      "Train Epoch: 416 [0/1649 (0%)]\tLoss: 0.021682\n",
      "\n",
      "Test set: Average loss: 0.2859, Accuracy: 377/412 (92%)\n",
      "\n",
      "Train Epoch: 417 [0/1649 (0%)]\tLoss: 0.098814\n",
      "\n",
      "Test set: Average loss: 0.2702, Accuracy: 380/412 (92%)\n",
      "\n",
      "Train Epoch: 418 [0/1649 (0%)]\tLoss: 0.104573\n",
      "\n",
      "Test set: Average loss: 0.2580, Accuracy: 379/412 (92%)\n",
      "\n",
      "Train Epoch: 419 [0/1649 (0%)]\tLoss: 0.032028\n",
      "\n",
      "Test set: Average loss: 0.2593, Accuracy: 378/412 (92%)\n",
      "\n",
      "Train Epoch: 420 [0/1649 (0%)]\tLoss: 0.017988\n",
      "\n",
      "Test set: Average loss: 0.2673, Accuracy: 375/412 (91%)\n",
      "\n",
      "Train Epoch: 421 [0/1649 (0%)]\tLoss: 0.054079\n",
      "\n",
      "Test set: Average loss: 0.2759, Accuracy: 376/412 (91%)\n",
      "\n",
      "Train Epoch: 422 [0/1649 (0%)]\tLoss: 0.013733\n",
      "\n",
      "Test set: Average loss: 0.2868, Accuracy: 376/412 (91%)\n",
      "\n",
      "Train Epoch: 423 [0/1649 (0%)]\tLoss: 0.132093\n",
      "\n",
      "Test set: Average loss: 0.2921, Accuracy: 377/412 (92%)\n",
      "\n",
      "Train Epoch: 424 [0/1649 (0%)]\tLoss: 0.056853\n",
      "\n",
      "Test set: Average loss: 0.2984, Accuracy: 379/412 (92%)\n",
      "\n",
      "Train Epoch: 425 [0/1649 (0%)]\tLoss: 0.107305\n",
      "\n",
      "Test set: Average loss: 0.2834, Accuracy: 381/412 (92%)\n",
      "\n",
      "Train Epoch: 426 [0/1649 (0%)]\tLoss: 0.091257\n",
      "\n",
      "Test set: Average loss: 0.2536, Accuracy: 383/412 (93%)\n",
      "\n",
      "Train Epoch: 427 [0/1649 (0%)]\tLoss: 0.073012\n",
      "\n",
      "Test set: Average loss: 0.2368, Accuracy: 382/412 (93%)\n",
      "\n",
      "Train Epoch: 428 [0/1649 (0%)]\tLoss: 0.007517\n",
      "\n",
      "Test set: Average loss: 0.2320, Accuracy: 383/412 (93%)\n",
      "\n",
      "Train Epoch: 429 [0/1649 (0%)]\tLoss: 0.058692\n",
      "\n",
      "Test set: Average loss: 0.2413, Accuracy: 384/412 (93%)\n",
      "\n",
      "Train Epoch: 430 [0/1649 (0%)]\tLoss: 0.060643\n",
      "\n",
      "Test set: Average loss: 0.2562, Accuracy: 379/412 (92%)\n",
      "\n",
      "Train Epoch: 431 [0/1649 (0%)]\tLoss: 0.073465\n",
      "\n",
      "Test set: Average loss: 0.2699, Accuracy: 377/412 (92%)\n",
      "\n",
      "Train Epoch: 432 [0/1649 (0%)]\tLoss: 0.086880\n",
      "\n",
      "Test set: Average loss: 0.2691, Accuracy: 378/412 (92%)\n",
      "\n",
      "Train Epoch: 433 [0/1649 (0%)]\tLoss: 0.112473\n",
      "\n",
      "Test set: Average loss: 0.2587, Accuracy: 382/412 (93%)\n",
      "\n",
      "Train Epoch: 434 [0/1649 (0%)]\tLoss: 0.032911\n",
      "\n",
      "Test set: Average loss: 0.2470, Accuracy: 383/412 (93%)\n",
      "\n",
      "Train Epoch: 435 [0/1649 (0%)]\tLoss: 0.196194\n",
      "\n",
      "Test set: Average loss: 0.2391, Accuracy: 383/412 (93%)\n",
      "\n",
      "Train Epoch: 436 [0/1649 (0%)]\tLoss: 0.033080\n",
      "\n",
      "Test set: Average loss: 0.2396, Accuracy: 381/412 (92%)\n",
      "\n",
      "Train Epoch: 437 [0/1649 (0%)]\tLoss: 0.029330\n",
      "\n",
      "Test set: Average loss: 0.2407, Accuracy: 385/412 (93%)\n",
      "\n",
      "Train Epoch: 438 [0/1649 (0%)]\tLoss: 0.098565\n",
      "\n",
      "Test set: Average loss: 0.2376, Accuracy: 383/412 (93%)\n",
      "\n",
      "Train Epoch: 439 [0/1649 (0%)]\tLoss: 0.068354\n",
      "\n",
      "Test set: Average loss: 0.2505, Accuracy: 381/412 (92%)\n",
      "\n",
      "Train Epoch: 440 [0/1649 (0%)]\tLoss: 0.007400\n",
      "\n",
      "Test set: Average loss: 0.2835, Accuracy: 381/412 (92%)\n",
      "\n",
      "Train Epoch: 441 [0/1649 (0%)]\tLoss: 0.088909\n",
      "\n",
      "Test set: Average loss: 0.2701, Accuracy: 380/412 (92%)\n",
      "\n",
      "Train Epoch: 442 [0/1649 (0%)]\tLoss: 0.021814\n",
      "\n",
      "Test set: Average loss: 0.2824, Accuracy: 380/412 (92%)\n",
      "\n",
      "Train Epoch: 443 [0/1649 (0%)]\tLoss: 0.036431\n",
      "\n",
      "Test set: Average loss: 0.2956, Accuracy: 379/412 (92%)\n",
      "\n",
      "Train Epoch: 444 [0/1649 (0%)]\tLoss: 0.106027\n",
      "\n",
      "Test set: Average loss: 0.3034, Accuracy: 377/412 (92%)\n",
      "\n",
      "Train Epoch: 445 [0/1649 (0%)]\tLoss: 0.018643\n",
      "\n",
      "Test set: Average loss: 0.3125, Accuracy: 377/412 (92%)\n",
      "\n",
      "Train Epoch: 446 [0/1649 (0%)]\tLoss: 0.048904\n",
      "\n",
      "Test set: Average loss: 0.3154, Accuracy: 377/412 (92%)\n",
      "\n",
      "Train Epoch: 447 [0/1649 (0%)]\tLoss: 0.038561\n",
      "\n",
      "Test set: Average loss: 0.3107, Accuracy: 379/412 (92%)\n",
      "\n",
      "Train Epoch: 448 [0/1649 (0%)]\tLoss: 0.064695\n",
      "\n",
      "Test set: Average loss: 0.2787, Accuracy: 381/412 (92%)\n",
      "\n",
      "Train Epoch: 449 [0/1649 (0%)]\tLoss: 0.054670\n",
      "\n",
      "Test set: Average loss: 0.2588, Accuracy: 380/412 (92%)\n",
      "\n",
      "Train Epoch: 450 [0/1649 (0%)]\tLoss: 0.029922\n",
      "\n",
      "Test set: Average loss: 0.2529, Accuracy: 388/412 (94%)\n",
      "\n",
      "Train Epoch: 451 [0/1649 (0%)]\tLoss: 0.074624\n",
      "\n",
      "Test set: Average loss: 0.2471, Accuracy: 384/412 (93%)\n",
      "\n",
      "Train Epoch: 452 [0/1649 (0%)]\tLoss: 0.024948\n",
      "\n",
      "Test set: Average loss: 0.2616, Accuracy: 383/412 (93%)\n",
      "\n",
      "Train Epoch: 453 [0/1649 (0%)]\tLoss: 0.275544\n",
      "\n",
      "Test set: Average loss: 0.2657, Accuracy: 382/412 (93%)\n",
      "\n",
      "Train Epoch: 454 [0/1649 (0%)]\tLoss: 0.040924\n",
      "\n",
      "Test set: Average loss: 0.2745, Accuracy: 379/412 (92%)\n",
      "\n",
      "Train Epoch: 455 [0/1649 (0%)]\tLoss: 0.038383\n",
      "\n",
      "Test set: Average loss: 0.2747, Accuracy: 378/412 (92%)\n",
      "\n",
      "Train Epoch: 456 [0/1649 (0%)]\tLoss: 0.047477\n",
      "\n",
      "Test set: Average loss: 0.2798, Accuracy: 380/412 (92%)\n",
      "\n",
      "Train Epoch: 457 [0/1649 (0%)]\tLoss: 0.055232\n",
      "\n",
      "Test set: Average loss: 0.2850, Accuracy: 378/412 (92%)\n",
      "\n",
      "Train Epoch: 458 [0/1649 (0%)]\tLoss: 0.005158\n",
      "\n",
      "Test set: Average loss: 0.2905, Accuracy: 380/412 (92%)\n",
      "\n",
      "Train Epoch: 459 [0/1649 (0%)]\tLoss: 0.046937\n",
      "\n",
      "Test set: Average loss: 0.2846, Accuracy: 380/412 (92%)\n",
      "\n",
      "Train Epoch: 460 [0/1649 (0%)]\tLoss: 0.158312\n",
      "\n",
      "Test set: Average loss: 0.2674, Accuracy: 381/412 (92%)\n",
      "\n",
      "Train Epoch: 461 [0/1649 (0%)]\tLoss: 0.016169\n",
      "\n",
      "Test set: Average loss: 0.2575, Accuracy: 380/412 (92%)\n",
      "\n",
      "Train Epoch: 462 [0/1649 (0%)]\tLoss: 0.050278\n",
      "\n",
      "Test set: Average loss: 0.2526, Accuracy: 382/412 (93%)\n",
      "\n",
      "Train Epoch: 463 [0/1649 (0%)]\tLoss: 0.022207\n",
      "\n",
      "Test set: Average loss: 0.2506, Accuracy: 382/412 (93%)\n",
      "\n",
      "Train Epoch: 464 [0/1649 (0%)]\tLoss: 0.027441\n",
      "\n",
      "Test set: Average loss: 0.2534, Accuracy: 384/412 (93%)\n",
      "\n",
      "Train Epoch: 465 [0/1649 (0%)]\tLoss: 0.012002\n",
      "\n",
      "Test set: Average loss: 0.2620, Accuracy: 385/412 (93%)\n",
      "\n",
      "Train Epoch: 466 [0/1649 (0%)]\tLoss: 0.022531\n",
      "\n",
      "Test set: Average loss: 0.2699, Accuracy: 384/412 (93%)\n",
      "\n",
      "Train Epoch: 467 [0/1649 (0%)]\tLoss: 0.085135\n",
      "\n",
      "Test set: Average loss: 0.2749, Accuracy: 385/412 (93%)\n",
      "\n",
      "Train Epoch: 468 [0/1649 (0%)]\tLoss: 0.024917\n",
      "\n",
      "Test set: Average loss: 0.2792, Accuracy: 386/412 (94%)\n",
      "\n",
      "Train Epoch: 469 [0/1649 (0%)]\tLoss: 0.048254\n",
      "\n",
      "Test set: Average loss: 0.2811, Accuracy: 385/412 (93%)\n",
      "\n",
      "Train Epoch: 470 [0/1649 (0%)]\tLoss: 0.116037\n",
      "\n",
      "Test set: Average loss: 0.2711, Accuracy: 385/412 (93%)\n",
      "\n",
      "Train Epoch: 471 [0/1649 (0%)]\tLoss: 0.015787\n",
      "\n",
      "Test set: Average loss: 0.2674, Accuracy: 387/412 (94%)\n",
      "\n",
      "Train Epoch: 472 [0/1649 (0%)]\tLoss: 0.041190\n",
      "\n",
      "Test set: Average loss: 0.2719, Accuracy: 385/412 (93%)\n",
      "\n",
      "Train Epoch: 473 [0/1649 (0%)]\tLoss: 0.040114\n",
      "\n",
      "Test set: Average loss: 0.2798, Accuracy: 382/412 (93%)\n",
      "\n",
      "Train Epoch: 474 [0/1649 (0%)]\tLoss: 0.115911\n",
      "\n",
      "Test set: Average loss: 0.2892, Accuracy: 380/412 (92%)\n",
      "\n",
      "Train Epoch: 475 [0/1649 (0%)]\tLoss: 0.018858\n",
      "\n",
      "Test set: Average loss: 0.3048, Accuracy: 373/412 (91%)\n",
      "\n",
      "Train Epoch: 476 [0/1649 (0%)]\tLoss: 0.021449\n",
      "\n",
      "Test set: Average loss: 0.3222, Accuracy: 375/412 (91%)\n",
      "\n",
      "Train Epoch: 477 [0/1649 (0%)]\tLoss: 0.067427\n",
      "\n",
      "Test set: Average loss: 0.3258, Accuracy: 372/412 (90%)\n",
      "\n",
      "Train Epoch: 478 [0/1649 (0%)]\tLoss: 0.064596\n",
      "\n",
      "Test set: Average loss: 0.3162, Accuracy: 376/412 (91%)\n",
      "\n",
      "Train Epoch: 479 [0/1649 (0%)]\tLoss: 0.046954\n",
      "\n",
      "Test set: Average loss: 0.2990, Accuracy: 378/412 (92%)\n",
      "\n",
      "Train Epoch: 480 [0/1649 (0%)]\tLoss: 0.013939\n",
      "\n",
      "Test set: Average loss: 0.2950, Accuracy: 378/412 (92%)\n",
      "\n",
      "Train Epoch: 481 [0/1649 (0%)]\tLoss: 0.018618\n",
      "\n",
      "Test set: Average loss: 0.2987, Accuracy: 378/412 (92%)\n",
      "\n",
      "Train Epoch: 482 [0/1649 (0%)]\tLoss: 0.081466\n",
      "\n",
      "Test set: Average loss: 0.2925, Accuracy: 380/412 (92%)\n",
      "\n",
      "Train Epoch: 483 [0/1649 (0%)]\tLoss: 0.044987\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.2860, Accuracy: 379/412 (92%)\n",
      "\n",
      "Train Epoch: 484 [0/1649 (0%)]\tLoss: 0.004580\n",
      "\n",
      "Test set: Average loss: 0.2820, Accuracy: 379/412 (92%)\n",
      "\n",
      "Train Epoch: 485 [0/1649 (0%)]\tLoss: 0.012084\n",
      "\n",
      "Test set: Average loss: 0.2792, Accuracy: 379/412 (92%)\n",
      "\n",
      "Train Epoch: 486 [0/1649 (0%)]\tLoss: 0.018104\n",
      "\n",
      "Test set: Average loss: 0.2745, Accuracy: 379/412 (92%)\n",
      "\n",
      "Train Epoch: 487 [0/1649 (0%)]\tLoss: 0.025429\n",
      "\n",
      "Test set: Average loss: 0.2718, Accuracy: 383/412 (93%)\n",
      "\n",
      "Train Epoch: 488 [0/1649 (0%)]\tLoss: 0.024925\n",
      "\n",
      "Test set: Average loss: 0.2709, Accuracy: 382/412 (93%)\n",
      "\n",
      "Train Epoch: 489 [0/1649 (0%)]\tLoss: 0.017974\n",
      "\n",
      "Test set: Average loss: 0.2752, Accuracy: 384/412 (93%)\n",
      "\n",
      "Train Epoch: 490 [0/1649 (0%)]\tLoss: 0.005192\n",
      "\n",
      "Test set: Average loss: 0.2820, Accuracy: 382/412 (93%)\n",
      "\n",
      "Train Epoch: 491 [0/1649 (0%)]\tLoss: 0.017328\n",
      "\n",
      "Test set: Average loss: 0.2883, Accuracy: 381/412 (92%)\n",
      "\n",
      "Train Epoch: 492 [0/1649 (0%)]\tLoss: 0.174694\n",
      "\n",
      "Test set: Average loss: 0.2717, Accuracy: 383/412 (93%)\n",
      "\n",
      "Train Epoch: 493 [0/1649 (0%)]\tLoss: 0.023948\n",
      "\n",
      "Test set: Average loss: 0.2676, Accuracy: 380/412 (92%)\n",
      "\n",
      "Train Epoch: 494 [0/1649 (0%)]\tLoss: 0.014821\n",
      "\n",
      "Test set: Average loss: 0.2640, Accuracy: 382/412 (93%)\n",
      "\n",
      "Train Epoch: 495 [0/1649 (0%)]\tLoss: 0.031034\n",
      "\n",
      "Test set: Average loss: 0.2567, Accuracy: 381/412 (92%)\n",
      "\n",
      "Train Epoch: 496 [0/1649 (0%)]\tLoss: 0.047540\n",
      "\n",
      "Test set: Average loss: 0.2486, Accuracy: 381/412 (92%)\n",
      "\n",
      "Train Epoch: 497 [0/1649 (0%)]\tLoss: 0.014239\n",
      "\n",
      "Test set: Average loss: 0.2396, Accuracy: 381/412 (92%)\n",
      "\n",
      "Train Epoch: 498 [0/1649 (0%)]\tLoss: 0.006213\n",
      "\n",
      "Test set: Average loss: 0.2333, Accuracy: 383/412 (93%)\n",
      "\n",
      "Train Epoch: 499 [0/1649 (0%)]\tLoss: 0.002636\n",
      "\n",
      "Test set: Average loss: 0.2295, Accuracy: 383/412 (93%)\n",
      "\n",
      "max acc :  94.1747572815534\n",
      "Used Seed:  1042\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "epoch_arr = range(500)\n",
    "train_loss = []\n",
    "test_loss = []\n",
    "max_test = 0\n",
    "\n",
    "#Entrainement\n",
    "for epoch in epoch_arr:\n",
    "    train_loss.append( train(model, dataloader_train, optimizer, epoch, F.nll_loss))\n",
    "    loss,test_prc = test(model, dataloader_test)\n",
    "    if test_prc > max_test:\n",
    "        max_test = test_prc\n",
    "        torch.save(model.state_dict(), './best.pth')\n",
    "    test_loss.append( loss )\n",
    "print(\"max acc : \",max_test)\n",
    "print(\"Used Seed: \", manualSeed)\n",
    "#Affichage des courbes de loss\n",
    "plt.plot(epoch_arr,train_loss,'b')\n",
    "plt.plot(epoch_arr,test_loss,'g')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Réseau residuel\n",
    "\n",
    "Ici les résultats sont bien meilleurs pouvant atteindre les 95%.\n",
    "\n",
    "Mais il est possible d'aller encore plus loin avec des architectures bien plus complexes.\n",
    "Pour cette expérimentation nous allons essayer de construire une architecture de type ResNet (pour Residual Network).\n",
    "Le principe est simple, après chaque convolution il y a une perte de l'information d'origine, ainsi pour pouvoir conserver ces informations lors du traitement il suffit de sauvegarder les données avant un ensemble de convolution, puis de venir les ajouter à la fin d'un ensemble de convolution. Ce type de d'opération s'appel un block résiduel, dans notre cas nous allons construire des blocks de 2 convolution 3*3, et pour venir injecter les données nous allons simplement faire la somme après la 2ème convolution.\n",
    "Nous allons également utiliser des batchnorms entre chaque convolution pour améliorer les performances du réseau.\n",
    "Ensuite notre réseau final sera constitué 4 bloc résiduel suivit de 2 couches full connected pour ramener l'informations à un ensemble traitable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv3x3(in_planes, out_planes, stride=1):\n",
    "    \"\"\"Convolution 3*3 conservant la taille initiale de l'image en utilsant un padding de 1\"\"\"\n",
    "    return nn.Conv2d(in_planes, out_planes, kernel_size=3, stride=stride,\n",
    "padding=1, bias=False)\n",
    "\n",
    "class ResBlock(nn.Module):\n",
    "    \"\"\"Définition d'un bloc résiduel\"\"\"\n",
    "    def __init__(self, inplanes, planes, stride=1, downsample=None):\n",
    "        super(ResBlock, self).__init__()\n",
    "        self.conv1 = conv3x3(inplanes, planes, stride)\n",
    "        self.bn1 = nn.BatchNorm2d(planes)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.conv2 = conv3x3(planes, planes)\n",
    "        self.bn2 = nn.BatchNorm2d(planes)\n",
    "        #Ajoute une couche supplémentaire pour redimenssioner le résidu si il ne possède pas la même\n",
    "        #forme que la sortie des convolutions\n",
    "        if inplanes != planes:\n",
    "            self.downsample = nn.Sequential(nn.Conv2d(inplanes, planes, kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(planes))\n",
    "        else:\n",
    "            self.downsample = None\n",
    "        self.stride = stride\n",
    "\n",
    "    def forward(self, x):\n",
    "        identity = x\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "\n",
    "        if self.downsample is not None:\n",
    "            identity = self.downsample(x)\n",
    "\n",
    "        out += identity\n",
    "        out = self.relu(out)\n",
    "\n",
    "        return out\n",
    "\n",
    "class Net_RES_32(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net_RES_32, self).__init__()\n",
    "        self.b1 = ResBlock(1,32)\n",
    "        self.b2 = ResBlock(32,32)\n",
    "        self.b3 = ResBlock(32,64)\n",
    "        self.b4 = ResBlock(64,128)\n",
    "        self.fc1 = nn.Linear(64*4*4, 300)\n",
    "        #self.fc1_b = nn.Linear(800, 200)\n",
    "        self.fc2 = nn.Linear(300, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.b1(x)\n",
    "        x = F.max_pool2d(x,2)\n",
    "\n",
    "        x = self.b2(x)\n",
    "        x = F.max_pool2d(x,2)\n",
    "\n",
    "        x = self.b3(x)\n",
    "        x = F.max_pool2d(x,2)\n",
    "        #x = self.b4(x)\n",
    "        #x = F.max_pool2d(x,2)\n",
    "\n",
    "        x = x.view(-1,x.shape[1]*x.shape[2]*x.shape[3])\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        #x = F.relu(self.fc1_b(x))\n",
    "        x = self.fc2(x)\n",
    "        return F.log_softmax(x, dim=1)\n",
    "criterion = nn.NLLLoss()\n",
    "model = Net_RES_32().to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.003)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ce réseau étant bien plus complexe que les précédent nous allons l'entraîner jusqu'à 1000 epoch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 0 [0/1649 (0%)]\tLoss: 2.358273\n",
      "\n",
      "Test set: Average loss: 2.3055, Accuracy: 34/412 (8%)\n",
      "\n",
      "Train Epoch: 1 [0/1649 (0%)]\tLoss: 2.836824\n",
      "\n",
      "Test set: Average loss: 2.3018, Accuracy: 37/412 (9%)\n",
      "\n",
      "Train Epoch: 2 [0/1649 (0%)]\tLoss: 2.729532\n",
      "\n",
      "Test set: Average loss: 2.3027, Accuracy: 47/412 (11%)\n",
      "\n",
      "Train Epoch: 3 [0/1649 (0%)]\tLoss: 2.281057\n",
      "\n",
      "Test set: Average loss: 2.3047, Accuracy: 38/412 (9%)\n",
      "\n",
      "Train Epoch: 4 [0/1649 (0%)]\tLoss: 2.315024\n",
      "\n",
      "Test set: Average loss: 2.3049, Accuracy: 38/412 (9%)\n",
      "\n",
      "Train Epoch: 5 [0/1649 (0%)]\tLoss: 2.270632\n",
      "\n",
      "Test set: Average loss: 2.3005, Accuracy: 38/412 (9%)\n",
      "\n",
      "Train Epoch: 6 [0/1649 (0%)]\tLoss: 2.126606\n",
      "\n",
      "Test set: Average loss: 2.2947, Accuracy: 67/412 (16%)\n",
      "\n",
      "Train Epoch: 7 [0/1649 (0%)]\tLoss: 1.897759\n",
      "\n",
      "Test set: Average loss: 2.2915, Accuracy: 62/412 (15%)\n",
      "\n",
      "Train Epoch: 8 [0/1649 (0%)]\tLoss: 1.829829\n",
      "\n",
      "Test set: Average loss: 2.2898, Accuracy: 68/412 (17%)\n",
      "\n",
      "Train Epoch: 9 [0/1649 (0%)]\tLoss: 1.759290\n",
      "\n",
      "Test set: Average loss: 2.2868, Accuracy: 88/412 (21%)\n",
      "\n",
      "Train Epoch: 10 [0/1649 (0%)]\tLoss: 1.758072\n",
      "\n",
      "Test set: Average loss: 2.2832, Accuracy: 67/412 (16%)\n",
      "\n",
      "Train Epoch: 11 [0/1649 (0%)]\tLoss: 1.518746\n",
      "\n",
      "Test set: Average loss: 2.2806, Accuracy: 43/412 (10%)\n",
      "\n",
      "Train Epoch: 12 [0/1649 (0%)]\tLoss: 1.536932\n",
      "\n",
      "Test set: Average loss: 2.2778, Accuracy: 42/412 (10%)\n",
      "\n",
      "Train Epoch: 13 [0/1649 (0%)]\tLoss: 1.405134\n",
      "\n",
      "Test set: Average loss: 2.2726, Accuracy: 42/412 (10%)\n",
      "\n",
      "Train Epoch: 14 [0/1649 (0%)]\tLoss: 1.525234\n",
      "\n",
      "Test set: Average loss: 2.2667, Accuracy: 42/412 (10%)\n",
      "\n",
      "Train Epoch: 15 [0/1649 (0%)]\tLoss: 1.324855\n",
      "\n",
      "Test set: Average loss: 2.2563, Accuracy: 72/412 (17%)\n",
      "\n",
      "Train Epoch: 16 [0/1649 (0%)]\tLoss: 1.351801\n",
      "\n",
      "Test set: Average loss: 2.2388, Accuracy: 56/412 (14%)\n",
      "\n",
      "Train Epoch: 17 [0/1649 (0%)]\tLoss: 1.083379\n",
      "\n",
      "Test set: Average loss: 2.2174, Accuracy: 60/412 (15%)\n",
      "\n",
      "Train Epoch: 18 [0/1649 (0%)]\tLoss: 0.874884\n",
      "\n",
      "Test set: Average loss: 2.1903, Accuracy: 80/412 (19%)\n",
      "\n",
      "Train Epoch: 19 [0/1649 (0%)]\tLoss: 1.184592\n",
      "\n",
      "Test set: Average loss: 2.1649, Accuracy: 128/412 (31%)\n",
      "\n",
      "Train Epoch: 20 [0/1649 (0%)]\tLoss: 1.318429\n",
      "\n",
      "Test set: Average loss: 2.1624, Accuracy: 130/412 (32%)\n",
      "\n",
      "Train Epoch: 21 [0/1649 (0%)]\tLoss: 1.086646\n",
      "\n",
      "Test set: Average loss: 2.1566, Accuracy: 124/412 (30%)\n",
      "\n",
      "Train Epoch: 22 [0/1649 (0%)]\tLoss: 1.004634\n",
      "\n",
      "Test set: Average loss: 2.1484, Accuracy: 116/412 (28%)\n",
      "\n",
      "Train Epoch: 23 [0/1649 (0%)]\tLoss: 0.898193\n",
      "\n",
      "Test set: Average loss: 2.1364, Accuracy: 65/412 (16%)\n",
      "\n",
      "Train Epoch: 24 [0/1649 (0%)]\tLoss: 1.005016\n",
      "\n",
      "Test set: Average loss: 2.0905, Accuracy: 67/412 (16%)\n",
      "\n",
      "Train Epoch: 25 [0/1649 (0%)]\tLoss: 1.205399\n",
      "\n",
      "Test set: Average loss: 2.0161, Accuracy: 103/412 (25%)\n",
      "\n",
      "Train Epoch: 26 [0/1649 (0%)]\tLoss: 0.776171\n",
      "\n",
      "Test set: Average loss: 1.8513, Accuracy: 198/412 (48%)\n",
      "\n",
      "Train Epoch: 27 [0/1649 (0%)]\tLoss: 0.667495\n",
      "\n",
      "Test set: Average loss: 1.6263, Accuracy: 269/412 (65%)\n",
      "\n",
      "Train Epoch: 28 [0/1649 (0%)]\tLoss: 0.828842\n",
      "\n",
      "Test set: Average loss: 1.4750, Accuracy: 279/412 (68%)\n",
      "\n",
      "Train Epoch: 29 [0/1649 (0%)]\tLoss: 0.686464\n",
      "\n",
      "Test set: Average loss: 1.3556, Accuracy: 289/412 (70%)\n",
      "\n",
      "Train Epoch: 30 [0/1649 (0%)]\tLoss: 0.849444\n",
      "\n",
      "Test set: Average loss: 1.2521, Accuracy: 287/412 (70%)\n",
      "\n",
      "Train Epoch: 31 [0/1649 (0%)]\tLoss: 0.637441\n",
      "\n",
      "Test set: Average loss: 1.2083, Accuracy: 293/412 (71%)\n",
      "\n",
      "Train Epoch: 32 [0/1649 (0%)]\tLoss: 0.895293\n",
      "\n",
      "Test set: Average loss: 1.2079, Accuracy: 281/412 (68%)\n",
      "\n",
      "Train Epoch: 33 [0/1649 (0%)]\tLoss: 0.573137\n",
      "\n",
      "Test set: Average loss: 1.1535, Accuracy: 296/412 (72%)\n",
      "\n",
      "Train Epoch: 34 [0/1649 (0%)]\tLoss: 0.590754\n",
      "\n",
      "Test set: Average loss: 1.0223, Accuracy: 325/412 (79%)\n",
      "\n",
      "Train Epoch: 35 [0/1649 (0%)]\tLoss: 0.760742\n",
      "\n",
      "Test set: Average loss: 0.8932, Accuracy: 355/412 (86%)\n",
      "\n",
      "Train Epoch: 36 [0/1649 (0%)]\tLoss: 0.560838\n",
      "\n",
      "Test set: Average loss: 0.8027, Accuracy: 371/412 (90%)\n",
      "\n",
      "Train Epoch: 37 [0/1649 (0%)]\tLoss: 0.389291\n",
      "\n",
      "Test set: Average loss: 0.7215, Accuracy: 370/412 (90%)\n",
      "\n",
      "Train Epoch: 38 [0/1649 (0%)]\tLoss: 0.419262\n",
      "\n",
      "Test set: Average loss: 0.6505, Accuracy: 368/412 (89%)\n",
      "\n",
      "Train Epoch: 39 [0/1649 (0%)]\tLoss: 0.335477\n",
      "\n",
      "Test set: Average loss: 0.5923, Accuracy: 368/412 (89%)\n",
      "\n",
      "Train Epoch: 40 [0/1649 (0%)]\tLoss: 0.400134\n",
      "\n",
      "Test set: Average loss: 0.5469, Accuracy: 364/412 (88%)\n",
      "\n",
      "Train Epoch: 41 [0/1649 (0%)]\tLoss: 0.370828\n",
      "\n",
      "Test set: Average loss: 0.5146, Accuracy: 363/412 (88%)\n",
      "\n",
      "Train Epoch: 42 [0/1649 (0%)]\tLoss: 0.641510\n",
      "\n",
      "Test set: Average loss: 0.4991, Accuracy: 363/412 (88%)\n",
      "\n",
      "Train Epoch: 43 [0/1649 (0%)]\tLoss: 0.449920\n",
      "\n",
      "Test set: Average loss: 0.5084, Accuracy: 362/412 (88%)\n",
      "\n",
      "Train Epoch: 44 [0/1649 (0%)]\tLoss: 0.392110\n",
      "\n",
      "Test set: Average loss: 0.5062, Accuracy: 363/412 (88%)\n",
      "\n",
      "Train Epoch: 45 [0/1649 (0%)]\tLoss: 0.398311\n",
      "\n",
      "Test set: Average loss: 0.4909, Accuracy: 354/412 (86%)\n",
      "\n",
      "Train Epoch: 46 [0/1649 (0%)]\tLoss: 0.499246\n",
      "\n",
      "Test set: Average loss: 0.4881, Accuracy: 348/412 (84%)\n",
      "\n",
      "Train Epoch: 47 [0/1649 (0%)]\tLoss: 0.459441\n",
      "\n",
      "Test set: Average loss: 0.4511, Accuracy: 351/412 (85%)\n",
      "\n",
      "Train Epoch: 48 [0/1649 (0%)]\tLoss: 0.286624\n",
      "\n",
      "Test set: Average loss: 0.3998, Accuracy: 359/412 (87%)\n",
      "\n",
      "Train Epoch: 49 [0/1649 (0%)]\tLoss: 0.456204\n",
      "\n",
      "Test set: Average loss: 0.3528, Accuracy: 371/412 (90%)\n",
      "\n",
      "Train Epoch: 50 [0/1649 (0%)]\tLoss: 0.391374\n",
      "\n",
      "Test set: Average loss: 0.3090, Accuracy: 381/412 (92%)\n",
      "\n",
      "Train Epoch: 51 [0/1649 (0%)]\tLoss: 0.486488\n",
      "\n",
      "Test set: Average loss: 0.2686, Accuracy: 387/412 (94%)\n",
      "\n",
      "Train Epoch: 52 [0/1649 (0%)]\tLoss: 0.657448\n",
      "\n",
      "Test set: Average loss: 0.2456, Accuracy: 391/412 (95%)\n",
      "\n",
      "Train Epoch: 53 [0/1649 (0%)]\tLoss: 0.156952\n",
      "\n",
      "Test set: Average loss: 0.2544, Accuracy: 386/412 (94%)\n",
      "\n",
      "Train Epoch: 54 [0/1649 (0%)]\tLoss: 0.499326\n",
      "\n",
      "Test set: Average loss: 0.2572, Accuracy: 381/412 (92%)\n",
      "\n",
      "Train Epoch: 55 [0/1649 (0%)]\tLoss: 0.177877\n",
      "\n",
      "Test set: Average loss: 0.2639, Accuracy: 379/412 (92%)\n",
      "\n",
      "Train Epoch: 56 [0/1649 (0%)]\tLoss: 0.497661\n",
      "\n",
      "Test set: Average loss: 0.2734, Accuracy: 377/412 (92%)\n",
      "\n",
      "Train Epoch: 57 [0/1649 (0%)]\tLoss: 0.603861\n",
      "\n",
      "Test set: Average loss: 0.2558, Accuracy: 388/412 (94%)\n",
      "\n",
      "Train Epoch: 58 [0/1649 (0%)]\tLoss: 0.209424\n",
      "\n",
      "Test set: Average loss: 0.2958, Accuracy: 373/412 (91%)\n",
      "\n",
      "Train Epoch: 59 [0/1649 (0%)]\tLoss: 0.174179\n",
      "\n",
      "Test set: Average loss: 0.3826, Accuracy: 352/412 (85%)\n",
      "\n",
      "Train Epoch: 60 [0/1649 (0%)]\tLoss: 0.658006\n",
      "\n",
      "Test set: Average loss: 0.3429, Accuracy: 365/412 (89%)\n",
      "\n",
      "Train Epoch: 61 [0/1649 (0%)]\tLoss: 0.193914\n",
      "\n",
      "Test set: Average loss: 0.2882, Accuracy: 379/412 (92%)\n",
      "\n",
      "Train Epoch: 62 [0/1649 (0%)]\tLoss: 0.265997\n",
      "\n",
      "Test set: Average loss: 0.2767, Accuracy: 379/412 (92%)\n",
      "\n",
      "Train Epoch: 63 [0/1649 (0%)]\tLoss: 0.343691\n",
      "\n",
      "Test set: Average loss: 0.2971, Accuracy: 375/412 (91%)\n",
      "\n",
      "Train Epoch: 64 [0/1649 (0%)]\tLoss: 0.345454\n",
      "\n",
      "Test set: Average loss: 0.2819, Accuracy: 374/412 (91%)\n",
      "\n",
      "Train Epoch: 65 [0/1649 (0%)]\tLoss: 0.303593\n",
      "\n",
      "Test set: Average loss: 0.2293, Accuracy: 387/412 (94%)\n",
      "\n",
      "Train Epoch: 66 [0/1649 (0%)]\tLoss: 0.305067\n",
      "\n",
      "Test set: Average loss: 0.2221, Accuracy: 387/412 (94%)\n",
      "\n",
      "Train Epoch: 67 [0/1649 (0%)]\tLoss: 0.155841\n",
      "\n",
      "Test set: Average loss: 0.2439, Accuracy: 380/412 (92%)\n",
      "\n",
      "Train Epoch: 68 [0/1649 (0%)]\tLoss: 0.286833\n",
      "\n",
      "Test set: Average loss: 0.2276, Accuracy: 382/412 (93%)\n",
      "\n",
      "Train Epoch: 69 [0/1649 (0%)]\tLoss: 0.479695\n",
      "\n",
      "Test set: Average loss: 0.2232, Accuracy: 381/412 (92%)\n",
      "\n",
      "Train Epoch: 70 [0/1649 (0%)]\tLoss: 0.175085\n",
      "\n",
      "Test set: Average loss: 0.2216, Accuracy: 380/412 (92%)\n",
      "\n",
      "Train Epoch: 71 [0/1649 (0%)]\tLoss: 0.135666\n",
      "\n",
      "Test set: Average loss: 0.2413, Accuracy: 380/412 (92%)\n",
      "\n",
      "Train Epoch: 72 [0/1649 (0%)]\tLoss: 0.544596\n",
      "\n",
      "Test set: Average loss: 0.2505, Accuracy: 378/412 (92%)\n",
      "\n",
      "Train Epoch: 73 [0/1649 (0%)]\tLoss: 0.376295\n",
      "\n",
      "Test set: Average loss: 0.2362, Accuracy: 379/412 (92%)\n",
      "\n",
      "Train Epoch: 74 [0/1649 (0%)]\tLoss: 0.226597\n",
      "\n",
      "Test set: Average loss: 0.2263, Accuracy: 381/412 (92%)\n",
      "\n",
      "Train Epoch: 75 [0/1649 (0%)]\tLoss: 0.402959\n",
      "\n",
      "Test set: Average loss: 0.2282, Accuracy: 384/412 (93%)\n",
      "\n",
      "Train Epoch: 76 [0/1649 (0%)]\tLoss: 0.119996\n",
      "\n",
      "Test set: Average loss: 0.2200, Accuracy: 387/412 (94%)\n",
      "\n",
      "Train Epoch: 77 [0/1649 (0%)]\tLoss: 0.117954\n",
      "\n",
      "Test set: Average loss: 0.2194, Accuracy: 388/412 (94%)\n",
      "\n",
      "Train Epoch: 78 [0/1649 (0%)]\tLoss: 0.144611\n",
      "\n",
      "Test set: Average loss: 0.2132, Accuracy: 387/412 (94%)\n",
      "\n",
      "Train Epoch: 79 [0/1649 (0%)]\tLoss: 0.168278\n",
      "\n",
      "Test set: Average loss: 0.1937, Accuracy: 391/412 (95%)\n",
      "\n",
      "Train Epoch: 80 [0/1649 (0%)]\tLoss: 0.281163\n",
      "\n",
      "Test set: Average loss: 0.1754, Accuracy: 393/412 (95%)\n",
      "\n",
      "Train Epoch: 81 [0/1649 (0%)]\tLoss: 0.161492\n",
      "\n",
      "Test set: Average loss: 0.1716, Accuracy: 391/412 (95%)\n",
      "\n",
      "Train Epoch: 82 [0/1649 (0%)]\tLoss: 0.218042\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.1898, Accuracy: 389/412 (94%)\n",
      "\n",
      "Train Epoch: 83 [0/1649 (0%)]\tLoss: 0.045619\n",
      "\n",
      "Test set: Average loss: 0.2321, Accuracy: 382/412 (93%)\n",
      "\n",
      "Train Epoch: 84 [0/1649 (0%)]\tLoss: 0.168882\n",
      "\n",
      "Test set: Average loss: 0.2750, Accuracy: 373/412 (91%)\n",
      "\n",
      "Train Epoch: 85 [0/1649 (0%)]\tLoss: 0.196899\n",
      "\n",
      "Test set: Average loss: 0.2224, Accuracy: 382/412 (93%)\n",
      "\n",
      "Train Epoch: 86 [0/1649 (0%)]\tLoss: 0.213616\n",
      "\n",
      "Test set: Average loss: 0.1885, Accuracy: 388/412 (94%)\n",
      "\n",
      "Train Epoch: 87 [0/1649 (0%)]\tLoss: 0.159544\n",
      "\n",
      "Test set: Average loss: 0.1690, Accuracy: 388/412 (94%)\n",
      "\n",
      "Train Epoch: 88 [0/1649 (0%)]\tLoss: 0.137084\n",
      "\n",
      "Test set: Average loss: 0.2163, Accuracy: 381/412 (92%)\n",
      "\n",
      "Train Epoch: 89 [0/1649 (0%)]\tLoss: 0.084049\n",
      "\n",
      "Test set: Average loss: 0.2863, Accuracy: 369/412 (90%)\n",
      "\n",
      "Train Epoch: 90 [0/1649 (0%)]\tLoss: 0.120719\n",
      "\n",
      "Test set: Average loss: 0.3317, Accuracy: 363/412 (88%)\n",
      "\n",
      "Train Epoch: 91 [0/1649 (0%)]\tLoss: 0.247080\n",
      "\n",
      "Test set: Average loss: 0.3173, Accuracy: 365/412 (89%)\n",
      "\n",
      "Train Epoch: 92 [0/1649 (0%)]\tLoss: 0.214249\n",
      "\n",
      "Test set: Average loss: 0.2629, Accuracy: 368/412 (89%)\n",
      "\n",
      "Train Epoch: 93 [0/1649 (0%)]\tLoss: 0.110382\n",
      "\n",
      "Test set: Average loss: 0.2137, Accuracy: 380/412 (92%)\n",
      "\n",
      "Train Epoch: 94 [0/1649 (0%)]\tLoss: 0.182137\n",
      "\n",
      "Test set: Average loss: 0.1853, Accuracy: 388/412 (94%)\n",
      "\n",
      "Train Epoch: 95 [0/1649 (0%)]\tLoss: 0.153354\n",
      "\n",
      "Test set: Average loss: 0.1935, Accuracy: 388/412 (94%)\n",
      "\n",
      "Train Epoch: 96 [0/1649 (0%)]\tLoss: 0.307093\n",
      "\n",
      "Test set: Average loss: 0.1624, Accuracy: 388/412 (94%)\n",
      "\n",
      "Train Epoch: 97 [0/1649 (0%)]\tLoss: 0.130435\n",
      "\n",
      "Test set: Average loss: 0.1441, Accuracy: 390/412 (95%)\n",
      "\n",
      "Train Epoch: 98 [0/1649 (0%)]\tLoss: 0.203876\n",
      "\n",
      "Test set: Average loss: 0.1422, Accuracy: 394/412 (96%)\n",
      "\n",
      "Train Epoch: 99 [0/1649 (0%)]\tLoss: 0.118512\n",
      "\n",
      "Test set: Average loss: 0.2159, Accuracy: 379/412 (92%)\n",
      "\n",
      "Train Epoch: 100 [0/1649 (0%)]\tLoss: 0.349021\n",
      "\n",
      "Test set: Average loss: 0.4785, Accuracy: 335/412 (81%)\n",
      "\n",
      "Train Epoch: 101 [0/1649 (0%)]\tLoss: 0.176820\n",
      "\n",
      "Test set: Average loss: 0.6573, Accuracy: 317/412 (77%)\n",
      "\n",
      "Train Epoch: 102 [0/1649 (0%)]\tLoss: 0.295429\n",
      "\n",
      "Test set: Average loss: 0.4706, Accuracy: 339/412 (82%)\n",
      "\n",
      "Train Epoch: 103 [0/1649 (0%)]\tLoss: 0.231092\n",
      "\n",
      "Test set: Average loss: 0.2585, Accuracy: 376/412 (91%)\n",
      "\n",
      "Train Epoch: 104 [0/1649 (0%)]\tLoss: 0.038693\n",
      "\n",
      "Test set: Average loss: 0.1611, Accuracy: 392/412 (95%)\n",
      "\n",
      "Train Epoch: 105 [0/1649 (0%)]\tLoss: 0.041451\n",
      "\n",
      "Test set: Average loss: 0.1469, Accuracy: 397/412 (96%)\n",
      "\n",
      "Train Epoch: 106 [0/1649 (0%)]\tLoss: 0.159349\n",
      "\n",
      "Test set: Average loss: 0.1869, Accuracy: 389/412 (94%)\n",
      "\n",
      "Train Epoch: 107 [0/1649 (0%)]\tLoss: 0.127381\n",
      "\n",
      "Test set: Average loss: 0.2830, Accuracy: 373/412 (91%)\n",
      "\n",
      "Train Epoch: 108 [0/1649 (0%)]\tLoss: 0.119032\n",
      "\n",
      "Test set: Average loss: 0.3620, Accuracy: 366/412 (89%)\n",
      "\n",
      "Train Epoch: 109 [0/1649 (0%)]\tLoss: 0.066229\n",
      "\n",
      "Test set: Average loss: 0.4046, Accuracy: 356/412 (86%)\n",
      "\n",
      "Train Epoch: 110 [0/1649 (0%)]\tLoss: 0.119904\n",
      "\n",
      "Test set: Average loss: 0.3628, Accuracy: 356/412 (86%)\n",
      "\n",
      "Train Epoch: 111 [0/1649 (0%)]\tLoss: 0.107111\n",
      "\n",
      "Test set: Average loss: 0.2532, Accuracy: 380/412 (92%)\n",
      "\n",
      "Train Epoch: 112 [0/1649 (0%)]\tLoss: 0.242943\n",
      "\n",
      "Test set: Average loss: 0.1947, Accuracy: 386/412 (94%)\n",
      "\n",
      "Train Epoch: 113 [0/1649 (0%)]\tLoss: 0.193281\n",
      "\n",
      "Test set: Average loss: 0.1693, Accuracy: 391/412 (95%)\n",
      "\n",
      "Train Epoch: 114 [0/1649 (0%)]\tLoss: 0.126583\n",
      "\n",
      "Test set: Average loss: 0.1777, Accuracy: 389/412 (94%)\n",
      "\n",
      "Train Epoch: 115 [0/1649 (0%)]\tLoss: 0.118743\n",
      "\n",
      "Test set: Average loss: 0.1801, Accuracy: 392/412 (95%)\n",
      "\n",
      "Train Epoch: 116 [0/1649 (0%)]\tLoss: 0.316381\n",
      "\n",
      "Test set: Average loss: 0.1318, Accuracy: 397/412 (96%)\n",
      "\n",
      "Train Epoch: 117 [0/1649 (0%)]\tLoss: 0.065265\n",
      "\n",
      "Test set: Average loss: 0.1213, Accuracy: 398/412 (97%)\n",
      "\n",
      "Train Epoch: 118 [0/1649 (0%)]\tLoss: 0.153353\n",
      "\n",
      "Test set: Average loss: 0.1279, Accuracy: 398/412 (97%)\n",
      "\n",
      "Train Epoch: 119 [0/1649 (0%)]\tLoss: 0.077066\n",
      "\n",
      "Test set: Average loss: 0.1428, Accuracy: 396/412 (96%)\n",
      "\n",
      "Train Epoch: 120 [0/1649 (0%)]\tLoss: 0.188849\n",
      "\n",
      "Test set: Average loss: 0.1330, Accuracy: 396/412 (96%)\n",
      "\n",
      "Train Epoch: 121 [0/1649 (0%)]\tLoss: 0.120566\n",
      "\n",
      "Test set: Average loss: 0.1230, Accuracy: 397/412 (96%)\n",
      "\n",
      "Train Epoch: 122 [0/1649 (0%)]\tLoss: 0.080056\n",
      "\n",
      "Test set: Average loss: 0.1221, Accuracy: 393/412 (95%)\n",
      "\n",
      "Train Epoch: 123 [0/1649 (0%)]\tLoss: 0.086486\n",
      "\n",
      "Test set: Average loss: 0.1127, Accuracy: 395/412 (96%)\n",
      "\n",
      "Train Epoch: 124 [0/1649 (0%)]\tLoss: 0.051563\n",
      "\n",
      "Test set: Average loss: 0.1101, Accuracy: 395/412 (96%)\n",
      "\n",
      "Train Epoch: 125 [0/1649 (0%)]\tLoss: 0.279789\n",
      "\n",
      "Test set: Average loss: 0.1153, Accuracy: 397/412 (96%)\n",
      "\n",
      "Train Epoch: 126 [0/1649 (0%)]\tLoss: 0.185931\n",
      "\n",
      "Test set: Average loss: 0.1392, Accuracy: 392/412 (95%)\n",
      "\n",
      "Train Epoch: 127 [0/1649 (0%)]\tLoss: 0.043967\n",
      "\n",
      "Test set: Average loss: 0.1574, Accuracy: 388/412 (94%)\n",
      "\n",
      "Train Epoch: 128 [0/1649 (0%)]\tLoss: 0.031609\n",
      "\n",
      "Test set: Average loss: 0.1802, Accuracy: 383/412 (93%)\n",
      "\n",
      "Train Epoch: 129 [0/1649 (0%)]\tLoss: 0.105834\n",
      "\n",
      "Test set: Average loss: 0.1457, Accuracy: 389/412 (94%)\n",
      "\n",
      "Train Epoch: 130 [0/1649 (0%)]\tLoss: 0.070613\n",
      "\n",
      "Test set: Average loss: 0.0983, Accuracy: 398/412 (97%)\n",
      "\n",
      "Train Epoch: 131 [0/1649 (0%)]\tLoss: 0.080426\n",
      "\n",
      "Test set: Average loss: 0.0889, Accuracy: 401/412 (97%)\n",
      "\n",
      "Train Epoch: 132 [0/1649 (0%)]\tLoss: 0.013552\n",
      "\n",
      "Test set: Average loss: 0.1135, Accuracy: 394/412 (96%)\n",
      "\n",
      "Train Epoch: 133 [0/1649 (0%)]\tLoss: 0.067348\n",
      "\n",
      "Test set: Average loss: 0.1307, Accuracy: 392/412 (95%)\n",
      "\n",
      "Train Epoch: 134 [0/1649 (0%)]\tLoss: 0.131617\n",
      "\n",
      "Test set: Average loss: 0.1720, Accuracy: 385/412 (93%)\n",
      "\n",
      "Train Epoch: 135 [0/1649 (0%)]\tLoss: 0.135791\n",
      "\n",
      "Test set: Average loss: 0.1337, Accuracy: 393/412 (95%)\n",
      "\n",
      "Train Epoch: 136 [0/1649 (0%)]\tLoss: 0.138348\n",
      "\n",
      "Test set: Average loss: 0.0983, Accuracy: 399/412 (97%)\n",
      "\n",
      "Train Epoch: 137 [0/1649 (0%)]\tLoss: 0.028114\n",
      "\n",
      "Test set: Average loss: 0.1127, Accuracy: 396/412 (96%)\n",
      "\n",
      "Train Epoch: 138 [0/1649 (0%)]\tLoss: 0.071193\n",
      "\n",
      "Test set: Average loss: 0.1605, Accuracy: 389/412 (94%)\n",
      "\n",
      "Train Epoch: 139 [0/1649 (0%)]\tLoss: 0.119650\n",
      "\n",
      "Test set: Average loss: 0.2133, Accuracy: 381/412 (92%)\n",
      "\n",
      "Train Epoch: 140 [0/1649 (0%)]\tLoss: 0.200927\n",
      "\n",
      "Test set: Average loss: 0.1378, Accuracy: 395/412 (96%)\n",
      "\n",
      "Train Epoch: 141 [0/1649 (0%)]\tLoss: 0.216715\n",
      "\n",
      "Test set: Average loss: 0.1030, Accuracy: 399/412 (97%)\n",
      "\n",
      "Train Epoch: 142 [0/1649 (0%)]\tLoss: 0.194159\n",
      "\n",
      "Test set: Average loss: 0.0852, Accuracy: 402/412 (98%)\n",
      "\n",
      "Train Epoch: 143 [0/1649 (0%)]\tLoss: 0.037292\n",
      "\n",
      "Test set: Average loss: 0.0823, Accuracy: 401/412 (97%)\n",
      "\n",
      "Train Epoch: 144 [0/1649 (0%)]\tLoss: 0.108033\n",
      "\n",
      "Test set: Average loss: 0.0820, Accuracy: 403/412 (98%)\n",
      "\n",
      "Train Epoch: 145 [0/1649 (0%)]\tLoss: 0.123461\n",
      "\n",
      "Test set: Average loss: 0.0843, Accuracy: 401/412 (97%)\n",
      "\n",
      "Train Epoch: 146 [0/1649 (0%)]\tLoss: 0.306912\n",
      "\n",
      "Test set: Average loss: 0.0951, Accuracy: 400/412 (97%)\n",
      "\n",
      "Train Epoch: 147 [0/1649 (0%)]\tLoss: 0.038889\n",
      "\n",
      "Test set: Average loss: 0.1113, Accuracy: 394/412 (96%)\n",
      "\n",
      "Train Epoch: 148 [0/1649 (0%)]\tLoss: 0.081860\n",
      "\n",
      "Test set: Average loss: 0.1232, Accuracy: 394/412 (96%)\n",
      "\n",
      "Train Epoch: 149 [0/1649 (0%)]\tLoss: 0.102550\n",
      "\n",
      "Test set: Average loss: 0.1104, Accuracy: 396/412 (96%)\n",
      "\n",
      "Train Epoch: 150 [0/1649 (0%)]\tLoss: 0.076204\n",
      "\n",
      "Test set: Average loss: 0.1037, Accuracy: 398/412 (97%)\n",
      "\n",
      "Train Epoch: 151 [0/1649 (0%)]\tLoss: 0.275323\n",
      "\n",
      "Test set: Average loss: 0.1028, Accuracy: 402/412 (98%)\n",
      "\n",
      "Train Epoch: 152 [0/1649 (0%)]\tLoss: 0.063427\n",
      "\n",
      "Test set: Average loss: 0.1353, Accuracy: 396/412 (96%)\n",
      "\n",
      "Train Epoch: 153 [0/1649 (0%)]\tLoss: 0.128987\n",
      "\n",
      "Test set: Average loss: 0.1398, Accuracy: 397/412 (96%)\n",
      "\n",
      "Train Epoch: 154 [0/1649 (0%)]\tLoss: 0.054229\n",
      "\n",
      "Test set: Average loss: 0.1650, Accuracy: 394/412 (96%)\n",
      "\n",
      "Train Epoch: 155 [0/1649 (0%)]\tLoss: 0.093626\n",
      "\n",
      "Test set: Average loss: 0.1594, Accuracy: 395/412 (96%)\n",
      "\n",
      "Train Epoch: 156 [0/1649 (0%)]\tLoss: 0.085627\n",
      "\n",
      "Test set: Average loss: 0.1294, Accuracy: 398/412 (97%)\n",
      "\n",
      "Train Epoch: 157 [0/1649 (0%)]\tLoss: 0.038685\n",
      "\n",
      "Test set: Average loss: 0.1162, Accuracy: 400/412 (97%)\n",
      "\n",
      "Train Epoch: 158 [0/1649 (0%)]\tLoss: 0.080173\n",
      "\n",
      "Test set: Average loss: 0.1037, Accuracy: 401/412 (97%)\n",
      "\n",
      "Train Epoch: 159 [0/1649 (0%)]\tLoss: 0.035732\n",
      "\n",
      "Test set: Average loss: 0.0961, Accuracy: 401/412 (97%)\n",
      "\n",
      "Train Epoch: 160 [0/1649 (0%)]\tLoss: 0.103630\n",
      "\n",
      "Test set: Average loss: 0.0908, Accuracy: 402/412 (98%)\n",
      "\n",
      "Train Epoch: 161 [0/1649 (0%)]\tLoss: 0.049369\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.0885, Accuracy: 401/412 (97%)\n",
      "\n",
      "Train Epoch: 162 [0/1649 (0%)]\tLoss: 0.223296\n",
      "\n",
      "Test set: Average loss: 0.0862, Accuracy: 401/412 (97%)\n",
      "\n",
      "Train Epoch: 163 [0/1649 (0%)]\tLoss: 0.064244\n",
      "\n",
      "Test set: Average loss: 0.0852, Accuracy: 401/412 (97%)\n",
      "\n",
      "Train Epoch: 164 [0/1649 (0%)]\tLoss: 0.116478\n",
      "\n",
      "Test set: Average loss: 0.0837, Accuracy: 401/412 (97%)\n",
      "\n",
      "Train Epoch: 165 [0/1649 (0%)]\tLoss: 0.093019\n",
      "\n",
      "Test set: Average loss: 0.0842, Accuracy: 401/412 (97%)\n",
      "\n",
      "Train Epoch: 166 [0/1649 (0%)]\tLoss: 0.026518\n",
      "\n",
      "Test set: Average loss: 0.0892, Accuracy: 400/412 (97%)\n",
      "\n",
      "Train Epoch: 167 [0/1649 (0%)]\tLoss: 0.071791\n",
      "\n",
      "Test set: Average loss: 0.0771, Accuracy: 402/412 (98%)\n",
      "\n",
      "Train Epoch: 168 [0/1649 (0%)]\tLoss: 0.053593\n",
      "\n",
      "Test set: Average loss: 0.0719, Accuracy: 402/412 (98%)\n",
      "\n",
      "Train Epoch: 169 [0/1649 (0%)]\tLoss: 0.088730\n",
      "\n",
      "Test set: Average loss: 0.0750, Accuracy: 400/412 (97%)\n",
      "\n",
      "Train Epoch: 170 [0/1649 (0%)]\tLoss: 0.027149\n",
      "\n",
      "Test set: Average loss: 0.0918, Accuracy: 399/412 (97%)\n",
      "\n",
      "Train Epoch: 171 [0/1649 (0%)]\tLoss: 0.096125\n",
      "\n",
      "Test set: Average loss: 0.1141, Accuracy: 397/412 (96%)\n",
      "\n",
      "Train Epoch: 172 [0/1649 (0%)]\tLoss: 0.050938\n",
      "\n",
      "Test set: Average loss: 0.1162, Accuracy: 398/412 (97%)\n",
      "\n",
      "Train Epoch: 173 [0/1649 (0%)]\tLoss: 0.087067\n",
      "\n",
      "Test set: Average loss: 0.1058, Accuracy: 400/412 (97%)\n",
      "\n",
      "Train Epoch: 174 [0/1649 (0%)]\tLoss: 0.064920\n",
      "\n",
      "Test set: Average loss: 0.1207, Accuracy: 395/412 (96%)\n",
      "\n",
      "Train Epoch: 175 [0/1649 (0%)]\tLoss: 0.157117\n",
      "\n",
      "Test set: Average loss: 0.1361, Accuracy: 392/412 (95%)\n",
      "\n",
      "Train Epoch: 176 [0/1649 (0%)]\tLoss: 0.073099\n",
      "\n",
      "Test set: Average loss: 0.1128, Accuracy: 399/412 (97%)\n",
      "\n",
      "Train Epoch: 177 [0/1649 (0%)]\tLoss: 0.090315\n",
      "\n",
      "Test set: Average loss: 0.1107, Accuracy: 399/412 (97%)\n",
      "\n",
      "Train Epoch: 178 [0/1649 (0%)]\tLoss: 0.073748\n",
      "\n",
      "Test set: Average loss: 0.1933, Accuracy: 386/412 (94%)\n",
      "\n",
      "Train Epoch: 179 [0/1649 (0%)]\tLoss: 0.037966\n",
      "\n",
      "Test set: Average loss: 0.3324, Accuracy: 367/412 (89%)\n",
      "\n",
      "Train Epoch: 180 [0/1649 (0%)]\tLoss: 0.037078\n",
      "\n",
      "Test set: Average loss: 0.5431, Accuracy: 346/412 (84%)\n",
      "\n",
      "Train Epoch: 181 [0/1649 (0%)]\tLoss: 0.112732\n",
      "\n",
      "Test set: Average loss: 0.3442, Accuracy: 371/412 (90%)\n",
      "\n",
      "Train Epoch: 182 [0/1649 (0%)]\tLoss: 0.128646\n",
      "\n",
      "Test set: Average loss: 0.1742, Accuracy: 395/412 (96%)\n",
      "\n",
      "Train Epoch: 183 [0/1649 (0%)]\tLoss: 0.062630\n",
      "\n",
      "Test set: Average loss: 0.1379, Accuracy: 395/412 (96%)\n",
      "\n",
      "Train Epoch: 184 [0/1649 (0%)]\tLoss: 0.072348\n",
      "\n",
      "Test set: Average loss: 0.1719, Accuracy: 390/412 (95%)\n",
      "\n",
      "Train Epoch: 185 [0/1649 (0%)]\tLoss: 0.079280\n",
      "\n",
      "Test set: Average loss: 0.2449, Accuracy: 384/412 (93%)\n",
      "\n",
      "Train Epoch: 186 [0/1649 (0%)]\tLoss: 0.250440\n",
      "\n",
      "Test set: Average loss: 0.2528, Accuracy: 382/412 (93%)\n",
      "\n",
      "Train Epoch: 187 [0/1649 (0%)]\tLoss: 0.198310\n",
      "\n",
      "Test set: Average loss: 0.2020, Accuracy: 389/412 (94%)\n",
      "\n",
      "Train Epoch: 188 [0/1649 (0%)]\tLoss: 0.169614\n",
      "\n",
      "Test set: Average loss: 0.1651, Accuracy: 392/412 (95%)\n",
      "\n",
      "Train Epoch: 189 [0/1649 (0%)]\tLoss: 0.105179\n",
      "\n",
      "Test set: Average loss: 0.1366, Accuracy: 393/412 (95%)\n",
      "\n",
      "Train Epoch: 190 [0/1649 (0%)]\tLoss: 0.025010\n",
      "\n",
      "Test set: Average loss: 0.1236, Accuracy: 394/412 (96%)\n",
      "\n",
      "Train Epoch: 191 [0/1649 (0%)]\tLoss: 0.157870\n",
      "\n",
      "Test set: Average loss: 0.1019, Accuracy: 395/412 (96%)\n",
      "\n",
      "Train Epoch: 192 [0/1649 (0%)]\tLoss: 0.054002\n",
      "\n",
      "Test set: Average loss: 0.0834, Accuracy: 398/412 (97%)\n",
      "\n",
      "Train Epoch: 193 [0/1649 (0%)]\tLoss: 0.060986\n",
      "\n",
      "Test set: Average loss: 0.0677, Accuracy: 400/412 (97%)\n",
      "\n",
      "Train Epoch: 194 [0/1649 (0%)]\tLoss: 0.056713\n",
      "\n",
      "Test set: Average loss: 0.0543, Accuracy: 404/412 (98%)\n",
      "\n",
      "Train Epoch: 195 [0/1649 (0%)]\tLoss: 0.176805\n",
      "\n",
      "Test set: Average loss: 0.0466, Accuracy: 407/412 (99%)\n",
      "\n",
      "Train Epoch: 196 [0/1649 (0%)]\tLoss: 0.047992\n",
      "\n",
      "Test set: Average loss: 0.0676, Accuracy: 404/412 (98%)\n",
      "\n",
      "Train Epoch: 197 [0/1649 (0%)]\tLoss: 0.217309\n",
      "\n",
      "Test set: Average loss: 0.1008, Accuracy: 392/412 (95%)\n",
      "\n",
      "Train Epoch: 198 [0/1649 (0%)]\tLoss: 0.088609\n",
      "\n",
      "Test set: Average loss: 0.1054, Accuracy: 394/412 (96%)\n",
      "\n",
      "Train Epoch: 199 [0/1649 (0%)]\tLoss: 0.097077\n",
      "\n",
      "Test set: Average loss: 0.1006, Accuracy: 393/412 (95%)\n",
      "\n",
      "Train Epoch: 200 [0/1649 (0%)]\tLoss: 0.137062\n",
      "\n",
      "Test set: Average loss: 0.0612, Accuracy: 399/412 (97%)\n",
      "\n",
      "Train Epoch: 201 [0/1649 (0%)]\tLoss: 0.027009\n",
      "\n",
      "Test set: Average loss: 0.0484, Accuracy: 405/412 (98%)\n",
      "\n",
      "Train Epoch: 202 [0/1649 (0%)]\tLoss: 0.030720\n",
      "\n",
      "Test set: Average loss: 0.0552, Accuracy: 403/412 (98%)\n",
      "\n",
      "Train Epoch: 203 [0/1649 (0%)]\tLoss: 0.100463\n",
      "\n",
      "Test set: Average loss: 0.0728, Accuracy: 400/412 (97%)\n",
      "\n",
      "Train Epoch: 204 [0/1649 (0%)]\tLoss: 0.008663\n",
      "\n",
      "Test set: Average loss: 0.1012, Accuracy: 396/412 (96%)\n",
      "\n",
      "Train Epoch: 205 [0/1649 (0%)]\tLoss: 0.023955\n",
      "\n",
      "Test set: Average loss: 0.1309, Accuracy: 393/412 (95%)\n",
      "\n",
      "Train Epoch: 206 [0/1649 (0%)]\tLoss: 0.059271\n",
      "\n",
      "Test set: Average loss: 0.1613, Accuracy: 387/412 (94%)\n",
      "\n",
      "Train Epoch: 207 [0/1649 (0%)]\tLoss: 0.078645\n",
      "\n",
      "Test set: Average loss: 0.1500, Accuracy: 390/412 (95%)\n",
      "\n",
      "Train Epoch: 208 [0/1649 (0%)]\tLoss: 0.118544\n",
      "\n",
      "Test set: Average loss: 0.1140, Accuracy: 396/412 (96%)\n",
      "\n",
      "Train Epoch: 209 [0/1649 (0%)]\tLoss: 0.039987\n",
      "\n",
      "Test set: Average loss: 0.0956, Accuracy: 398/412 (97%)\n",
      "\n",
      "Train Epoch: 210 [0/1649 (0%)]\tLoss: 0.029079\n",
      "\n",
      "Test set: Average loss: 0.0926, Accuracy: 399/412 (97%)\n",
      "\n",
      "Train Epoch: 211 [0/1649 (0%)]\tLoss: 0.055287\n",
      "\n",
      "Test set: Average loss: 0.0969, Accuracy: 400/412 (97%)\n",
      "\n",
      "Train Epoch: 212 [0/1649 (0%)]\tLoss: 0.021610\n",
      "\n",
      "Test set: Average loss: 0.1171, Accuracy: 394/412 (96%)\n",
      "\n",
      "Train Epoch: 213 [0/1649 (0%)]\tLoss: 0.140653\n",
      "\n",
      "Test set: Average loss: 0.1438, Accuracy: 390/412 (95%)\n",
      "\n",
      "Train Epoch: 214 [0/1649 (0%)]\tLoss: 0.043650\n",
      "\n",
      "Test set: Average loss: 0.1384, Accuracy: 391/412 (95%)\n",
      "\n",
      "Train Epoch: 215 [0/1649 (0%)]\tLoss: 0.037134\n",
      "\n",
      "Test set: Average loss: 0.1223, Accuracy: 394/412 (96%)\n",
      "\n",
      "Train Epoch: 216 [0/1649 (0%)]\tLoss: 0.054021\n",
      "\n",
      "Test set: Average loss: 0.0991, Accuracy: 399/412 (97%)\n",
      "\n",
      "Train Epoch: 217 [0/1649 (0%)]\tLoss: 0.033108\n",
      "\n",
      "Test set: Average loss: 0.0893, Accuracy: 401/412 (97%)\n",
      "\n",
      "Train Epoch: 218 [0/1649 (0%)]\tLoss: 0.133755\n",
      "\n",
      "Test set: Average loss: 0.0868, Accuracy: 398/412 (97%)\n",
      "\n",
      "Train Epoch: 219 [0/1649 (0%)]\tLoss: 0.060021\n",
      "\n",
      "Test set: Average loss: 0.1097, Accuracy: 397/412 (96%)\n",
      "\n",
      "Train Epoch: 220 [0/1649 (0%)]\tLoss: 0.084003\n",
      "\n",
      "Test set: Average loss: 0.1485, Accuracy: 392/412 (95%)\n",
      "\n",
      "Train Epoch: 221 [0/1649 (0%)]\tLoss: 0.250362\n",
      "\n",
      "Test set: Average loss: 0.1266, Accuracy: 397/412 (96%)\n",
      "\n",
      "Train Epoch: 222 [0/1649 (0%)]\tLoss: 0.066757\n",
      "\n",
      "Test set: Average loss: 0.1215, Accuracy: 398/412 (97%)\n",
      "\n",
      "Train Epoch: 223 [0/1649 (0%)]\tLoss: 0.055679\n",
      "\n",
      "Test set: Average loss: 0.1292, Accuracy: 399/412 (97%)\n",
      "\n",
      "Train Epoch: 224 [0/1649 (0%)]\tLoss: 0.034987\n",
      "\n",
      "Test set: Average loss: 0.1430, Accuracy: 395/412 (96%)\n",
      "\n",
      "Train Epoch: 225 [0/1649 (0%)]\tLoss: 0.080995\n",
      "\n",
      "Test set: Average loss: 0.1299, Accuracy: 396/412 (96%)\n",
      "\n",
      "Train Epoch: 226 [0/1649 (0%)]\tLoss: 0.122222\n",
      "\n",
      "Test set: Average loss: 0.1195, Accuracy: 398/412 (97%)\n",
      "\n",
      "Train Epoch: 227 [0/1649 (0%)]\tLoss: 0.085251\n",
      "\n",
      "Test set: Average loss: 0.1072, Accuracy: 396/412 (96%)\n",
      "\n",
      "Train Epoch: 228 [0/1649 (0%)]\tLoss: 0.063143\n",
      "\n",
      "Test set: Average loss: 0.0958, Accuracy: 399/412 (97%)\n",
      "\n",
      "Train Epoch: 229 [0/1649 (0%)]\tLoss: 0.113718\n",
      "\n",
      "Test set: Average loss: 0.1024, Accuracy: 399/412 (97%)\n",
      "\n",
      "Train Epoch: 230 [0/1649 (0%)]\tLoss: 0.020460\n",
      "\n",
      "Test set: Average loss: 0.1223, Accuracy: 399/412 (97%)\n",
      "\n",
      "Train Epoch: 231 [0/1649 (0%)]\tLoss: 0.080066\n",
      "\n",
      "Test set: Average loss: 0.1399, Accuracy: 397/412 (96%)\n",
      "\n",
      "Train Epoch: 232 [0/1649 (0%)]\tLoss: 0.036462\n",
      "\n",
      "Test set: Average loss: 0.1589, Accuracy: 395/412 (96%)\n",
      "\n",
      "Train Epoch: 233 [0/1649 (0%)]\tLoss: 0.102617\n",
      "\n",
      "Test set: Average loss: 0.1860, Accuracy: 393/412 (95%)\n",
      "\n",
      "Train Epoch: 234 [0/1649 (0%)]\tLoss: 0.078882\n",
      "\n",
      "Test set: Average loss: 0.2329, Accuracy: 383/412 (93%)\n",
      "\n",
      "Train Epoch: 235 [0/1649 (0%)]\tLoss: 0.181206\n",
      "\n",
      "Test set: Average loss: 0.2318, Accuracy: 380/412 (92%)\n",
      "\n",
      "Train Epoch: 236 [0/1649 (0%)]\tLoss: 0.062680\n",
      "\n",
      "Test set: Average loss: 0.1935, Accuracy: 385/412 (93%)\n",
      "\n",
      "Train Epoch: 237 [0/1649 (0%)]\tLoss: 0.081803\n",
      "\n",
      "Test set: Average loss: 0.1513, Accuracy: 392/412 (95%)\n",
      "\n",
      "Train Epoch: 238 [0/1649 (0%)]\tLoss: 0.380566\n",
      "\n",
      "Test set: Average loss: 0.1237, Accuracy: 393/412 (95%)\n",
      "\n",
      "Train Epoch: 239 [0/1649 (0%)]\tLoss: 0.052941\n",
      "\n",
      "Test set: Average loss: 0.1062, Accuracy: 396/412 (96%)\n",
      "\n",
      "Train Epoch: 240 [0/1649 (0%)]\tLoss: 0.047872\n",
      "\n",
      "Test set: Average loss: 0.0969, Accuracy: 395/412 (96%)\n",
      "\n",
      "Train Epoch: 241 [0/1649 (0%)]\tLoss: 0.096201\n",
      "\n",
      "Test set: Average loss: 0.0932, Accuracy: 396/412 (96%)\n",
      "\n",
      "Train Epoch: 242 [0/1649 (0%)]\tLoss: 0.098259\n",
      "\n",
      "Test set: Average loss: 0.0872, Accuracy: 397/412 (96%)\n",
      "\n",
      "Train Epoch: 243 [0/1649 (0%)]\tLoss: 0.032601\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.0864, Accuracy: 397/412 (96%)\n",
      "\n",
      "Train Epoch: 244 [0/1649 (0%)]\tLoss: 0.087744\n",
      "\n",
      "Test set: Average loss: 0.0711, Accuracy: 399/412 (97%)\n",
      "\n",
      "Train Epoch: 245 [0/1649 (0%)]\tLoss: 0.050343\n",
      "\n",
      "Test set: Average loss: 0.0652, Accuracy: 402/412 (98%)\n",
      "\n",
      "Train Epoch: 246 [0/1649 (0%)]\tLoss: 0.012726\n",
      "\n",
      "Test set: Average loss: 0.0679, Accuracy: 403/412 (98%)\n",
      "\n",
      "Train Epoch: 247 [0/1649 (0%)]\tLoss: 0.055885\n",
      "\n",
      "Test set: Average loss: 0.0786, Accuracy: 402/412 (98%)\n",
      "\n",
      "Train Epoch: 248 [0/1649 (0%)]\tLoss: 0.049402\n",
      "\n",
      "Test set: Average loss: 0.0865, Accuracy: 402/412 (98%)\n",
      "\n",
      "Train Epoch: 249 [0/1649 (0%)]\tLoss: 0.041492\n",
      "\n",
      "Test set: Average loss: 0.0919, Accuracy: 402/412 (98%)\n",
      "\n",
      "Train Epoch: 250 [0/1649 (0%)]\tLoss: 0.165295\n",
      "\n",
      "Test set: Average loss: 0.0967, Accuracy: 402/412 (98%)\n",
      "\n",
      "Train Epoch: 251 [0/1649 (0%)]\tLoss: 0.086837\n",
      "\n",
      "Test set: Average loss: 0.0906, Accuracy: 402/412 (98%)\n",
      "\n",
      "Train Epoch: 252 [0/1649 (0%)]\tLoss: 0.041552\n",
      "\n",
      "Test set: Average loss: 0.0860, Accuracy: 402/412 (98%)\n",
      "\n",
      "Train Epoch: 253 [0/1649 (0%)]\tLoss: 0.030855\n",
      "\n",
      "Test set: Average loss: 0.0789, Accuracy: 402/412 (98%)\n",
      "\n",
      "Train Epoch: 254 [0/1649 (0%)]\tLoss: 0.014972\n",
      "\n",
      "Test set: Average loss: 0.0758, Accuracy: 402/412 (98%)\n",
      "\n",
      "Train Epoch: 255 [0/1649 (0%)]\tLoss: 0.022294\n",
      "\n",
      "Test set: Average loss: 0.0737, Accuracy: 403/412 (98%)\n",
      "\n",
      "Train Epoch: 256 [0/1649 (0%)]\tLoss: 0.089565\n",
      "\n",
      "Test set: Average loss: 0.0701, Accuracy: 403/412 (98%)\n",
      "\n",
      "Train Epoch: 257 [0/1649 (0%)]\tLoss: 0.123710\n",
      "\n",
      "Test set: Average loss: 0.0735, Accuracy: 402/412 (98%)\n",
      "\n",
      "Train Epoch: 258 [0/1649 (0%)]\tLoss: 0.066648\n",
      "\n",
      "Test set: Average loss: 0.0837, Accuracy: 402/412 (98%)\n",
      "\n",
      "Train Epoch: 259 [0/1649 (0%)]\tLoss: 0.058181\n",
      "\n",
      "Test set: Average loss: 0.0999, Accuracy: 397/412 (96%)\n",
      "\n",
      "Train Epoch: 260 [0/1649 (0%)]\tLoss: 0.043498\n",
      "\n",
      "Test set: Average loss: 0.1195, Accuracy: 394/412 (96%)\n",
      "\n",
      "Train Epoch: 261 [0/1649 (0%)]\tLoss: 0.096101\n",
      "\n",
      "Test set: Average loss: 0.1325, Accuracy: 394/412 (96%)\n",
      "\n",
      "Train Epoch: 262 [0/1649 (0%)]\tLoss: 0.070170\n",
      "\n",
      "Test set: Average loss: 0.1348, Accuracy: 393/412 (95%)\n",
      "\n",
      "Train Epoch: 263 [0/1649 (0%)]\tLoss: 0.027726\n",
      "\n",
      "Test set: Average loss: 0.1427, Accuracy: 389/412 (94%)\n",
      "\n",
      "Train Epoch: 264 [0/1649 (0%)]\tLoss: 0.106080\n",
      "\n",
      "Test set: Average loss: 0.1192, Accuracy: 393/412 (95%)\n",
      "\n",
      "Train Epoch: 265 [0/1649 (0%)]\tLoss: 0.026355\n",
      "\n",
      "Test set: Average loss: 0.0909, Accuracy: 400/412 (97%)\n",
      "\n",
      "Train Epoch: 266 [0/1649 (0%)]\tLoss: 0.065573\n",
      "\n",
      "Test set: Average loss: 0.0728, Accuracy: 404/412 (98%)\n",
      "\n",
      "Train Epoch: 267 [0/1649 (0%)]\tLoss: 0.076496\n",
      "\n",
      "Test set: Average loss: 0.0636, Accuracy: 404/412 (98%)\n",
      "\n",
      "Train Epoch: 268 [0/1649 (0%)]\tLoss: 0.022512\n",
      "\n",
      "Test set: Average loss: 0.0757, Accuracy: 400/412 (97%)\n",
      "\n",
      "Train Epoch: 269 [0/1649 (0%)]\tLoss: 0.046420\n",
      "\n",
      "Test set: Average loss: 0.1150, Accuracy: 399/412 (97%)\n",
      "\n",
      "Train Epoch: 270 [0/1649 (0%)]\tLoss: 0.030517\n",
      "\n",
      "Test set: Average loss: 0.1651, Accuracy: 393/412 (95%)\n",
      "\n",
      "Train Epoch: 271 [0/1649 (0%)]\tLoss: 0.095078\n",
      "\n",
      "Test set: Average loss: 0.1753, Accuracy: 392/412 (95%)\n",
      "\n",
      "Train Epoch: 272 [0/1649 (0%)]\tLoss: 0.023078\n",
      "\n",
      "Test set: Average loss: 0.1888, Accuracy: 390/412 (95%)\n",
      "\n",
      "Train Epoch: 273 [0/1649 (0%)]\tLoss: 0.052348\n",
      "\n",
      "Test set: Average loss: 0.1859, Accuracy: 390/412 (95%)\n",
      "\n",
      "Train Epoch: 274 [0/1649 (0%)]\tLoss: 0.025899\n",
      "\n",
      "Test set: Average loss: 0.1717, Accuracy: 391/412 (95%)\n",
      "\n",
      "Train Epoch: 275 [0/1649 (0%)]\tLoss: 0.019560\n",
      "\n",
      "Test set: Average loss: 0.1503, Accuracy: 393/412 (95%)\n",
      "\n",
      "Train Epoch: 276 [0/1649 (0%)]\tLoss: 0.043527\n",
      "\n",
      "Test set: Average loss: 0.1432, Accuracy: 394/412 (96%)\n",
      "\n",
      "Train Epoch: 277 [0/1649 (0%)]\tLoss: 0.022579\n",
      "\n",
      "Test set: Average loss: 0.1340, Accuracy: 395/412 (96%)\n",
      "\n",
      "Train Epoch: 278 [0/1649 (0%)]\tLoss: 0.168130\n",
      "\n",
      "Test set: Average loss: 0.1176, Accuracy: 395/412 (96%)\n",
      "\n",
      "Train Epoch: 279 [0/1649 (0%)]\tLoss: 0.013652\n",
      "\n",
      "Test set: Average loss: 0.1150, Accuracy: 396/412 (96%)\n",
      "\n",
      "Train Epoch: 280 [0/1649 (0%)]\tLoss: 0.014096\n",
      "\n",
      "Test set: Average loss: 0.1093, Accuracy: 398/412 (97%)\n",
      "\n",
      "Train Epoch: 281 [0/1649 (0%)]\tLoss: 0.019968\n",
      "\n",
      "Test set: Average loss: 0.1032, Accuracy: 398/412 (97%)\n",
      "\n",
      "Train Epoch: 282 [0/1649 (0%)]\tLoss: 0.002210\n",
      "\n",
      "Test set: Average loss: 0.1000, Accuracy: 400/412 (97%)\n",
      "\n",
      "Train Epoch: 283 [0/1649 (0%)]\tLoss: 0.006832\n",
      "\n",
      "Test set: Average loss: 0.0948, Accuracy: 401/412 (97%)\n",
      "\n",
      "Train Epoch: 284 [0/1649 (0%)]\tLoss: 0.018247\n",
      "\n",
      "Test set: Average loss: 0.0938, Accuracy: 403/412 (98%)\n",
      "\n",
      "Train Epoch: 285 [0/1649 (0%)]\tLoss: 0.004539\n",
      "\n",
      "Test set: Average loss: 0.0944, Accuracy: 403/412 (98%)\n",
      "\n",
      "Train Epoch: 286 [0/1649 (0%)]\tLoss: 0.012270\n",
      "\n",
      "Test set: Average loss: 0.0924, Accuracy: 403/412 (98%)\n",
      "\n",
      "Train Epoch: 287 [0/1649 (0%)]\tLoss: 0.102488\n",
      "\n",
      "Test set: Average loss: 0.0944, Accuracy: 400/412 (97%)\n",
      "\n",
      "Train Epoch: 288 [0/1649 (0%)]\tLoss: 0.040719\n",
      "\n",
      "Test set: Average loss: 0.0936, Accuracy: 400/412 (97%)\n",
      "\n",
      "Train Epoch: 289 [0/1649 (0%)]\tLoss: 0.005188\n",
      "\n",
      "Test set: Average loss: 0.0943, Accuracy: 400/412 (97%)\n",
      "\n",
      "Train Epoch: 290 [0/1649 (0%)]\tLoss: 0.020003\n",
      "\n",
      "Test set: Average loss: 0.0888, Accuracy: 401/412 (97%)\n",
      "\n",
      "Train Epoch: 291 [0/1649 (0%)]\tLoss: 0.024493\n",
      "\n",
      "Test set: Average loss: 0.0882, Accuracy: 402/412 (98%)\n",
      "\n",
      "Train Epoch: 292 [0/1649 (0%)]\tLoss: 0.006132\n",
      "\n",
      "Test set: Average loss: 0.0901, Accuracy: 401/412 (97%)\n",
      "\n",
      "Train Epoch: 293 [0/1649 (0%)]\tLoss: 0.006849\n",
      "\n",
      "Test set: Average loss: 0.0931, Accuracy: 402/412 (98%)\n",
      "\n",
      "Train Epoch: 294 [0/1649 (0%)]\tLoss: 0.011011\n",
      "\n",
      "Test set: Average loss: 0.0939, Accuracy: 403/412 (98%)\n",
      "\n",
      "Train Epoch: 295 [0/1649 (0%)]\tLoss: 0.164205\n",
      "\n",
      "Test set: Average loss: 0.0948, Accuracy: 401/412 (97%)\n",
      "\n",
      "Train Epoch: 296 [0/1649 (0%)]\tLoss: 0.019658\n",
      "\n",
      "Test set: Average loss: 0.0983, Accuracy: 400/412 (97%)\n",
      "\n",
      "Train Epoch: 297 [0/1649 (0%)]\tLoss: 0.075231\n",
      "\n",
      "Test set: Average loss: 0.0807, Accuracy: 404/412 (98%)\n",
      "\n",
      "Train Epoch: 298 [0/1649 (0%)]\tLoss: 0.014705\n",
      "\n",
      "Test set: Average loss: 0.0749, Accuracy: 405/412 (98%)\n",
      "\n",
      "Train Epoch: 299 [0/1649 (0%)]\tLoss: 0.028750\n",
      "\n",
      "Test set: Average loss: 0.0718, Accuracy: 405/412 (98%)\n",
      "\n",
      "Train Epoch: 300 [0/1649 (0%)]\tLoss: 0.036022\n",
      "\n",
      "Test set: Average loss: 0.0740, Accuracy: 404/412 (98%)\n",
      "\n",
      "Train Epoch: 301 [0/1649 (0%)]\tLoss: 0.008475\n",
      "\n",
      "Test set: Average loss: 0.0914, Accuracy: 401/412 (97%)\n",
      "\n",
      "Train Epoch: 302 [0/1649 (0%)]\tLoss: 0.016343\n",
      "\n",
      "Test set: Average loss: 0.1145, Accuracy: 400/412 (97%)\n",
      "\n",
      "Train Epoch: 303 [0/1649 (0%)]\tLoss: 0.042482\n",
      "\n",
      "Test set: Average loss: 0.1385, Accuracy: 396/412 (96%)\n",
      "\n",
      "Train Epoch: 304 [0/1649 (0%)]\tLoss: 0.051140\n",
      "\n",
      "Test set: Average loss: 0.1518, Accuracy: 394/412 (96%)\n",
      "\n",
      "Train Epoch: 305 [0/1649 (0%)]\tLoss: 0.076114\n",
      "\n",
      "Test set: Average loss: 0.1582, Accuracy: 395/412 (96%)\n",
      "\n",
      "Train Epoch: 306 [0/1649 (0%)]\tLoss: 0.088247\n",
      "\n",
      "Test set: Average loss: 0.1512, Accuracy: 393/412 (95%)\n",
      "\n",
      "Train Epoch: 307 [0/1649 (0%)]\tLoss: 0.050620\n",
      "\n",
      "Test set: Average loss: 0.1103, Accuracy: 400/412 (97%)\n",
      "\n",
      "Train Epoch: 308 [0/1649 (0%)]\tLoss: 0.016745\n",
      "\n",
      "Test set: Average loss: 0.1013, Accuracy: 399/412 (97%)\n",
      "\n",
      "Train Epoch: 309 [0/1649 (0%)]\tLoss: 0.008371\n",
      "\n",
      "Test set: Average loss: 0.1014, Accuracy: 398/412 (97%)\n",
      "\n",
      "Train Epoch: 310 [0/1649 (0%)]\tLoss: 0.122169\n",
      "\n",
      "Test set: Average loss: 0.0905, Accuracy: 402/412 (98%)\n",
      "\n",
      "Train Epoch: 311 [0/1649 (0%)]\tLoss: 0.069436\n",
      "\n",
      "Test set: Average loss: 0.0786, Accuracy: 404/412 (98%)\n",
      "\n",
      "Train Epoch: 312 [0/1649 (0%)]\tLoss: 0.220396\n",
      "\n",
      "Test set: Average loss: 0.0642, Accuracy: 403/412 (98%)\n",
      "\n",
      "Train Epoch: 313 [0/1649 (0%)]\tLoss: 0.015854\n",
      "\n",
      "Test set: Average loss: 0.0601, Accuracy: 404/412 (98%)\n",
      "\n",
      "Train Epoch: 314 [0/1649 (0%)]\tLoss: 0.017034\n",
      "\n",
      "Test set: Average loss: 0.0607, Accuracy: 403/412 (98%)\n",
      "\n",
      "Train Epoch: 315 [0/1649 (0%)]\tLoss: 0.017667\n",
      "\n",
      "Test set: Average loss: 0.0641, Accuracy: 403/412 (98%)\n",
      "\n",
      "Train Epoch: 316 [0/1649 (0%)]\tLoss: 0.064350\n",
      "\n",
      "Test set: Average loss: 0.0693, Accuracy: 403/412 (98%)\n",
      "\n",
      "Train Epoch: 317 [0/1649 (0%)]\tLoss: 0.019914\n",
      "\n",
      "Test set: Average loss: 0.0760, Accuracy: 402/412 (98%)\n",
      "\n",
      "Train Epoch: 318 [0/1649 (0%)]\tLoss: 0.191983\n",
      "\n",
      "Test set: Average loss: 0.0902, Accuracy: 402/412 (98%)\n",
      "\n",
      "Train Epoch: 319 [0/1649 (0%)]\tLoss: 0.028890\n",
      "\n",
      "Test set: Average loss: 0.1147, Accuracy: 397/412 (96%)\n",
      "\n",
      "Train Epoch: 320 [0/1649 (0%)]\tLoss: 0.031648\n",
      "\n",
      "Test set: Average loss: 0.1278, Accuracy: 395/412 (96%)\n",
      "\n",
      "Train Epoch: 321 [0/1649 (0%)]\tLoss: 0.007749\n",
      "\n",
      "Test set: Average loss: 0.1385, Accuracy: 396/412 (96%)\n",
      "\n",
      "Train Epoch: 322 [0/1649 (0%)]\tLoss: 0.118621\n",
      "\n",
      "Test set: Average loss: 0.1091, Accuracy: 399/412 (97%)\n",
      "\n",
      "Train Epoch: 323 [0/1649 (0%)]\tLoss: 0.016144\n",
      "\n",
      "Test set: Average loss: 0.1160, Accuracy: 400/412 (97%)\n",
      "\n",
      "Train Epoch: 324 [0/1649 (0%)]\tLoss: 0.119875\n",
      "\n",
      "Test set: Average loss: 0.1348, Accuracy: 394/412 (96%)\n",
      "\n",
      "Train Epoch: 325 [0/1649 (0%)]\tLoss: 0.072492\n",
      "\n",
      "Test set: Average loss: 0.1482, Accuracy: 390/412 (95%)\n",
      "\n",
      "Train Epoch: 326 [0/1649 (0%)]\tLoss: 0.106017\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.1510, Accuracy: 391/412 (95%)\n",
      "\n",
      "Train Epoch: 327 [0/1649 (0%)]\tLoss: 0.250072\n",
      "\n",
      "Test set: Average loss: 0.1572, Accuracy: 393/412 (95%)\n",
      "\n",
      "Train Epoch: 328 [0/1649 (0%)]\tLoss: 0.051613\n",
      "\n",
      "Test set: Average loss: 0.1482, Accuracy: 389/412 (94%)\n",
      "\n",
      "Train Epoch: 329 [0/1649 (0%)]\tLoss: 0.178585\n",
      "\n",
      "Test set: Average loss: 0.1516, Accuracy: 393/412 (95%)\n",
      "\n",
      "Train Epoch: 330 [0/1649 (0%)]\tLoss: 0.047790\n",
      "\n",
      "Test set: Average loss: 0.1485, Accuracy: 394/412 (96%)\n",
      "\n",
      "Train Epoch: 331 [0/1649 (0%)]\tLoss: 0.059252\n",
      "\n",
      "Test set: Average loss: 0.1603, Accuracy: 393/412 (95%)\n",
      "\n",
      "Train Epoch: 332 [0/1649 (0%)]\tLoss: 0.103289\n",
      "\n",
      "Test set: Average loss: 0.1627, Accuracy: 392/412 (95%)\n",
      "\n",
      "Train Epoch: 333 [0/1649 (0%)]\tLoss: 0.155707\n",
      "\n",
      "Test set: Average loss: 0.1610, Accuracy: 390/412 (95%)\n",
      "\n",
      "Train Epoch: 334 [0/1649 (0%)]\tLoss: 0.088239\n",
      "\n",
      "Test set: Average loss: 0.1554, Accuracy: 393/412 (95%)\n",
      "\n",
      "Train Epoch: 335 [0/1649 (0%)]\tLoss: 0.112976\n",
      "\n",
      "Test set: Average loss: 0.1216, Accuracy: 398/412 (97%)\n",
      "\n",
      "Train Epoch: 336 [0/1649 (0%)]\tLoss: 0.030308\n",
      "\n",
      "Test set: Average loss: 0.0998, Accuracy: 402/412 (98%)\n",
      "\n",
      "Train Epoch: 337 [0/1649 (0%)]\tLoss: 0.011971\n",
      "\n",
      "Test set: Average loss: 0.1012, Accuracy: 402/412 (98%)\n",
      "\n",
      "Train Epoch: 338 [0/1649 (0%)]\tLoss: 0.004689\n",
      "\n",
      "Test set: Average loss: 0.1155, Accuracy: 398/412 (97%)\n",
      "\n",
      "Train Epoch: 339 [0/1649 (0%)]\tLoss: 0.026591\n",
      "\n",
      "Test set: Average loss: 0.1327, Accuracy: 396/412 (96%)\n",
      "\n",
      "Train Epoch: 340 [0/1649 (0%)]\tLoss: 0.156699\n",
      "\n",
      "Test set: Average loss: 0.0902, Accuracy: 399/412 (97%)\n",
      "\n",
      "Train Epoch: 341 [0/1649 (0%)]\tLoss: 0.030071\n",
      "\n",
      "Test set: Average loss: 0.0761, Accuracy: 403/412 (98%)\n",
      "\n",
      "Train Epoch: 342 [0/1649 (0%)]\tLoss: 0.149522\n",
      "\n",
      "Test set: Average loss: 0.0931, Accuracy: 398/412 (97%)\n",
      "\n",
      "Train Epoch: 343 [0/1649 (0%)]\tLoss: 0.015526\n",
      "\n",
      "Test set: Average loss: 0.2124, Accuracy: 386/412 (94%)\n",
      "\n",
      "Train Epoch: 344 [0/1649 (0%)]\tLoss: 0.054184\n",
      "\n",
      "Test set: Average loss: 0.5341, Accuracy: 347/412 (84%)\n",
      "\n",
      "Train Epoch: 345 [0/1649 (0%)]\tLoss: 0.155218\n",
      "\n",
      "Test set: Average loss: 0.8258, Accuracy: 335/412 (81%)\n",
      "\n",
      "Train Epoch: 346 [0/1649 (0%)]\tLoss: 0.068294\n",
      "\n",
      "Test set: Average loss: 0.9456, Accuracy: 327/412 (79%)\n",
      "\n",
      "Train Epoch: 347 [0/1649 (0%)]\tLoss: 0.162249\n",
      "\n",
      "Test set: Average loss: 0.5304, Accuracy: 343/412 (83%)\n",
      "\n",
      "Train Epoch: 348 [0/1649 (0%)]\tLoss: 0.026095\n",
      "\n",
      "Test set: Average loss: 0.3373, Accuracy: 372/412 (90%)\n",
      "\n",
      "Train Epoch: 349 [0/1649 (0%)]\tLoss: 0.014589\n",
      "\n",
      "Test set: Average loss: 0.2964, Accuracy: 375/412 (91%)\n",
      "\n",
      "Train Epoch: 350 [0/1649 (0%)]\tLoss: 0.083162\n",
      "\n",
      "Test set: Average loss: 0.2484, Accuracy: 381/412 (92%)\n",
      "\n",
      "Train Epoch: 351 [0/1649 (0%)]\tLoss: 0.063639\n",
      "\n",
      "Test set: Average loss: 0.2113, Accuracy: 388/412 (94%)\n",
      "\n",
      "Train Epoch: 352 [0/1649 (0%)]\tLoss: 0.046438\n",
      "\n",
      "Test set: Average loss: 0.1884, Accuracy: 395/412 (96%)\n",
      "\n",
      "Train Epoch: 353 [0/1649 (0%)]\tLoss: 0.050006\n",
      "\n",
      "Test set: Average loss: 0.1460, Accuracy: 400/412 (97%)\n",
      "\n",
      "Train Epoch: 354 [0/1649 (0%)]\tLoss: 0.016968\n",
      "\n",
      "Test set: Average loss: 0.1186, Accuracy: 403/412 (98%)\n",
      "\n",
      "Train Epoch: 355 [0/1649 (0%)]\tLoss: 0.123386\n",
      "\n",
      "Test set: Average loss: 0.0883, Accuracy: 401/412 (97%)\n",
      "\n",
      "Train Epoch: 356 [0/1649 (0%)]\tLoss: 0.019629\n",
      "\n",
      "Test set: Average loss: 0.0728, Accuracy: 401/412 (97%)\n",
      "\n",
      "Train Epoch: 357 [0/1649 (0%)]\tLoss: 0.068222\n",
      "\n",
      "Test set: Average loss: 0.0653, Accuracy: 402/412 (98%)\n",
      "\n",
      "Train Epoch: 358 [0/1649 (0%)]\tLoss: 0.011070\n",
      "\n",
      "Test set: Average loss: 0.0679, Accuracy: 403/412 (98%)\n",
      "\n",
      "Train Epoch: 359 [0/1649 (0%)]\tLoss: 0.029730\n",
      "\n",
      "Test set: Average loss: 0.0797, Accuracy: 398/412 (97%)\n",
      "\n",
      "Train Epoch: 360 [0/1649 (0%)]\tLoss: 0.035122\n",
      "\n",
      "Test set: Average loss: 0.0900, Accuracy: 398/412 (97%)\n",
      "\n",
      "Train Epoch: 361 [0/1649 (0%)]\tLoss: 0.045561\n",
      "\n",
      "Test set: Average loss: 0.1031, Accuracy: 397/412 (96%)\n",
      "\n",
      "Train Epoch: 362 [0/1649 (0%)]\tLoss: 0.018672\n",
      "\n",
      "Test set: Average loss: 0.1079, Accuracy: 398/412 (97%)\n",
      "\n",
      "Train Epoch: 363 [0/1649 (0%)]\tLoss: 0.050594\n",
      "\n",
      "Test set: Average loss: 0.1139, Accuracy: 398/412 (97%)\n",
      "\n",
      "Train Epoch: 364 [0/1649 (0%)]\tLoss: 0.026560\n",
      "\n",
      "Test set: Average loss: 0.1150, Accuracy: 397/412 (96%)\n",
      "\n",
      "Train Epoch: 365 [0/1649 (0%)]\tLoss: 0.109890\n",
      "\n",
      "Test set: Average loss: 0.1012, Accuracy: 397/412 (96%)\n",
      "\n",
      "Train Epoch: 366 [0/1649 (0%)]\tLoss: 0.057835\n",
      "\n",
      "Test set: Average loss: 0.0804, Accuracy: 399/412 (97%)\n",
      "\n",
      "Train Epoch: 367 [0/1649 (0%)]\tLoss: 0.051692\n",
      "\n",
      "Test set: Average loss: 0.0637, Accuracy: 403/412 (98%)\n",
      "\n",
      "Train Epoch: 368 [0/1649 (0%)]\tLoss: 0.017203\n",
      "\n",
      "Test set: Average loss: 0.0604, Accuracy: 403/412 (98%)\n",
      "\n",
      "Train Epoch: 369 [0/1649 (0%)]\tLoss: 0.020316\n",
      "\n",
      "Test set: Average loss: 0.0579, Accuracy: 404/412 (98%)\n",
      "\n",
      "Train Epoch: 370 [0/1649 (0%)]\tLoss: 0.023564\n",
      "\n",
      "Test set: Average loss: 0.0658, Accuracy: 401/412 (97%)\n",
      "\n",
      "Train Epoch: 371 [0/1649 (0%)]\tLoss: 0.012076\n",
      "\n",
      "Test set: Average loss: 0.0772, Accuracy: 400/412 (97%)\n",
      "\n",
      "Train Epoch: 372 [0/1649 (0%)]\tLoss: 0.012854\n",
      "\n",
      "Test set: Average loss: 0.0898, Accuracy: 400/412 (97%)\n",
      "\n",
      "Train Epoch: 373 [0/1649 (0%)]\tLoss: 0.072178\n",
      "\n",
      "Test set: Average loss: 0.0784, Accuracy: 399/412 (97%)\n",
      "\n",
      "Train Epoch: 374 [0/1649 (0%)]\tLoss: 0.366130\n",
      "\n",
      "Test set: Average loss: 0.0792, Accuracy: 402/412 (98%)\n",
      "\n",
      "Train Epoch: 375 [0/1649 (0%)]\tLoss: 0.134253\n",
      "\n",
      "Test set: Average loss: 0.0741, Accuracy: 406/412 (99%)\n",
      "\n",
      "Train Epoch: 376 [0/1649 (0%)]\tLoss: 0.001256\n",
      "\n",
      "Test set: Average loss: 0.0809, Accuracy: 404/412 (98%)\n",
      "\n",
      "Train Epoch: 377 [0/1649 (0%)]\tLoss: 0.004025\n",
      "\n",
      "Test set: Average loss: 0.0970, Accuracy: 402/412 (98%)\n",
      "\n",
      "Train Epoch: 378 [0/1649 (0%)]\tLoss: 0.007710\n",
      "\n",
      "Test set: Average loss: 0.1241, Accuracy: 396/412 (96%)\n",
      "\n",
      "Train Epoch: 379 [0/1649 (0%)]\tLoss: 0.064837\n",
      "\n",
      "Test set: Average loss: 0.1392, Accuracy: 394/412 (96%)\n",
      "\n",
      "Train Epoch: 380 [0/1649 (0%)]\tLoss: 0.058087\n",
      "\n",
      "Test set: Average loss: 0.1403, Accuracy: 394/412 (96%)\n",
      "\n",
      "Train Epoch: 381 [0/1649 (0%)]\tLoss: 0.079879\n",
      "\n",
      "Test set: Average loss: 0.1726, Accuracy: 394/412 (96%)\n",
      "\n",
      "Train Epoch: 382 [0/1649 (0%)]\tLoss: 0.094563\n",
      "\n",
      "Test set: Average loss: 0.1750, Accuracy: 392/412 (95%)\n",
      "\n",
      "Train Epoch: 383 [0/1649 (0%)]\tLoss: 0.073254\n",
      "\n",
      "Test set: Average loss: 0.1361, Accuracy: 397/412 (96%)\n",
      "\n",
      "Train Epoch: 384 [0/1649 (0%)]\tLoss: 0.017178\n",
      "\n",
      "Test set: Average loss: 0.1116, Accuracy: 400/412 (97%)\n",
      "\n",
      "Train Epoch: 385 [0/1649 (0%)]\tLoss: 0.034520\n",
      "\n",
      "Test set: Average loss: 0.0983, Accuracy: 402/412 (98%)\n",
      "\n",
      "Train Epoch: 386 [0/1649 (0%)]\tLoss: 0.004091\n",
      "\n",
      "Test set: Average loss: 0.1028, Accuracy: 401/412 (97%)\n",
      "\n",
      "Train Epoch: 387 [0/1649 (0%)]\tLoss: 0.016878\n",
      "\n",
      "Test set: Average loss: 0.1241, Accuracy: 397/412 (96%)\n",
      "\n",
      "Train Epoch: 388 [0/1649 (0%)]\tLoss: 0.276103\n",
      "\n",
      "Test set: Average loss: 0.1135, Accuracy: 400/412 (97%)\n",
      "\n",
      "Train Epoch: 389 [0/1649 (0%)]\tLoss: 0.033798\n",
      "\n",
      "Test set: Average loss: 0.0950, Accuracy: 399/412 (97%)\n",
      "\n",
      "Train Epoch: 390 [0/1649 (0%)]\tLoss: 0.038069\n",
      "\n",
      "Test set: Average loss: 0.0784, Accuracy: 401/412 (97%)\n",
      "\n",
      "Train Epoch: 391 [0/1649 (0%)]\tLoss: 0.067579\n",
      "\n",
      "Test set: Average loss: 0.0650, Accuracy: 403/412 (98%)\n",
      "\n",
      "Train Epoch: 392 [0/1649 (0%)]\tLoss: 0.018542\n",
      "\n",
      "Test set: Average loss: 0.0587, Accuracy: 403/412 (98%)\n",
      "\n",
      "Train Epoch: 393 [0/1649 (0%)]\tLoss: 0.063392\n",
      "\n",
      "Test set: Average loss: 0.0522, Accuracy: 405/412 (98%)\n",
      "\n",
      "Train Epoch: 394 [0/1649 (0%)]\tLoss: 0.012367\n",
      "\n",
      "Test set: Average loss: 0.0502, Accuracy: 408/412 (99%)\n",
      "\n",
      "Train Epoch: 395 [0/1649 (0%)]\tLoss: 0.011773\n",
      "\n",
      "Test set: Average loss: 0.0506, Accuracy: 405/412 (98%)\n",
      "\n",
      "Train Epoch: 396 [0/1649 (0%)]\tLoss: 0.026363\n",
      "\n",
      "Test set: Average loss: 0.0537, Accuracy: 405/412 (98%)\n",
      "\n",
      "Train Epoch: 397 [0/1649 (0%)]\tLoss: 0.048269\n",
      "\n",
      "Test set: Average loss: 0.0527, Accuracy: 405/412 (98%)\n",
      "\n",
      "Train Epoch: 398 [0/1649 (0%)]\tLoss: 0.029076\n",
      "\n",
      "Test set: Average loss: 0.0518, Accuracy: 404/412 (98%)\n",
      "\n",
      "Train Epoch: 399 [0/1649 (0%)]\tLoss: 0.091289\n",
      "\n",
      "Test set: Average loss: 0.0541, Accuracy: 404/412 (98%)\n",
      "\n",
      "Train Epoch: 400 [0/1649 (0%)]\tLoss: 0.018520\n",
      "\n",
      "Test set: Average loss: 0.0654, Accuracy: 402/412 (98%)\n",
      "\n",
      "Train Epoch: 401 [0/1649 (0%)]\tLoss: 0.003913\n",
      "\n",
      "Test set: Average loss: 0.0826, Accuracy: 400/412 (97%)\n",
      "\n",
      "Train Epoch: 402 [0/1649 (0%)]\tLoss: 0.013670\n",
      "\n",
      "Test set: Average loss: 0.1021, Accuracy: 397/412 (96%)\n",
      "\n",
      "Train Epoch: 403 [0/1649 (0%)]\tLoss: 0.043508\n",
      "\n",
      "Test set: Average loss: 0.1098, Accuracy: 394/412 (96%)\n",
      "\n",
      "Train Epoch: 404 [0/1649 (0%)]\tLoss: 0.006880\n",
      "\n",
      "Test set: Average loss: 0.1170, Accuracy: 393/412 (95%)\n",
      "\n",
      "Train Epoch: 405 [0/1649 (0%)]\tLoss: 0.011593\n",
      "\n",
      "Test set: Average loss: 0.1241, Accuracy: 392/412 (95%)\n",
      "\n",
      "Train Epoch: 406 [0/1649 (0%)]\tLoss: 0.010766\n",
      "\n",
      "Test set: Average loss: 0.1327, Accuracy: 391/412 (95%)\n",
      "\n",
      "Train Epoch: 407 [0/1649 (0%)]\tLoss: 0.006678\n",
      "\n",
      "Test set: Average loss: 0.1306, Accuracy: 391/412 (95%)\n",
      "\n",
      "Train Epoch: 408 [0/1649 (0%)]\tLoss: 0.004376\n",
      "\n",
      "Test set: Average loss: 0.1284, Accuracy: 393/412 (95%)\n",
      "\n",
      "Train Epoch: 409 [0/1649 (0%)]\tLoss: 0.073222\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.1034, Accuracy: 399/412 (97%)\n",
      "\n",
      "Train Epoch: 410 [0/1649 (0%)]\tLoss: 0.042731\n",
      "\n",
      "Test set: Average loss: 0.0853, Accuracy: 401/412 (97%)\n",
      "\n",
      "Train Epoch: 411 [0/1649 (0%)]\tLoss: 0.027241\n",
      "\n",
      "Test set: Average loss: 0.0667, Accuracy: 403/412 (98%)\n",
      "\n",
      "Train Epoch: 412 [0/1649 (0%)]\tLoss: 0.032885\n",
      "\n",
      "Test set: Average loss: 0.0613, Accuracy: 403/412 (98%)\n",
      "\n",
      "Train Epoch: 413 [0/1649 (0%)]\tLoss: 0.004327\n",
      "\n",
      "Test set: Average loss: 0.0617, Accuracy: 402/412 (98%)\n",
      "\n",
      "Train Epoch: 414 [0/1649 (0%)]\tLoss: 0.005094\n",
      "\n",
      "Test set: Average loss: 0.0664, Accuracy: 401/412 (97%)\n",
      "\n",
      "Train Epoch: 415 [0/1649 (0%)]\tLoss: 0.187851\n",
      "\n",
      "Test set: Average loss: 0.0722, Accuracy: 400/412 (97%)\n",
      "\n",
      "Train Epoch: 416 [0/1649 (0%)]\tLoss: 0.011809\n",
      "\n",
      "Test set: Average loss: 0.0796, Accuracy: 400/412 (97%)\n",
      "\n",
      "Train Epoch: 417 [0/1649 (0%)]\tLoss: 0.090849\n",
      "\n",
      "Test set: Average loss: 0.0978, Accuracy: 397/412 (96%)\n",
      "\n",
      "Train Epoch: 418 [0/1649 (0%)]\tLoss: 0.007601\n",
      "\n",
      "Test set: Average loss: 0.1228, Accuracy: 394/412 (96%)\n",
      "\n",
      "Train Epoch: 419 [0/1649 (0%)]\tLoss: 0.007023\n",
      "\n",
      "Test set: Average loss: 0.1516, Accuracy: 393/412 (95%)\n",
      "\n",
      "Train Epoch: 420 [0/1649 (0%)]\tLoss: 0.007854\n",
      "\n",
      "Test set: Average loss: 0.1781, Accuracy: 391/412 (95%)\n",
      "\n",
      "Train Epoch: 421 [0/1649 (0%)]\tLoss: 0.010964\n",
      "\n",
      "Test set: Average loss: 0.1926, Accuracy: 391/412 (95%)\n",
      "\n",
      "Train Epoch: 422 [0/1649 (0%)]\tLoss: 0.040285\n",
      "\n",
      "Test set: Average loss: 0.1607, Accuracy: 392/412 (95%)\n",
      "\n",
      "Train Epoch: 423 [0/1649 (0%)]\tLoss: 0.017506\n",
      "\n",
      "Test set: Average loss: 0.1390, Accuracy: 393/412 (95%)\n",
      "\n",
      "Train Epoch: 424 [0/1649 (0%)]\tLoss: 0.014058\n",
      "\n",
      "Test set: Average loss: 0.1186, Accuracy: 395/412 (96%)\n",
      "\n",
      "Train Epoch: 425 [0/1649 (0%)]\tLoss: 0.037612\n",
      "\n",
      "Test set: Average loss: 0.1041, Accuracy: 398/412 (97%)\n",
      "\n",
      "Train Epoch: 426 [0/1649 (0%)]\tLoss: 0.045488\n",
      "\n",
      "Test set: Average loss: 0.0773, Accuracy: 400/412 (97%)\n",
      "\n",
      "Train Epoch: 427 [0/1649 (0%)]\tLoss: 0.006838\n",
      "\n",
      "Test set: Average loss: 0.0658, Accuracy: 405/412 (98%)\n",
      "\n",
      "Train Epoch: 428 [0/1649 (0%)]\tLoss: 0.077446\n",
      "\n",
      "Test set: Average loss: 0.0669, Accuracy: 405/412 (98%)\n",
      "\n",
      "Train Epoch: 429 [0/1649 (0%)]\tLoss: 0.002881\n",
      "\n",
      "Test set: Average loss: 0.0684, Accuracy: 405/412 (98%)\n",
      "\n",
      "Train Epoch: 430 [0/1649 (0%)]\tLoss: 0.010626\n",
      "\n",
      "Test set: Average loss: 0.0697, Accuracy: 405/412 (98%)\n",
      "\n",
      "Train Epoch: 431 [0/1649 (0%)]\tLoss: 0.007761\n",
      "\n",
      "Test set: Average loss: 0.0707, Accuracy: 406/412 (99%)\n",
      "\n",
      "Train Epoch: 432 [0/1649 (0%)]\tLoss: 0.006583\n",
      "\n",
      "Test set: Average loss: 0.0714, Accuracy: 406/412 (99%)\n",
      "\n",
      "Train Epoch: 433 [0/1649 (0%)]\tLoss: 0.005420\n",
      "\n",
      "Test set: Average loss: 0.0722, Accuracy: 405/412 (98%)\n",
      "\n",
      "Train Epoch: 434 [0/1649 (0%)]\tLoss: 0.028408\n",
      "\n",
      "Test set: Average loss: 0.0720, Accuracy: 405/412 (98%)\n",
      "\n",
      "Train Epoch: 435 [0/1649 (0%)]\tLoss: 0.007981\n",
      "\n",
      "Test set: Average loss: 0.0722, Accuracy: 405/412 (98%)\n",
      "\n",
      "Train Epoch: 436 [0/1649 (0%)]\tLoss: 0.113051\n",
      "\n",
      "Test set: Average loss: 0.0735, Accuracy: 405/412 (98%)\n",
      "\n",
      "Train Epoch: 437 [0/1649 (0%)]\tLoss: 0.009715\n",
      "\n",
      "Test set: Average loss: 0.0740, Accuracy: 405/412 (98%)\n",
      "\n",
      "Train Epoch: 438 [0/1649 (0%)]\tLoss: 0.007780\n",
      "\n",
      "Test set: Average loss: 0.0754, Accuracy: 405/412 (98%)\n",
      "\n",
      "Train Epoch: 439 [0/1649 (0%)]\tLoss: 0.085698\n",
      "\n",
      "Test set: Average loss: 0.0772, Accuracy: 405/412 (98%)\n",
      "\n",
      "Train Epoch: 440 [0/1649 (0%)]\tLoss: 0.051431\n",
      "\n",
      "Test set: Average loss: 0.0758, Accuracy: 405/412 (98%)\n",
      "\n",
      "Train Epoch: 441 [0/1649 (0%)]\tLoss: 0.051730\n",
      "\n",
      "Test set: Average loss: 0.0825, Accuracy: 403/412 (98%)\n",
      "\n",
      "Train Epoch: 442 [0/1649 (0%)]\tLoss: 0.006329\n",
      "\n",
      "Test set: Average loss: 0.0934, Accuracy: 403/412 (98%)\n",
      "\n",
      "Train Epoch: 443 [0/1649 (0%)]\tLoss: 0.076742\n",
      "\n",
      "Test set: Average loss: 0.0951, Accuracy: 402/412 (98%)\n",
      "\n",
      "Train Epoch: 444 [0/1649 (0%)]\tLoss: 0.012133\n",
      "\n",
      "Test set: Average loss: 0.0981, Accuracy: 402/412 (98%)\n",
      "\n",
      "Train Epoch: 445 [0/1649 (0%)]\tLoss: 0.019666\n",
      "\n",
      "Test set: Average loss: 0.0968, Accuracy: 402/412 (98%)\n",
      "\n",
      "Train Epoch: 446 [0/1649 (0%)]\tLoss: 0.030214\n",
      "\n",
      "Test set: Average loss: 0.0898, Accuracy: 403/412 (98%)\n",
      "\n",
      "Train Epoch: 447 [0/1649 (0%)]\tLoss: 0.012834\n",
      "\n",
      "Test set: Average loss: 0.0825, Accuracy: 404/412 (98%)\n",
      "\n",
      "Train Epoch: 448 [0/1649 (0%)]\tLoss: 0.038710\n",
      "\n",
      "Test set: Average loss: 0.0774, Accuracy: 405/412 (98%)\n",
      "\n",
      "Train Epoch: 449 [0/1649 (0%)]\tLoss: 0.017062\n",
      "\n",
      "Test set: Average loss: 0.0745, Accuracy: 404/412 (98%)\n",
      "\n",
      "Train Epoch: 450 [0/1649 (0%)]\tLoss: 0.014759\n",
      "\n",
      "Test set: Average loss: 0.0738, Accuracy: 403/412 (98%)\n",
      "\n",
      "Train Epoch: 451 [0/1649 (0%)]\tLoss: 0.002846\n",
      "\n",
      "Test set: Average loss: 0.0747, Accuracy: 403/412 (98%)\n",
      "\n",
      "Train Epoch: 452 [0/1649 (0%)]\tLoss: 0.022096\n",
      "\n",
      "Test set: Average loss: 0.0761, Accuracy: 403/412 (98%)\n",
      "\n",
      "Train Epoch: 453 [0/1649 (0%)]\tLoss: 0.005169\n",
      "\n",
      "Test set: Average loss: 0.0792, Accuracy: 402/412 (98%)\n",
      "\n",
      "Train Epoch: 454 [0/1649 (0%)]\tLoss: 0.029470\n",
      "\n",
      "Test set: Average loss: 0.0821, Accuracy: 402/412 (98%)\n",
      "\n",
      "Train Epoch: 455 [0/1649 (0%)]\tLoss: 0.079433\n",
      "\n",
      "Test set: Average loss: 0.0818, Accuracy: 402/412 (98%)\n",
      "\n",
      "Train Epoch: 456 [0/1649 (0%)]\tLoss: 0.016337\n",
      "\n",
      "Test set: Average loss: 0.0814, Accuracy: 405/412 (98%)\n",
      "\n",
      "Train Epoch: 457 [0/1649 (0%)]\tLoss: 0.079361\n",
      "\n",
      "Test set: Average loss: 0.0797, Accuracy: 405/412 (98%)\n",
      "\n",
      "Train Epoch: 458 [0/1649 (0%)]\tLoss: 0.004171\n",
      "\n",
      "Test set: Average loss: 0.0794, Accuracy: 406/412 (99%)\n",
      "\n",
      "Train Epoch: 459 [0/1649 (0%)]\tLoss: 0.012858\n",
      "\n",
      "Test set: Average loss: 0.0795, Accuracy: 406/412 (99%)\n",
      "\n",
      "Train Epoch: 460 [0/1649 (0%)]\tLoss: 0.019054\n",
      "\n",
      "Test set: Average loss: 0.0814, Accuracy: 404/412 (98%)\n",
      "\n",
      "Train Epoch: 461 [0/1649 (0%)]\tLoss: 0.004665\n",
      "\n",
      "Test set: Average loss: 0.0831, Accuracy: 403/412 (98%)\n",
      "\n",
      "Train Epoch: 462 [0/1649 (0%)]\tLoss: 0.008445\n",
      "\n",
      "Test set: Average loss: 0.0846, Accuracy: 403/412 (98%)\n",
      "\n",
      "Train Epoch: 463 [0/1649 (0%)]\tLoss: 0.034200\n",
      "\n",
      "Test set: Average loss: 0.0846, Accuracy: 403/412 (98%)\n",
      "\n",
      "Train Epoch: 464 [0/1649 (0%)]\tLoss: 0.033735\n",
      "\n",
      "Test set: Average loss: 0.0833, Accuracy: 404/412 (98%)\n",
      "\n",
      "Train Epoch: 465 [0/1649 (0%)]\tLoss: 0.062971\n",
      "\n",
      "Test set: Average loss: 0.0792, Accuracy: 405/412 (98%)\n",
      "\n",
      "Train Epoch: 466 [0/1649 (0%)]\tLoss: 0.007776\n",
      "\n",
      "Test set: Average loss: 0.0757, Accuracy: 405/412 (98%)\n",
      "\n",
      "Train Epoch: 467 [0/1649 (0%)]\tLoss: 0.099219\n",
      "\n",
      "Test set: Average loss: 0.0781, Accuracy: 403/412 (98%)\n",
      "\n",
      "Train Epoch: 468 [0/1649 (0%)]\tLoss: 0.037101\n",
      "\n",
      "Test set: Average loss: 0.0837, Accuracy: 403/412 (98%)\n",
      "\n",
      "Train Epoch: 469 [0/1649 (0%)]\tLoss: 0.029142\n",
      "\n",
      "Test set: Average loss: 0.0859, Accuracy: 402/412 (98%)\n",
      "\n",
      "Train Epoch: 470 [0/1649 (0%)]\tLoss: 0.007093\n",
      "\n",
      "Test set: Average loss: 0.0870, Accuracy: 402/412 (98%)\n",
      "\n",
      "Train Epoch: 471 [0/1649 (0%)]\tLoss: 0.046283\n",
      "\n",
      "Test set: Average loss: 0.0890, Accuracy: 402/412 (98%)\n",
      "\n",
      "Train Epoch: 472 [0/1649 (0%)]\tLoss: 0.004847\n",
      "\n",
      "Test set: Average loss: 0.0920, Accuracy: 401/412 (97%)\n",
      "\n",
      "Train Epoch: 473 [0/1649 (0%)]\tLoss: 0.010386\n",
      "\n",
      "Test set: Average loss: 0.0972, Accuracy: 400/412 (97%)\n",
      "\n",
      "Train Epoch: 474 [0/1649 (0%)]\tLoss: 0.003893\n",
      "\n",
      "Test set: Average loss: 0.1025, Accuracy: 401/412 (97%)\n",
      "\n",
      "Train Epoch: 475 [0/1649 (0%)]\tLoss: 0.034877\n",
      "\n",
      "Test set: Average loss: 0.1140, Accuracy: 401/412 (97%)\n",
      "\n",
      "Train Epoch: 476 [0/1649 (0%)]\tLoss: 0.002686\n",
      "\n",
      "Test set: Average loss: 0.1243, Accuracy: 401/412 (97%)\n",
      "\n",
      "Train Epoch: 477 [0/1649 (0%)]\tLoss: 0.007428\n",
      "\n",
      "Test set: Average loss: 0.1379, Accuracy: 398/412 (97%)\n",
      "\n",
      "Train Epoch: 478 [0/1649 (0%)]\tLoss: 0.092122\n",
      "\n",
      "Test set: Average loss: 0.1306, Accuracy: 400/412 (97%)\n",
      "\n",
      "Train Epoch: 479 [0/1649 (0%)]\tLoss: 0.026176\n",
      "\n",
      "Test set: Average loss: 0.1165, Accuracy: 401/412 (97%)\n",
      "\n",
      "Train Epoch: 480 [0/1649 (0%)]\tLoss: 0.012398\n",
      "\n",
      "Test set: Average loss: 0.1015, Accuracy: 401/412 (97%)\n",
      "\n",
      "Train Epoch: 481 [0/1649 (0%)]\tLoss: 0.029495\n",
      "\n",
      "Test set: Average loss: 0.0770, Accuracy: 403/412 (98%)\n",
      "\n",
      "Train Epoch: 482 [0/1649 (0%)]\tLoss: 0.003387\n",
      "\n",
      "Test set: Average loss: 0.0637, Accuracy: 405/412 (98%)\n",
      "\n",
      "Train Epoch: 483 [0/1649 (0%)]\tLoss: 0.046546\n",
      "\n",
      "Test set: Average loss: 0.0566, Accuracy: 406/412 (99%)\n",
      "\n",
      "Train Epoch: 484 [0/1649 (0%)]\tLoss: 0.024779\n",
      "\n",
      "Test set: Average loss: 0.0557, Accuracy: 404/412 (98%)\n",
      "\n",
      "Train Epoch: 485 [0/1649 (0%)]\tLoss: 0.010786\n",
      "\n",
      "Test set: Average loss: 0.0605, Accuracy: 404/412 (98%)\n",
      "\n",
      "Train Epoch: 486 [0/1649 (0%)]\tLoss: 0.135004\n",
      "\n",
      "Test set: Average loss: 0.0641, Accuracy: 404/412 (98%)\n",
      "\n",
      "Train Epoch: 487 [0/1649 (0%)]\tLoss: 0.076237\n",
      "\n",
      "Test set: Average loss: 0.0692, Accuracy: 403/412 (98%)\n",
      "\n",
      "Train Epoch: 488 [0/1649 (0%)]\tLoss: 0.004732\n",
      "\n",
      "Test set: Average loss: 0.0808, Accuracy: 402/412 (98%)\n",
      "\n",
      "Train Epoch: 489 [0/1649 (0%)]\tLoss: 0.003406\n",
      "\n",
      "Test set: Average loss: 0.0956, Accuracy: 400/412 (97%)\n",
      "\n",
      "Train Epoch: 490 [0/1649 (0%)]\tLoss: 0.009877\n",
      "\n",
      "Test set: Average loss: 0.1126, Accuracy: 400/412 (97%)\n",
      "\n",
      "Train Epoch: 491 [0/1649 (0%)]\tLoss: 0.026771\n",
      "\n",
      "Test set: Average loss: 0.1309, Accuracy: 397/412 (96%)\n",
      "\n",
      "Train Epoch: 492 [0/1649 (0%)]\tLoss: 0.004872\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.1436, Accuracy: 396/412 (96%)\n",
      "\n",
      "Train Epoch: 493 [0/1649 (0%)]\tLoss: 0.075961\n",
      "\n",
      "Test set: Average loss: 0.1327, Accuracy: 399/412 (97%)\n",
      "\n",
      "Train Epoch: 494 [0/1649 (0%)]\tLoss: 0.001178\n",
      "\n",
      "Test set: Average loss: 0.1258, Accuracy: 398/412 (97%)\n",
      "\n",
      "Train Epoch: 495 [0/1649 (0%)]\tLoss: 0.015739\n",
      "\n",
      "Test set: Average loss: 0.1076, Accuracy: 400/412 (97%)\n",
      "\n",
      "Train Epoch: 496 [0/1649 (0%)]\tLoss: 0.005418\n",
      "\n",
      "Test set: Average loss: 0.0924, Accuracy: 400/412 (97%)\n",
      "\n",
      "Train Epoch: 497 [0/1649 (0%)]\tLoss: 0.018696\n",
      "\n",
      "Test set: Average loss: 0.0813, Accuracy: 401/412 (97%)\n",
      "\n",
      "Train Epoch: 498 [0/1649 (0%)]\tLoss: 0.004074\n",
      "\n",
      "Test set: Average loss: 0.0727, Accuracy: 404/412 (98%)\n",
      "\n",
      "Train Epoch: 499 [0/1649 (0%)]\tLoss: 0.002365\n",
      "\n",
      "Test set: Average loss: 0.0668, Accuracy: 404/412 (98%)\n",
      "\n",
      "Train Epoch: 500 [0/1649 (0%)]\tLoss: 0.009010\n",
      "\n",
      "Test set: Average loss: 0.0571, Accuracy: 405/412 (98%)\n",
      "\n",
      "Train Epoch: 501 [0/1649 (0%)]\tLoss: 0.006861\n",
      "\n",
      "Test set: Average loss: 0.0525, Accuracy: 406/412 (99%)\n",
      "\n",
      "Train Epoch: 502 [0/1649 (0%)]\tLoss: 0.001879\n",
      "\n",
      "Test set: Average loss: 0.0511, Accuracy: 407/412 (99%)\n",
      "\n",
      "Train Epoch: 503 [0/1649 (0%)]\tLoss: 0.030188\n",
      "\n",
      "Test set: Average loss: 0.0532, Accuracy: 406/412 (99%)\n",
      "\n",
      "Train Epoch: 504 [0/1649 (0%)]\tLoss: 0.037019\n",
      "\n",
      "Test set: Average loss: 0.0591, Accuracy: 404/412 (98%)\n",
      "\n",
      "Train Epoch: 505 [0/1649 (0%)]\tLoss: 0.013308\n",
      "\n",
      "Test set: Average loss: 0.0644, Accuracy: 403/412 (98%)\n",
      "\n",
      "Train Epoch: 506 [0/1649 (0%)]\tLoss: 0.044866\n",
      "\n",
      "Test set: Average loss: 0.0769, Accuracy: 402/412 (98%)\n",
      "\n",
      "Train Epoch: 507 [0/1649 (0%)]\tLoss: 0.030329\n",
      "\n",
      "Test set: Average loss: 0.0983, Accuracy: 399/412 (97%)\n",
      "\n",
      "Train Epoch: 508 [0/1649 (0%)]\tLoss: 0.003948\n",
      "\n",
      "Test set: Average loss: 0.1185, Accuracy: 397/412 (96%)\n",
      "\n",
      "Train Epoch: 509 [0/1649 (0%)]\tLoss: 0.002256\n",
      "\n",
      "Test set: Average loss: 0.1364, Accuracy: 396/412 (96%)\n",
      "\n",
      "Train Epoch: 510 [0/1649 (0%)]\tLoss: 0.035920\n",
      "\n",
      "Test set: Average loss: 0.1501, Accuracy: 395/412 (96%)\n",
      "\n",
      "Train Epoch: 511 [0/1649 (0%)]\tLoss: 0.123969\n",
      "\n",
      "Test set: Average loss: 0.1157, Accuracy: 398/412 (97%)\n",
      "\n",
      "Train Epoch: 512 [0/1649 (0%)]\tLoss: 0.002895\n",
      "\n",
      "Test set: Average loss: 0.1018, Accuracy: 401/412 (97%)\n",
      "\n",
      "Train Epoch: 513 [0/1649 (0%)]\tLoss: 0.012693\n",
      "\n",
      "Test set: Average loss: 0.0949, Accuracy: 403/412 (98%)\n",
      "\n",
      "Train Epoch: 514 [0/1649 (0%)]\tLoss: 0.000633\n",
      "\n",
      "Test set: Average loss: 0.0933, Accuracy: 404/412 (98%)\n",
      "\n",
      "Train Epoch: 515 [0/1649 (0%)]\tLoss: 0.001377\n",
      "\n",
      "Test set: Average loss: 0.0943, Accuracy: 404/412 (98%)\n",
      "\n",
      "Train Epoch: 516 [0/1649 (0%)]\tLoss: 0.026245\n",
      "\n",
      "Test set: Average loss: 0.0908, Accuracy: 404/412 (98%)\n",
      "\n",
      "Train Epoch: 517 [0/1649 (0%)]\tLoss: 0.111111\n",
      "\n",
      "Test set: Average loss: 0.0810, Accuracy: 405/412 (98%)\n",
      "\n",
      "Train Epoch: 518 [0/1649 (0%)]\tLoss: 0.000984\n",
      "\n",
      "Test set: Average loss: 0.0833, Accuracy: 405/412 (98%)\n",
      "\n",
      "Train Epoch: 519 [0/1649 (0%)]\tLoss: 0.001863\n",
      "\n",
      "Test set: Average loss: 0.0914, Accuracy: 405/412 (98%)\n",
      "\n",
      "Train Epoch: 520 [0/1649 (0%)]\tLoss: 0.003343\n",
      "\n",
      "Test set: Average loss: 0.1084, Accuracy: 402/412 (98%)\n",
      "\n",
      "Train Epoch: 521 [0/1649 (0%)]\tLoss: 0.008099\n",
      "\n",
      "Test set: Average loss: 0.1524, Accuracy: 393/412 (95%)\n",
      "\n",
      "Train Epoch: 522 [0/1649 (0%)]\tLoss: 0.011008\n",
      "\n",
      "Test set: Average loss: 0.2050, Accuracy: 388/412 (94%)\n",
      "\n",
      "Train Epoch: 523 [0/1649 (0%)]\tLoss: 0.007984\n",
      "\n",
      "Test set: Average loss: 0.2481, Accuracy: 382/412 (93%)\n",
      "\n",
      "Train Epoch: 524 [0/1649 (0%)]\tLoss: 0.018674\n",
      "\n",
      "Test set: Average loss: 0.2140, Accuracy: 388/412 (94%)\n",
      "\n",
      "Train Epoch: 525 [0/1649 (0%)]\tLoss: 0.076475\n",
      "\n",
      "Test set: Average loss: 0.1155, Accuracy: 399/412 (97%)\n",
      "\n",
      "Train Epoch: 526 [0/1649 (0%)]\tLoss: 0.070352\n",
      "\n",
      "Test set: Average loss: 0.0841, Accuracy: 406/412 (99%)\n",
      "\n",
      "Train Epoch: 527 [0/1649 (0%)]\tLoss: 0.001720\n",
      "\n",
      "Test set: Average loss: 0.0835, Accuracy: 405/412 (98%)\n",
      "\n",
      "Train Epoch: 528 [0/1649 (0%)]\tLoss: 0.003312\n",
      "\n",
      "Test set: Average loss: 0.0985, Accuracy: 403/412 (98%)\n",
      "\n",
      "Train Epoch: 529 [0/1649 (0%)]\tLoss: 0.052212\n",
      "\n",
      "Test set: Average loss: 0.1317, Accuracy: 402/412 (98%)\n",
      "\n",
      "Train Epoch: 530 [0/1649 (0%)]\tLoss: 0.056787\n",
      "\n",
      "Test set: Average loss: 0.1337, Accuracy: 400/412 (97%)\n",
      "\n",
      "Train Epoch: 531 [0/1649 (0%)]\tLoss: 0.007986\n",
      "\n",
      "Test set: Average loss: 0.1330, Accuracy: 399/412 (97%)\n",
      "\n",
      "Train Epoch: 532 [0/1649 (0%)]\tLoss: 0.014341\n",
      "\n",
      "Test set: Average loss: 0.1164, Accuracy: 400/412 (97%)\n",
      "\n",
      "Train Epoch: 533 [0/1649 (0%)]\tLoss: 0.002199\n",
      "\n",
      "Test set: Average loss: 0.1067, Accuracy: 400/412 (97%)\n",
      "\n",
      "Train Epoch: 534 [0/1649 (0%)]\tLoss: 0.007099\n",
      "\n",
      "Test set: Average loss: 0.1002, Accuracy: 398/412 (97%)\n",
      "\n",
      "Train Epoch: 535 [0/1649 (0%)]\tLoss: 0.005534\n",
      "\n",
      "Test set: Average loss: 0.0946, Accuracy: 401/412 (97%)\n",
      "\n",
      "Train Epoch: 536 [0/1649 (0%)]\tLoss: 0.004580\n",
      "\n",
      "Test set: Average loss: 0.0930, Accuracy: 401/412 (97%)\n",
      "\n",
      "Train Epoch: 537 [0/1649 (0%)]\tLoss: 0.013475\n",
      "\n",
      "Test set: Average loss: 0.0916, Accuracy: 401/412 (97%)\n",
      "\n",
      "Train Epoch: 538 [0/1649 (0%)]\tLoss: 0.003249\n",
      "\n",
      "Test set: Average loss: 0.0915, Accuracy: 400/412 (97%)\n",
      "\n",
      "Train Epoch: 539 [0/1649 (0%)]\tLoss: 0.163018\n",
      "\n",
      "Test set: Average loss: 0.0966, Accuracy: 400/412 (97%)\n",
      "\n",
      "Train Epoch: 540 [0/1649 (0%)]\tLoss: 0.012499\n",
      "\n",
      "Test set: Average loss: 0.1046, Accuracy: 399/412 (97%)\n",
      "\n",
      "Train Epoch: 541 [0/1649 (0%)]\tLoss: 0.007629\n",
      "\n",
      "Test set: Average loss: 0.1143, Accuracy: 398/412 (97%)\n",
      "\n",
      "Train Epoch: 542 [0/1649 (0%)]\tLoss: 0.002239\n",
      "\n",
      "Test set: Average loss: 0.1216, Accuracy: 398/412 (97%)\n",
      "\n",
      "Train Epoch: 543 [0/1649 (0%)]\tLoss: 0.018683\n",
      "\n",
      "Test set: Average loss: 0.1161, Accuracy: 398/412 (97%)\n",
      "\n",
      "Train Epoch: 544 [0/1649 (0%)]\tLoss: 0.017032\n",
      "\n",
      "Test set: Average loss: 0.1011, Accuracy: 398/412 (97%)\n",
      "\n",
      "Train Epoch: 545 [0/1649 (0%)]\tLoss: 0.002214\n",
      "\n",
      "Test set: Average loss: 0.0887, Accuracy: 400/412 (97%)\n",
      "\n",
      "Train Epoch: 546 [0/1649 (0%)]\tLoss: 0.027515\n",
      "\n",
      "Test set: Average loss: 0.0653, Accuracy: 404/412 (98%)\n",
      "\n",
      "Train Epoch: 547 [0/1649 (0%)]\tLoss: 0.003603\n",
      "\n",
      "Test set: Average loss: 0.0553, Accuracy: 407/412 (99%)\n",
      "\n",
      "Train Epoch: 548 [0/1649 (0%)]\tLoss: 0.010215\n",
      "\n",
      "Test set: Average loss: 0.0522, Accuracy: 407/412 (99%)\n",
      "\n",
      "Train Epoch: 549 [0/1649 (0%)]\tLoss: 0.002694\n",
      "\n",
      "Test set: Average loss: 0.0522, Accuracy: 406/412 (99%)\n",
      "\n",
      "Train Epoch: 550 [0/1649 (0%)]\tLoss: 0.020137\n",
      "\n",
      "Test set: Average loss: 0.0551, Accuracy: 405/412 (98%)\n",
      "\n",
      "Train Epoch: 551 [0/1649 (0%)]\tLoss: 0.002610\n",
      "\n",
      "Test set: Average loss: 0.0594, Accuracy: 404/412 (98%)\n",
      "\n",
      "Train Epoch: 552 [0/1649 (0%)]\tLoss: 0.042042\n",
      "\n",
      "Test set: Average loss: 0.0593, Accuracy: 405/412 (98%)\n",
      "\n",
      "Train Epoch: 553 [0/1649 (0%)]\tLoss: 0.007786\n",
      "\n",
      "Test set: Average loss: 0.0607, Accuracy: 406/412 (99%)\n",
      "\n",
      "Train Epoch: 554 [0/1649 (0%)]\tLoss: 0.020394\n",
      "\n",
      "Test set: Average loss: 0.0592, Accuracy: 406/412 (99%)\n",
      "\n",
      "Train Epoch: 555 [0/1649 (0%)]\tLoss: 0.156998\n",
      "\n",
      "Test set: Average loss: 0.0573, Accuracy: 405/412 (98%)\n",
      "\n",
      "Train Epoch: 556 [0/1649 (0%)]\tLoss: 0.004617\n",
      "\n",
      "Test set: Average loss: 0.0651, Accuracy: 403/412 (98%)\n",
      "\n",
      "Train Epoch: 557 [0/1649 (0%)]\tLoss: 0.019993\n",
      "\n",
      "Test set: Average loss: 0.0708, Accuracy: 404/412 (98%)\n",
      "\n",
      "Train Epoch: 558 [0/1649 (0%)]\tLoss: 0.015470\n",
      "\n",
      "Test set: Average loss: 0.0768, Accuracy: 403/412 (98%)\n",
      "\n",
      "Train Epoch: 559 [0/1649 (0%)]\tLoss: 0.004379\n",
      "\n",
      "Test set: Average loss: 0.0834, Accuracy: 403/412 (98%)\n",
      "\n",
      "Train Epoch: 560 [0/1649 (0%)]\tLoss: 0.001006\n",
      "\n",
      "Test set: Average loss: 0.0938, Accuracy: 401/412 (97%)\n",
      "\n",
      "Train Epoch: 561 [0/1649 (0%)]\tLoss: 0.008763\n",
      "\n",
      "Test set: Average loss: 0.1014, Accuracy: 401/412 (97%)\n",
      "\n",
      "Train Epoch: 562 [0/1649 (0%)]\tLoss: 0.024665\n",
      "\n",
      "Test set: Average loss: 0.0999, Accuracy: 401/412 (97%)\n",
      "\n",
      "Train Epoch: 563 [0/1649 (0%)]\tLoss: 0.012026\n",
      "\n",
      "Test set: Average loss: 0.0977, Accuracy: 402/412 (98%)\n",
      "\n",
      "Train Epoch: 564 [0/1649 (0%)]\tLoss: 0.025379\n",
      "\n",
      "Test set: Average loss: 0.0921, Accuracy: 401/412 (97%)\n",
      "\n",
      "Train Epoch: 565 [0/1649 (0%)]\tLoss: 0.000215\n",
      "\n",
      "Test set: Average loss: 0.0880, Accuracy: 401/412 (97%)\n",
      "\n",
      "Train Epoch: 566 [0/1649 (0%)]\tLoss: 0.001270\n",
      "\n",
      "Test set: Average loss: 0.0853, Accuracy: 401/412 (97%)\n",
      "\n",
      "Train Epoch: 567 [0/1649 (0%)]\tLoss: 0.057017\n",
      "\n",
      "Test set: Average loss: 0.0713, Accuracy: 402/412 (98%)\n",
      "\n",
      "Train Epoch: 568 [0/1649 (0%)]\tLoss: 0.068940\n",
      "\n",
      "Test set: Average loss: 0.0676, Accuracy: 404/412 (98%)\n",
      "\n",
      "Train Epoch: 569 [0/1649 (0%)]\tLoss: 0.051212\n",
      "\n",
      "Test set: Average loss: 0.0695, Accuracy: 402/412 (98%)\n",
      "\n",
      "Train Epoch: 570 [0/1649 (0%)]\tLoss: 0.017270\n",
      "\n",
      "Test set: Average loss: 0.0651, Accuracy: 403/412 (98%)\n",
      "\n",
      "Train Epoch: 571 [0/1649 (0%)]\tLoss: 0.001309\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.0632, Accuracy: 403/412 (98%)\n",
      "\n",
      "Train Epoch: 572 [0/1649 (0%)]\tLoss: 0.011971\n",
      "\n",
      "Test set: Average loss: 0.0605, Accuracy: 403/412 (98%)\n",
      "\n",
      "Train Epoch: 573 [0/1649 (0%)]\tLoss: 0.063485\n",
      "\n",
      "Test set: Average loss: 0.0619, Accuracy: 404/412 (98%)\n",
      "\n",
      "Train Epoch: 574 [0/1649 (0%)]\tLoss: 0.000514\n",
      "\n",
      "Test set: Average loss: 0.0660, Accuracy: 404/412 (98%)\n",
      "\n",
      "Train Epoch: 575 [0/1649 (0%)]\tLoss: 0.003321\n",
      "\n",
      "Test set: Average loss: 0.0725, Accuracy: 404/412 (98%)\n",
      "\n",
      "Train Epoch: 576 [0/1649 (0%)]\tLoss: 0.001018\n",
      "\n",
      "Test set: Average loss: 0.0837, Accuracy: 403/412 (98%)\n",
      "\n",
      "Train Epoch: 577 [0/1649 (0%)]\tLoss: 0.006130\n",
      "\n",
      "Test set: Average loss: 0.0889, Accuracy: 401/412 (97%)\n",
      "\n",
      "Train Epoch: 578 [0/1649 (0%)]\tLoss: 0.008099\n",
      "\n",
      "Test set: Average loss: 0.0897, Accuracy: 400/412 (97%)\n",
      "\n",
      "Train Epoch: 579 [0/1649 (0%)]\tLoss: 0.057908\n",
      "\n",
      "Test set: Average loss: 0.0648, Accuracy: 402/412 (98%)\n",
      "\n",
      "Train Epoch: 580 [0/1649 (0%)]\tLoss: 0.062959\n",
      "\n",
      "Test set: Average loss: 0.0452, Accuracy: 405/412 (98%)\n",
      "\n",
      "Train Epoch: 581 [0/1649 (0%)]\tLoss: 0.014682\n",
      "\n",
      "Test set: Average loss: 0.0356, Accuracy: 406/412 (99%)\n",
      "\n",
      "Train Epoch: 582 [0/1649 (0%)]\tLoss: 0.037186\n",
      "\n",
      "Test set: Average loss: 0.0334, Accuracy: 407/412 (99%)\n",
      "\n",
      "Train Epoch: 583 [0/1649 (0%)]\tLoss: 0.002804\n",
      "\n",
      "Test set: Average loss: 0.0361, Accuracy: 408/412 (99%)\n",
      "\n",
      "Train Epoch: 584 [0/1649 (0%)]\tLoss: 0.021022\n",
      "\n",
      "Test set: Average loss: 0.0400, Accuracy: 408/412 (99%)\n",
      "\n",
      "Train Epoch: 585 [0/1649 (0%)]\tLoss: 0.000205\n",
      "\n",
      "Test set: Average loss: 0.0447, Accuracy: 406/412 (99%)\n",
      "\n",
      "Train Epoch: 586 [0/1649 (0%)]\tLoss: 0.001665\n",
      "\n",
      "Test set: Average loss: 0.0489, Accuracy: 406/412 (99%)\n",
      "\n",
      "Train Epoch: 587 [0/1649 (0%)]\tLoss: 0.012858\n",
      "\n",
      "Test set: Average loss: 0.0549, Accuracy: 405/412 (98%)\n",
      "\n",
      "Train Epoch: 588 [0/1649 (0%)]\tLoss: 0.005461\n",
      "\n",
      "Test set: Average loss: 0.0605, Accuracy: 405/412 (98%)\n",
      "\n",
      "Train Epoch: 589 [0/1649 (0%)]\tLoss: 0.014500\n",
      "\n",
      "Test set: Average loss: 0.0649, Accuracy: 404/412 (98%)\n",
      "\n",
      "Train Epoch: 590 [0/1649 (0%)]\tLoss: 0.022472\n",
      "\n",
      "Test set: Average loss: 0.0693, Accuracy: 405/412 (98%)\n",
      "\n",
      "Train Epoch: 591 [0/1649 (0%)]\tLoss: 0.005036\n",
      "\n",
      "Test set: Average loss: 0.0745, Accuracy: 403/412 (98%)\n",
      "\n",
      "Train Epoch: 592 [0/1649 (0%)]\tLoss: 0.010418\n",
      "\n",
      "Test set: Average loss: 0.0784, Accuracy: 402/412 (98%)\n",
      "\n",
      "Train Epoch: 593 [0/1649 (0%)]\tLoss: 0.008514\n",
      "\n",
      "Test set: Average loss: 0.0816, Accuracy: 402/412 (98%)\n",
      "\n",
      "Train Epoch: 594 [0/1649 (0%)]\tLoss: 0.004131\n",
      "\n",
      "Test set: Average loss: 0.0841, Accuracy: 401/412 (97%)\n",
      "\n",
      "Train Epoch: 595 [0/1649 (0%)]\tLoss: 0.000935\n",
      "\n",
      "Test set: Average loss: 0.0830, Accuracy: 401/412 (97%)\n",
      "\n",
      "Train Epoch: 596 [0/1649 (0%)]\tLoss: 0.008713\n",
      "\n",
      "Test set: Average loss: 0.0829, Accuracy: 401/412 (97%)\n",
      "\n",
      "Train Epoch: 597 [0/1649 (0%)]\tLoss: 0.019438\n",
      "\n",
      "Test set: Average loss: 0.0890, Accuracy: 401/412 (97%)\n",
      "\n",
      "Train Epoch: 598 [0/1649 (0%)]\tLoss: 0.105614\n",
      "\n",
      "Test set: Average loss: 0.0836, Accuracy: 403/412 (98%)\n",
      "\n",
      "Train Epoch: 599 [0/1649 (0%)]\tLoss: 0.010873\n",
      "\n",
      "Test set: Average loss: 0.0764, Accuracy: 403/412 (98%)\n",
      "\n",
      "Train Epoch: 600 [0/1649 (0%)]\tLoss: 0.012618\n",
      "\n",
      "Test set: Average loss: 0.0702, Accuracy: 403/412 (98%)\n",
      "\n",
      "Train Epoch: 601 [0/1649 (0%)]\tLoss: 0.002174\n",
      "\n",
      "Test set: Average loss: 0.0669, Accuracy: 404/412 (98%)\n",
      "\n",
      "Train Epoch: 602 [0/1649 (0%)]\tLoss: 0.000403\n",
      "\n",
      "Test set: Average loss: 0.0644, Accuracy: 403/412 (98%)\n",
      "\n",
      "Train Epoch: 603 [0/1649 (0%)]\tLoss: 0.005810\n",
      "\n",
      "Test set: Average loss: 0.0613, Accuracy: 403/412 (98%)\n",
      "\n",
      "Train Epoch: 604 [0/1649 (0%)]\tLoss: 0.014417\n",
      "\n",
      "Test set: Average loss: 0.0549, Accuracy: 406/412 (99%)\n",
      "\n",
      "Train Epoch: 605 [0/1649 (0%)]\tLoss: 0.018471\n",
      "\n",
      "Test set: Average loss: 0.0471, Accuracy: 406/412 (99%)\n",
      "\n",
      "Train Epoch: 606 [0/1649 (0%)]\tLoss: 0.116619\n",
      "\n",
      "Test set: Average loss: 0.0530, Accuracy: 403/412 (98%)\n",
      "\n",
      "Train Epoch: 607 [0/1649 (0%)]\tLoss: 0.000558\n",
      "\n",
      "Test set: Average loss: 0.1094, Accuracy: 397/412 (96%)\n",
      "\n",
      "Train Epoch: 608 [0/1649 (0%)]\tLoss: 0.001762\n",
      "\n",
      "Test set: Average loss: 0.2553, Accuracy: 383/412 (93%)\n",
      "\n",
      "Train Epoch: 609 [0/1649 (0%)]\tLoss: 0.004015\n",
      "\n",
      "Test set: Average loss: 0.4559, Accuracy: 368/412 (89%)\n",
      "\n",
      "Train Epoch: 610 [0/1649 (0%)]\tLoss: 0.008261\n",
      "\n",
      "Test set: Average loss: 0.5923, Accuracy: 359/412 (87%)\n",
      "\n",
      "Train Epoch: 611 [0/1649 (0%)]\tLoss: 0.061744\n",
      "\n",
      "Test set: Average loss: 0.3747, Accuracy: 375/412 (91%)\n",
      "\n",
      "Train Epoch: 612 [0/1649 (0%)]\tLoss: 0.015060\n",
      "\n",
      "Test set: Average loss: 0.2140, Accuracy: 390/412 (95%)\n",
      "\n",
      "Train Epoch: 613 [0/1649 (0%)]\tLoss: 0.001070\n",
      "\n",
      "Test set: Average loss: 0.1501, Accuracy: 395/412 (96%)\n",
      "\n",
      "Train Epoch: 614 [0/1649 (0%)]\tLoss: 0.089507\n",
      "\n",
      "Test set: Average loss: 0.1184, Accuracy: 401/412 (97%)\n",
      "\n",
      "Train Epoch: 615 [0/1649 (0%)]\tLoss: 0.002215\n",
      "\n",
      "Test set: Average loss: 0.1019, Accuracy: 403/412 (98%)\n",
      "\n",
      "Train Epoch: 616 [0/1649 (0%)]\tLoss: 0.001113\n",
      "\n",
      "Test set: Average loss: 0.0936, Accuracy: 403/412 (98%)\n",
      "\n",
      "Train Epoch: 617 [0/1649 (0%)]\tLoss: 0.006845\n",
      "\n",
      "Test set: Average loss: 0.0908, Accuracy: 403/412 (98%)\n",
      "\n",
      "Train Epoch: 618 [0/1649 (0%)]\tLoss: 0.003932\n",
      "\n",
      "Test set: Average loss: 0.0894, Accuracy: 403/412 (98%)\n",
      "\n",
      "Train Epoch: 619 [0/1649 (0%)]\tLoss: 0.005546\n",
      "\n",
      "Test set: Average loss: 0.0890, Accuracy: 401/412 (97%)\n",
      "\n",
      "Train Epoch: 620 [0/1649 (0%)]\tLoss: 0.014156\n",
      "\n",
      "Test set: Average loss: 0.0905, Accuracy: 401/412 (97%)\n",
      "\n",
      "Train Epoch: 621 [0/1649 (0%)]\tLoss: 0.004871\n",
      "\n",
      "Test set: Average loss: 0.0920, Accuracy: 401/412 (97%)\n",
      "\n",
      "Train Epoch: 622 [0/1649 (0%)]\tLoss: 0.083797\n",
      "\n",
      "Test set: Average loss: 0.0920, Accuracy: 401/412 (97%)\n",
      "\n",
      "Train Epoch: 623 [0/1649 (0%)]\tLoss: 0.026934\n",
      "\n",
      "Test set: Average loss: 0.0975, Accuracy: 402/412 (98%)\n",
      "\n",
      "Train Epoch: 624 [0/1649 (0%)]\tLoss: 0.030899\n",
      "\n",
      "Test set: Average loss: 0.1155, Accuracy: 401/412 (97%)\n",
      "\n",
      "Train Epoch: 625 [0/1649 (0%)]\tLoss: 0.011188\n",
      "\n",
      "Test set: Average loss: 0.1366, Accuracy: 398/412 (97%)\n",
      "\n",
      "Train Epoch: 626 [0/1649 (0%)]\tLoss: 0.041621\n",
      "\n",
      "Test set: Average loss: 0.1283, Accuracy: 398/412 (97%)\n",
      "\n",
      "Train Epoch: 627 [0/1649 (0%)]\tLoss: 0.058480\n",
      "\n",
      "Test set: Average loss: 0.1093, Accuracy: 401/412 (97%)\n",
      "\n",
      "Train Epoch: 628 [0/1649 (0%)]\tLoss: 0.008668\n",
      "\n",
      "Test set: Average loss: 0.1040, Accuracy: 401/412 (97%)\n",
      "\n",
      "Train Epoch: 629 [0/1649 (0%)]\tLoss: 0.147892\n",
      "\n",
      "Test set: Average loss: 0.0914, Accuracy: 402/412 (98%)\n",
      "\n",
      "Train Epoch: 630 [0/1649 (0%)]\tLoss: 0.000600\n",
      "\n",
      "Test set: Average loss: 0.0844, Accuracy: 403/412 (98%)\n",
      "\n",
      "Train Epoch: 631 [0/1649 (0%)]\tLoss: 0.001087\n",
      "\n",
      "Test set: Average loss: 0.0809, Accuracy: 404/412 (98%)\n",
      "\n",
      "Train Epoch: 632 [0/1649 (0%)]\tLoss: 0.039840\n",
      "\n",
      "Test set: Average loss: 0.0805, Accuracy: 404/412 (98%)\n",
      "\n",
      "Train Epoch: 633 [0/1649 (0%)]\tLoss: 0.001290\n",
      "\n",
      "Test set: Average loss: 0.0858, Accuracy: 401/412 (97%)\n",
      "\n",
      "Train Epoch: 634 [0/1649 (0%)]\tLoss: 0.000716\n",
      "\n",
      "Test set: Average loss: 0.0956, Accuracy: 401/412 (97%)\n",
      "\n",
      "Train Epoch: 635 [0/1649 (0%)]\tLoss: 0.029559\n",
      "\n",
      "Test set: Average loss: 0.1026, Accuracy: 400/412 (97%)\n",
      "\n",
      "Train Epoch: 636 [0/1649 (0%)]\tLoss: 0.070642\n",
      "\n",
      "Test set: Average loss: 0.1065, Accuracy: 401/412 (97%)\n",
      "\n",
      "Train Epoch: 637 [0/1649 (0%)]\tLoss: 0.127007\n",
      "\n",
      "Test set: Average loss: 0.0703, Accuracy: 405/412 (98%)\n",
      "\n",
      "Train Epoch: 638 [0/1649 (0%)]\tLoss: 0.014070\n",
      "\n",
      "Test set: Average loss: 0.0551, Accuracy: 405/412 (98%)\n",
      "\n",
      "Train Epoch: 639 [0/1649 (0%)]\tLoss: 0.014329\n",
      "\n",
      "Test set: Average loss: 0.0510, Accuracy: 403/412 (98%)\n",
      "\n",
      "Train Epoch: 640 [0/1649 (0%)]\tLoss: 0.011483\n",
      "\n",
      "Test set: Average loss: 0.0507, Accuracy: 403/412 (98%)\n",
      "\n",
      "Train Epoch: 641 [0/1649 (0%)]\tLoss: 0.105854\n",
      "\n",
      "Test set: Average loss: 0.0382, Accuracy: 407/412 (99%)\n",
      "\n",
      "Train Epoch: 642 [0/1649 (0%)]\tLoss: 0.001820\n",
      "\n",
      "Test set: Average loss: 0.0425, Accuracy: 407/412 (99%)\n",
      "\n",
      "Train Epoch: 643 [0/1649 (0%)]\tLoss: 0.004978\n",
      "\n",
      "Test set: Average loss: 0.0513, Accuracy: 404/412 (98%)\n",
      "\n",
      "Train Epoch: 644 [0/1649 (0%)]\tLoss: 0.009958\n",
      "\n",
      "Test set: Average loss: 0.0636, Accuracy: 402/412 (98%)\n",
      "\n",
      "Train Epoch: 645 [0/1649 (0%)]\tLoss: 0.015784\n",
      "\n",
      "Test set: Average loss: 0.0824, Accuracy: 399/412 (97%)\n",
      "\n",
      "Train Epoch: 646 [0/1649 (0%)]\tLoss: 0.067630\n",
      "\n",
      "Test set: Average loss: 0.1002, Accuracy: 396/412 (96%)\n",
      "\n",
      "Train Epoch: 647 [0/1649 (0%)]\tLoss: 0.002343\n",
      "\n",
      "Test set: Average loss: 0.1232, Accuracy: 395/412 (96%)\n",
      "\n",
      "Train Epoch: 648 [0/1649 (0%)]\tLoss: 0.022137\n",
      "\n",
      "Test set: Average loss: 0.1478, Accuracy: 392/412 (95%)\n",
      "\n",
      "Train Epoch: 649 [0/1649 (0%)]\tLoss: 0.008799\n",
      "\n",
      "Test set: Average loss: 0.1723, Accuracy: 388/412 (94%)\n",
      "\n",
      "Train Epoch: 650 [0/1649 (0%)]\tLoss: 0.049786\n",
      "\n",
      "Test set: Average loss: 0.1452, Accuracy: 393/412 (95%)\n",
      "\n",
      "Train Epoch: 651 [0/1649 (0%)]\tLoss: 0.051748\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.1223, Accuracy: 399/412 (97%)\n",
      "\n",
      "Train Epoch: 652 [0/1649 (0%)]\tLoss: 0.011761\n",
      "\n",
      "Test set: Average loss: 0.1130, Accuracy: 399/412 (97%)\n",
      "\n",
      "Train Epoch: 653 [0/1649 (0%)]\tLoss: 0.042023\n",
      "\n",
      "Test set: Average loss: 0.1049, Accuracy: 402/412 (98%)\n",
      "\n",
      "Train Epoch: 654 [0/1649 (0%)]\tLoss: 0.127398\n",
      "\n",
      "Test set: Average loss: 0.1201, Accuracy: 401/412 (97%)\n",
      "\n",
      "Train Epoch: 655 [0/1649 (0%)]\tLoss: 0.012154\n",
      "\n",
      "Test set: Average loss: 0.1451, Accuracy: 397/412 (96%)\n",
      "\n",
      "Train Epoch: 656 [0/1649 (0%)]\tLoss: 0.003009\n",
      "\n",
      "Test set: Average loss: 0.2028, Accuracy: 389/412 (94%)\n",
      "\n",
      "Train Epoch: 657 [0/1649 (0%)]\tLoss: 0.007114\n",
      "\n",
      "Test set: Average loss: 0.2739, Accuracy: 387/412 (94%)\n",
      "\n",
      "Train Epoch: 658 [0/1649 (0%)]\tLoss: 0.004799\n",
      "\n",
      "Test set: Average loss: 0.3505, Accuracy: 382/412 (93%)\n",
      "\n",
      "Train Epoch: 659 [0/1649 (0%)]\tLoss: 0.099129\n",
      "\n",
      "Test set: Average loss: 0.2766, Accuracy: 390/412 (95%)\n",
      "\n",
      "Train Epoch: 660 [0/1649 (0%)]\tLoss: 0.052095\n",
      "\n",
      "Test set: Average loss: 0.2095, Accuracy: 394/412 (96%)\n",
      "\n",
      "Train Epoch: 661 [0/1649 (0%)]\tLoss: 0.012363\n",
      "\n",
      "Test set: Average loss: 0.1666, Accuracy: 398/412 (97%)\n",
      "\n",
      "Train Epoch: 662 [0/1649 (0%)]\tLoss: 0.020752\n",
      "\n",
      "Test set: Average loss: 0.1383, Accuracy: 401/412 (97%)\n",
      "\n",
      "Train Epoch: 663 [0/1649 (0%)]\tLoss: 0.073117\n",
      "\n",
      "Test set: Average loss: 0.1142, Accuracy: 403/412 (98%)\n",
      "\n",
      "Train Epoch: 664 [0/1649 (0%)]\tLoss: 0.001349\n",
      "\n",
      "Test set: Average loss: 0.0982, Accuracy: 403/412 (98%)\n",
      "\n",
      "Train Epoch: 665 [0/1649 (0%)]\tLoss: 0.007649\n",
      "\n",
      "Test set: Average loss: 0.0911, Accuracy: 405/412 (98%)\n",
      "\n",
      "Train Epoch: 666 [0/1649 (0%)]\tLoss: 0.001201\n",
      "\n",
      "Test set: Average loss: 0.0928, Accuracy: 405/412 (98%)\n",
      "\n",
      "Train Epoch: 667 [0/1649 (0%)]\tLoss: 0.070469\n",
      "\n",
      "Test set: Average loss: 0.0961, Accuracy: 405/412 (98%)\n",
      "\n",
      "Train Epoch: 668 [0/1649 (0%)]\tLoss: 0.028454\n",
      "\n",
      "Test set: Average loss: 0.0942, Accuracy: 404/412 (98%)\n",
      "\n",
      "Train Epoch: 669 [0/1649 (0%)]\tLoss: 0.005514\n",
      "\n",
      "Test set: Average loss: 0.0970, Accuracy: 403/412 (98%)\n",
      "\n",
      "Train Epoch: 670 [0/1649 (0%)]\tLoss: 0.153582\n",
      "\n",
      "Test set: Average loss: 0.0848, Accuracy: 404/412 (98%)\n",
      "\n",
      "Train Epoch: 671 [0/1649 (0%)]\tLoss: 0.036106\n",
      "\n",
      "Test set: Average loss: 0.0769, Accuracy: 404/412 (98%)\n",
      "\n",
      "Train Epoch: 672 [0/1649 (0%)]\tLoss: 0.040916\n",
      "\n",
      "Test set: Average loss: 0.0740, Accuracy: 402/412 (98%)\n",
      "\n",
      "Train Epoch: 673 [0/1649 (0%)]\tLoss: 0.068115\n",
      "\n",
      "Test set: Average loss: 0.0751, Accuracy: 404/412 (98%)\n",
      "\n",
      "Train Epoch: 674 [0/1649 (0%)]\tLoss: 0.002776\n",
      "\n",
      "Test set: Average loss: 0.0798, Accuracy: 403/412 (98%)\n",
      "\n",
      "Train Epoch: 675 [0/1649 (0%)]\tLoss: 0.011089\n",
      "\n",
      "Test set: Average loss: 0.0797, Accuracy: 403/412 (98%)\n",
      "\n",
      "Train Epoch: 676 [0/1649 (0%)]\tLoss: 0.002083\n",
      "\n",
      "Test set: Average loss: 0.0809, Accuracy: 402/412 (98%)\n",
      "\n",
      "Train Epoch: 677 [0/1649 (0%)]\tLoss: 0.008187\n",
      "\n",
      "Test set: Average loss: 0.0835, Accuracy: 401/412 (97%)\n",
      "\n",
      "Train Epoch: 678 [0/1649 (0%)]\tLoss: 0.018541\n",
      "\n",
      "Test set: Average loss: 0.0844, Accuracy: 402/412 (98%)\n",
      "\n",
      "Train Epoch: 679 [0/1649 (0%)]\tLoss: 0.007762\n",
      "\n",
      "Test set: Average loss: 0.0857, Accuracy: 401/412 (97%)\n",
      "\n",
      "Train Epoch: 680 [0/1649 (0%)]\tLoss: 0.001638\n",
      "\n",
      "Test set: Average loss: 0.0886, Accuracy: 401/412 (97%)\n",
      "\n",
      "Train Epoch: 681 [0/1649 (0%)]\tLoss: 0.021795\n",
      "\n",
      "Test set: Average loss: 0.0906, Accuracy: 403/412 (98%)\n",
      "\n",
      "Train Epoch: 682 [0/1649 (0%)]\tLoss: 0.017348\n",
      "\n",
      "Test set: Average loss: 0.0943, Accuracy: 403/412 (98%)\n",
      "\n",
      "Train Epoch: 683 [0/1649 (0%)]\tLoss: 0.006505\n",
      "\n",
      "Test set: Average loss: 0.1019, Accuracy: 402/412 (98%)\n",
      "\n",
      "Train Epoch: 684 [0/1649 (0%)]\tLoss: 0.048101\n",
      "\n",
      "Test set: Average loss: 0.1110, Accuracy: 401/412 (97%)\n",
      "\n",
      "Train Epoch: 685 [0/1649 (0%)]\tLoss: 0.022409\n",
      "\n",
      "Test set: Average loss: 0.1106, Accuracy: 400/412 (97%)\n",
      "\n",
      "Train Epoch: 686 [0/1649 (0%)]\tLoss: 0.188723\n",
      "\n",
      "Test set: Average loss: 0.0660, Accuracy: 403/412 (98%)\n",
      "\n",
      "Train Epoch: 687 [0/1649 (0%)]\tLoss: 0.008750\n",
      "\n",
      "Test set: Average loss: 0.0579, Accuracy: 405/412 (98%)\n",
      "\n",
      "Train Epoch: 688 [0/1649 (0%)]\tLoss: 0.002151\n",
      "\n",
      "Test set: Average loss: 0.0641, Accuracy: 406/412 (99%)\n",
      "\n",
      "Train Epoch: 689 [0/1649 (0%)]\tLoss: 0.005488\n",
      "\n",
      "Test set: Average loss: 0.0761, Accuracy: 404/412 (98%)\n",
      "\n",
      "Train Epoch: 690 [0/1649 (0%)]\tLoss: 0.002380\n",
      "\n",
      "Test set: Average loss: 0.0924, Accuracy: 402/412 (98%)\n",
      "\n",
      "Train Epoch: 691 [0/1649 (0%)]\tLoss: 0.006668\n",
      "\n",
      "Test set: Average loss: 0.1088, Accuracy: 399/412 (97%)\n",
      "\n",
      "Train Epoch: 692 [0/1649 (0%)]\tLoss: 0.085916\n",
      "\n",
      "Test set: Average loss: 0.0993, Accuracy: 399/412 (97%)\n",
      "\n",
      "Train Epoch: 693 [0/1649 (0%)]\tLoss: 0.013378\n",
      "\n",
      "Test set: Average loss: 0.0827, Accuracy: 403/412 (98%)\n",
      "\n",
      "Train Epoch: 694 [0/1649 (0%)]\tLoss: 0.004522\n",
      "\n",
      "Test set: Average loss: 0.0706, Accuracy: 405/412 (98%)\n",
      "\n",
      "Train Epoch: 695 [0/1649 (0%)]\tLoss: 0.004911\n",
      "\n",
      "Test set: Average loss: 0.0634, Accuracy: 404/412 (98%)\n",
      "\n",
      "Train Epoch: 696 [0/1649 (0%)]\tLoss: 0.028711\n",
      "\n",
      "Test set: Average loss: 0.0584, Accuracy: 405/412 (98%)\n",
      "\n",
      "Train Epoch: 697 [0/1649 (0%)]\tLoss: 0.055566\n",
      "\n",
      "Test set: Average loss: 0.0611, Accuracy: 404/412 (98%)\n",
      "\n",
      "Train Epoch: 698 [0/1649 (0%)]\tLoss: 0.009018\n",
      "\n",
      "Test set: Average loss: 0.0725, Accuracy: 404/412 (98%)\n",
      "\n",
      "Train Epoch: 699 [0/1649 (0%)]\tLoss: 0.005117\n",
      "\n",
      "Test set: Average loss: 0.0884, Accuracy: 401/412 (97%)\n",
      "\n",
      "Train Epoch: 700 [0/1649 (0%)]\tLoss: 0.003047\n",
      "\n",
      "Test set: Average loss: 0.1056, Accuracy: 400/412 (97%)\n",
      "\n",
      "Train Epoch: 701 [0/1649 (0%)]\tLoss: 0.001023\n",
      "\n",
      "Test set: Average loss: 0.1231, Accuracy: 400/412 (97%)\n",
      "\n",
      "Train Epoch: 702 [0/1649 (0%)]\tLoss: 0.027821\n",
      "\n",
      "Test set: Average loss: 0.1212, Accuracy: 400/412 (97%)\n",
      "\n",
      "Train Epoch: 703 [0/1649 (0%)]\tLoss: 0.170835\n",
      "\n",
      "Test set: Average loss: 0.1101, Accuracy: 403/412 (98%)\n",
      "\n",
      "Train Epoch: 704 [0/1649 (0%)]\tLoss: 0.003116\n",
      "\n",
      "Test set: Average loss: 0.1064, Accuracy: 405/412 (98%)\n",
      "\n",
      "Train Epoch: 705 [0/1649 (0%)]\tLoss: 0.006013\n",
      "\n",
      "Test set: Average loss: 0.1045, Accuracy: 405/412 (98%)\n",
      "\n",
      "Train Epoch: 706 [0/1649 (0%)]\tLoss: 0.059627\n",
      "\n",
      "Test set: Average loss: 0.1070, Accuracy: 405/412 (98%)\n",
      "\n",
      "Train Epoch: 707 [0/1649 (0%)]\tLoss: 0.019973\n",
      "\n",
      "Test set: Average loss: 0.1054, Accuracy: 404/412 (98%)\n",
      "\n",
      "Train Epoch: 708 [0/1649 (0%)]\tLoss: 0.002739\n",
      "\n",
      "Test set: Average loss: 0.1043, Accuracy: 404/412 (98%)\n",
      "\n",
      "Train Epoch: 709 [0/1649 (0%)]\tLoss: 0.003221\n",
      "\n",
      "Test set: Average loss: 0.1035, Accuracy: 403/412 (98%)\n",
      "\n",
      "Train Epoch: 710 [0/1649 (0%)]\tLoss: 0.005379\n",
      "\n",
      "Test set: Average loss: 0.1041, Accuracy: 403/412 (98%)\n",
      "\n",
      "Train Epoch: 711 [0/1649 (0%)]\tLoss: 0.028461\n",
      "\n",
      "Test set: Average loss: 0.1033, Accuracy: 402/412 (98%)\n",
      "\n",
      "Train Epoch: 712 [0/1649 (0%)]\tLoss: 0.002132\n",
      "\n",
      "Test set: Average loss: 0.1042, Accuracy: 402/412 (98%)\n",
      "\n",
      "Train Epoch: 713 [0/1649 (0%)]\tLoss: 0.003971\n",
      "\n",
      "Test set: Average loss: 0.1042, Accuracy: 402/412 (98%)\n",
      "\n",
      "Train Epoch: 714 [0/1649 (0%)]\tLoss: 0.063975\n",
      "\n",
      "Test set: Average loss: 0.0892, Accuracy: 404/412 (98%)\n",
      "\n",
      "Train Epoch: 715 [0/1649 (0%)]\tLoss: 0.002743\n",
      "\n",
      "Test set: Average loss: 0.0794, Accuracy: 404/412 (98%)\n",
      "\n",
      "Train Epoch: 716 [0/1649 (0%)]\tLoss: 0.007559\n",
      "\n",
      "Test set: Average loss: 0.0714, Accuracy: 405/412 (98%)\n",
      "\n",
      "Train Epoch: 717 [0/1649 (0%)]\tLoss: 0.050112\n",
      "\n",
      "Test set: Average loss: 0.0660, Accuracy: 405/412 (98%)\n",
      "\n",
      "Train Epoch: 718 [0/1649 (0%)]\tLoss: 0.000676\n",
      "\n",
      "Test set: Average loss: 0.0631, Accuracy: 405/412 (98%)\n",
      "\n",
      "Train Epoch: 719 [0/1649 (0%)]\tLoss: 0.001583\n",
      "\n",
      "Test set: Average loss: 0.0605, Accuracy: 406/412 (99%)\n",
      "\n",
      "Train Epoch: 720 [0/1649 (0%)]\tLoss: 0.076500\n",
      "\n",
      "Test set: Average loss: 0.0568, Accuracy: 407/412 (99%)\n",
      "\n",
      "Train Epoch: 721 [0/1649 (0%)]\tLoss: 0.006020\n",
      "\n",
      "Test set: Average loss: 0.0545, Accuracy: 408/412 (99%)\n",
      "\n",
      "Train Epoch: 722 [0/1649 (0%)]\tLoss: 0.003926\n",
      "\n",
      "Test set: Average loss: 0.0539, Accuracy: 407/412 (99%)\n",
      "\n",
      "Train Epoch: 723 [0/1649 (0%)]\tLoss: 0.009145\n",
      "\n",
      "Test set: Average loss: 0.0539, Accuracy: 405/412 (98%)\n",
      "\n",
      "Train Epoch: 724 [0/1649 (0%)]\tLoss: 0.000568\n",
      "\n",
      "Test set: Average loss: 0.0544, Accuracy: 407/412 (99%)\n",
      "\n",
      "Train Epoch: 725 [0/1649 (0%)]\tLoss: 0.000784\n",
      "\n",
      "Test set: Average loss: 0.0560, Accuracy: 407/412 (99%)\n",
      "\n",
      "Train Epoch: 726 [0/1649 (0%)]\tLoss: 0.003566\n",
      "\n",
      "Test set: Average loss: 0.0576, Accuracy: 407/412 (99%)\n",
      "\n",
      "Train Epoch: 727 [0/1649 (0%)]\tLoss: 0.023699\n",
      "\n",
      "Test set: Average loss: 0.0593, Accuracy: 406/412 (99%)\n",
      "\n",
      "Train Epoch: 728 [0/1649 (0%)]\tLoss: 0.001887\n",
      "\n",
      "Test set: Average loss: 0.0610, Accuracy: 406/412 (99%)\n",
      "\n",
      "Train Epoch: 729 [0/1649 (0%)]\tLoss: 0.003021\n",
      "\n",
      "Test set: Average loss: 0.0627, Accuracy: 405/412 (98%)\n",
      "\n",
      "Train Epoch: 730 [0/1649 (0%)]\tLoss: 0.042534\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.0571, Accuracy: 405/412 (98%)\n",
      "\n",
      "Train Epoch: 731 [0/1649 (0%)]\tLoss: 0.001469\n",
      "\n",
      "Test set: Average loss: 0.0544, Accuracy: 405/412 (98%)\n",
      "\n",
      "Train Epoch: 732 [0/1649 (0%)]\tLoss: 0.007013\n",
      "\n",
      "Test set: Average loss: 0.0529, Accuracy: 405/412 (98%)\n",
      "\n",
      "Train Epoch: 733 [0/1649 (0%)]\tLoss: 0.002581\n",
      "\n",
      "Test set: Average loss: 0.0520, Accuracy: 404/412 (98%)\n",
      "\n",
      "Train Epoch: 734 [0/1649 (0%)]\tLoss: 0.000371\n",
      "\n",
      "Test set: Average loss: 0.0525, Accuracy: 405/412 (98%)\n",
      "\n",
      "Train Epoch: 735 [0/1649 (0%)]\tLoss: 0.000842\n",
      "\n",
      "Test set: Average loss: 0.0529, Accuracy: 405/412 (98%)\n",
      "\n",
      "Train Epoch: 736 [0/1649 (0%)]\tLoss: 0.003001\n",
      "\n",
      "Test set: Average loss: 0.0534, Accuracy: 405/412 (98%)\n",
      "\n",
      "Train Epoch: 737 [0/1649 (0%)]\tLoss: 0.007412\n",
      "\n",
      "Test set: Average loss: 0.0529, Accuracy: 405/412 (98%)\n",
      "\n",
      "Train Epoch: 738 [0/1649 (0%)]\tLoss: 0.003742\n",
      "\n",
      "Test set: Average loss: 0.0523, Accuracy: 405/412 (98%)\n",
      "\n",
      "Train Epoch: 739 [0/1649 (0%)]\tLoss: 0.001377\n",
      "\n",
      "Test set: Average loss: 0.0510, Accuracy: 405/412 (98%)\n",
      "\n",
      "Train Epoch: 740 [0/1649 (0%)]\tLoss: 0.022003\n",
      "\n",
      "Test set: Average loss: 0.0482, Accuracy: 407/412 (99%)\n",
      "\n",
      "Train Epoch: 741 [0/1649 (0%)]\tLoss: 0.004656\n",
      "\n",
      "Test set: Average loss: 0.0476, Accuracy: 406/412 (99%)\n",
      "\n",
      "Train Epoch: 742 [0/1649 (0%)]\tLoss: 0.000851\n",
      "\n",
      "Test set: Average loss: 0.0485, Accuracy: 406/412 (99%)\n",
      "\n",
      "Train Epoch: 743 [0/1649 (0%)]\tLoss: 0.001306\n",
      "\n",
      "Test set: Average loss: 0.0494, Accuracy: 406/412 (99%)\n",
      "\n",
      "Train Epoch: 744 [0/1649 (0%)]\tLoss: 0.045596\n",
      "\n",
      "Test set: Average loss: 0.0454, Accuracy: 407/412 (99%)\n",
      "\n",
      "Train Epoch: 745 [0/1649 (0%)]\tLoss: 0.002154\n",
      "\n",
      "Test set: Average loss: 0.0440, Accuracy: 409/412 (99%)\n",
      "\n",
      "Train Epoch: 746 [0/1649 (0%)]\tLoss: 0.000714\n",
      "\n",
      "Test set: Average loss: 0.0447, Accuracy: 409/412 (99%)\n",
      "\n",
      "Train Epoch: 747 [0/1649 (0%)]\tLoss: 0.005295\n",
      "\n",
      "Test set: Average loss: 0.0465, Accuracy: 409/412 (99%)\n",
      "\n",
      "Train Epoch: 748 [0/1649 (0%)]\tLoss: 0.008870\n",
      "\n",
      "Test set: Average loss: 0.0476, Accuracy: 408/412 (99%)\n",
      "\n",
      "Train Epoch: 749 [0/1649 (0%)]\tLoss: 0.001035\n",
      "\n",
      "Test set: Average loss: 0.0488, Accuracy: 407/412 (99%)\n",
      "\n",
      "Train Epoch: 750 [0/1649 (0%)]\tLoss: 0.006065\n",
      "\n",
      "Test set: Average loss: 0.0497, Accuracy: 407/412 (99%)\n",
      "\n",
      "Train Epoch: 751 [0/1649 (0%)]\tLoss: 0.002155\n",
      "\n",
      "Test set: Average loss: 0.0510, Accuracy: 407/412 (99%)\n",
      "\n",
      "Train Epoch: 752 [0/1649 (0%)]\tLoss: 0.012832\n",
      "\n",
      "Test set: Average loss: 0.0512, Accuracy: 408/412 (99%)\n",
      "\n",
      "Train Epoch: 753 [0/1649 (0%)]\tLoss: 0.004302\n",
      "\n",
      "Test set: Average loss: 0.0521, Accuracy: 408/412 (99%)\n",
      "\n",
      "Train Epoch: 754 [0/1649 (0%)]\tLoss: 0.004308\n",
      "\n",
      "Test set: Average loss: 0.0532, Accuracy: 408/412 (99%)\n",
      "\n",
      "Train Epoch: 755 [0/1649 (0%)]\tLoss: 0.000316\n",
      "\n",
      "Test set: Average loss: 0.0556, Accuracy: 407/412 (99%)\n",
      "\n",
      "Train Epoch: 756 [0/1649 (0%)]\tLoss: 0.000555\n",
      "\n",
      "Test set: Average loss: 0.0577, Accuracy: 406/412 (99%)\n",
      "\n",
      "Train Epoch: 757 [0/1649 (0%)]\tLoss: 0.000463\n",
      "\n",
      "Test set: Average loss: 0.0603, Accuracy: 406/412 (99%)\n",
      "\n",
      "Train Epoch: 758 [0/1649 (0%)]\tLoss: 0.010151\n",
      "\n",
      "Test set: Average loss: 0.0598, Accuracy: 406/412 (99%)\n",
      "\n",
      "Train Epoch: 759 [0/1649 (0%)]\tLoss: 0.007380\n",
      "\n",
      "Test set: Average loss: 0.0581, Accuracy: 406/412 (99%)\n",
      "\n",
      "Train Epoch: 760 [0/1649 (0%)]\tLoss: 0.005309\n",
      "\n",
      "Test set: Average loss: 0.0563, Accuracy: 406/412 (99%)\n",
      "\n",
      "Train Epoch: 761 [0/1649 (0%)]\tLoss: 0.011458\n",
      "\n",
      "Test set: Average loss: 0.0531, Accuracy: 407/412 (99%)\n",
      "\n",
      "Train Epoch: 762 [0/1649 (0%)]\tLoss: 0.001751\n",
      "\n",
      "Test set: Average loss: 0.0504, Accuracy: 407/412 (99%)\n",
      "\n",
      "Train Epoch: 763 [0/1649 (0%)]\tLoss: 0.001204\n",
      "\n",
      "Test set: Average loss: 0.0482, Accuracy: 408/412 (99%)\n",
      "\n",
      "Train Epoch: 764 [0/1649 (0%)]\tLoss: 0.000825\n",
      "\n",
      "Test set: Average loss: 0.0475, Accuracy: 408/412 (99%)\n",
      "\n",
      "Train Epoch: 765 [0/1649 (0%)]\tLoss: 0.008102\n",
      "\n",
      "Test set: Average loss: 0.0454, Accuracy: 408/412 (99%)\n",
      "\n",
      "Train Epoch: 766 [0/1649 (0%)]\tLoss: 0.001058\n",
      "\n",
      "Test set: Average loss: 0.0442, Accuracy: 408/412 (99%)\n",
      "\n",
      "Train Epoch: 767 [0/1649 (0%)]\tLoss: 0.002833\n",
      "\n",
      "Test set: Average loss: 0.0431, Accuracy: 409/412 (99%)\n",
      "\n",
      "Train Epoch: 768 [0/1649 (0%)]\tLoss: 0.001150\n",
      "\n",
      "Test set: Average loss: 0.0426, Accuracy: 409/412 (99%)\n",
      "\n",
      "Train Epoch: 769 [0/1649 (0%)]\tLoss: 0.001321\n",
      "\n",
      "Test set: Average loss: 0.0422, Accuracy: 409/412 (99%)\n",
      "\n",
      "Train Epoch: 770 [0/1649 (0%)]\tLoss: 0.000364\n",
      "\n",
      "Test set: Average loss: 0.0420, Accuracy: 409/412 (99%)\n",
      "\n",
      "Train Epoch: 771 [0/1649 (0%)]\tLoss: 0.005605\n",
      "\n",
      "Test set: Average loss: 0.0418, Accuracy: 409/412 (99%)\n",
      "\n",
      "Train Epoch: 772 [0/1649 (0%)]\tLoss: 0.003835\n",
      "\n",
      "Test set: Average loss: 0.0414, Accuracy: 409/412 (99%)\n",
      "\n",
      "Train Epoch: 773 [0/1649 (0%)]\tLoss: 0.002000\n",
      "\n",
      "Test set: Average loss: 0.0412, Accuracy: 409/412 (99%)\n",
      "\n",
      "Train Epoch: 774 [0/1649 (0%)]\tLoss: 0.003839\n",
      "\n",
      "Test set: Average loss: 0.0411, Accuracy: 410/412 (100%)\n",
      "\n",
      "Train Epoch: 775 [0/1649 (0%)]\tLoss: 0.051955\n",
      "\n",
      "Test set: Average loss: 0.0418, Accuracy: 410/412 (100%)\n",
      "\n",
      "Train Epoch: 776 [0/1649 (0%)]\tLoss: 0.000603\n",
      "\n",
      "Test set: Average loss: 0.0437, Accuracy: 409/412 (99%)\n",
      "\n",
      "Train Epoch: 777 [0/1649 (0%)]\tLoss: 0.000206\n",
      "\n",
      "Test set: Average loss: 0.0464, Accuracy: 408/412 (99%)\n",
      "\n",
      "Train Epoch: 778 [0/1649 (0%)]\tLoss: 0.003384\n",
      "\n",
      "Test set: Average loss: 0.0495, Accuracy: 408/412 (99%)\n",
      "\n",
      "Train Epoch: 779 [0/1649 (0%)]\tLoss: 0.001447\n",
      "\n",
      "Test set: Average loss: 0.0540, Accuracy: 408/412 (99%)\n",
      "\n",
      "Train Epoch: 780 [0/1649 (0%)]\tLoss: 0.008173\n",
      "\n",
      "Test set: Average loss: 0.0571, Accuracy: 407/412 (99%)\n",
      "\n",
      "Train Epoch: 781 [0/1649 (0%)]\tLoss: 0.041738\n",
      "\n",
      "Test set: Average loss: 0.0580, Accuracy: 408/412 (99%)\n",
      "\n",
      "Train Epoch: 782 [0/1649 (0%)]\tLoss: 0.002681\n",
      "\n",
      "Test set: Average loss: 0.0590, Accuracy: 408/412 (99%)\n",
      "\n",
      "Train Epoch: 783 [0/1649 (0%)]\tLoss: 0.000386\n",
      "\n",
      "Test set: Average loss: 0.0617, Accuracy: 408/412 (99%)\n",
      "\n",
      "Train Epoch: 784 [0/1649 (0%)]\tLoss: 0.002697\n",
      "\n",
      "Test set: Average loss: 0.0649, Accuracy: 406/412 (99%)\n",
      "\n",
      "Train Epoch: 785 [0/1649 (0%)]\tLoss: 0.000168\n",
      "\n",
      "Test set: Average loss: 0.0682, Accuracy: 404/412 (98%)\n",
      "\n",
      "Train Epoch: 786 [0/1649 (0%)]\tLoss: 0.097027\n",
      "\n",
      "Test set: Average loss: 0.0494, Accuracy: 409/412 (99%)\n",
      "\n",
      "Train Epoch: 787 [0/1649 (0%)]\tLoss: 0.000341\n",
      "\n",
      "Test set: Average loss: 0.0576, Accuracy: 406/412 (99%)\n",
      "\n",
      "Train Epoch: 788 [0/1649 (0%)]\tLoss: 0.001095\n",
      "\n",
      "Test set: Average loss: 0.0793, Accuracy: 404/412 (98%)\n",
      "\n",
      "Train Epoch: 789 [0/1649 (0%)]\tLoss: 0.000603\n",
      "\n",
      "Test set: Average loss: 0.1073, Accuracy: 403/412 (98%)\n",
      "\n",
      "Train Epoch: 790 [0/1649 (0%)]\tLoss: 0.071195\n",
      "\n",
      "Test set: Average loss: 0.1187, Accuracy: 401/412 (97%)\n",
      "\n",
      "Train Epoch: 791 [0/1649 (0%)]\tLoss: 0.000333\n",
      "\n",
      "Test set: Average loss: 0.1315, Accuracy: 400/412 (97%)\n",
      "\n",
      "Train Epoch: 792 [0/1649 (0%)]\tLoss: 0.021854\n",
      "\n",
      "Test set: Average loss: 0.1102, Accuracy: 400/412 (97%)\n",
      "\n",
      "Train Epoch: 793 [0/1649 (0%)]\tLoss: 0.000865\n",
      "\n",
      "Test set: Average loss: 0.0966, Accuracy: 401/412 (97%)\n",
      "\n",
      "Train Epoch: 794 [0/1649 (0%)]\tLoss: 0.000759\n",
      "\n",
      "Test set: Average loss: 0.0886, Accuracy: 403/412 (98%)\n",
      "\n",
      "Train Epoch: 795 [0/1649 (0%)]\tLoss: 0.000613\n",
      "\n",
      "Test set: Average loss: 0.0842, Accuracy: 403/412 (98%)\n",
      "\n",
      "Train Epoch: 796 [0/1649 (0%)]\tLoss: 0.000776\n",
      "\n",
      "Test set: Average loss: 0.0820, Accuracy: 401/412 (97%)\n",
      "\n",
      "Train Epoch: 797 [0/1649 (0%)]\tLoss: 0.019104\n",
      "\n",
      "Test set: Average loss: 0.0819, Accuracy: 401/412 (97%)\n",
      "\n",
      "Train Epoch: 798 [0/1649 (0%)]\tLoss: 0.002487\n",
      "\n",
      "Test set: Average loss: 0.0817, Accuracy: 401/412 (97%)\n",
      "\n",
      "Train Epoch: 799 [0/1649 (0%)]\tLoss: 0.005398\n",
      "\n",
      "Test set: Average loss: 0.0840, Accuracy: 401/412 (97%)\n",
      "\n",
      "Train Epoch: 800 [0/1649 (0%)]\tLoss: 0.003018\n",
      "\n",
      "Test set: Average loss: 0.0865, Accuracy: 400/412 (97%)\n",
      "\n",
      "Train Epoch: 801 [0/1649 (0%)]\tLoss: 0.006752\n",
      "\n",
      "Test set: Average loss: 0.0859, Accuracy: 400/412 (97%)\n",
      "\n",
      "Train Epoch: 802 [0/1649 (0%)]\tLoss: 0.041426\n",
      "\n",
      "Test set: Average loss: 0.0777, Accuracy: 401/412 (97%)\n",
      "\n",
      "Train Epoch: 803 [0/1649 (0%)]\tLoss: 0.010928\n",
      "\n",
      "Test set: Average loss: 0.0708, Accuracy: 402/412 (98%)\n",
      "\n",
      "Train Epoch: 804 [0/1649 (0%)]\tLoss: 0.030128\n",
      "\n",
      "Test set: Average loss: 0.0623, Accuracy: 404/412 (98%)\n",
      "\n",
      "Train Epoch: 805 [0/1649 (0%)]\tLoss: 0.010095\n",
      "\n",
      "Test set: Average loss: 0.0544, Accuracy: 406/412 (99%)\n",
      "\n",
      "Train Epoch: 806 [0/1649 (0%)]\tLoss: 0.006424\n",
      "\n",
      "Test set: Average loss: 0.0492, Accuracy: 406/412 (99%)\n",
      "\n",
      "Train Epoch: 807 [0/1649 (0%)]\tLoss: 0.010302\n",
      "\n",
      "Test set: Average loss: 0.0462, Accuracy: 406/412 (99%)\n",
      "\n",
      "Train Epoch: 808 [0/1649 (0%)]\tLoss: 0.004178\n",
      "\n",
      "Test set: Average loss: 0.0467, Accuracy: 407/412 (99%)\n",
      "\n",
      "Train Epoch: 809 [0/1649 (0%)]\tLoss: 0.003905\n",
      "\n",
      "Test set: Average loss: 0.0481, Accuracy: 407/412 (99%)\n",
      "\n",
      "Train Epoch: 810 [0/1649 (0%)]\tLoss: 0.000546\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.0506, Accuracy: 408/412 (99%)\n",
      "\n",
      "Train Epoch: 811 [0/1649 (0%)]\tLoss: 0.004397\n",
      "\n",
      "Test set: Average loss: 0.0534, Accuracy: 408/412 (99%)\n",
      "\n",
      "Train Epoch: 812 [0/1649 (0%)]\tLoss: 0.002135\n",
      "\n",
      "Test set: Average loss: 0.0567, Accuracy: 408/412 (99%)\n",
      "\n",
      "Train Epoch: 813 [0/1649 (0%)]\tLoss: 0.001509\n",
      "\n",
      "Test set: Average loss: 0.0581, Accuracy: 408/412 (99%)\n",
      "\n",
      "Train Epoch: 814 [0/1649 (0%)]\tLoss: 0.007408\n",
      "\n",
      "Test set: Average loss: 0.0607, Accuracy: 407/412 (99%)\n",
      "\n",
      "Train Epoch: 815 [0/1649 (0%)]\tLoss: 0.000573\n",
      "\n",
      "Test set: Average loss: 0.0622, Accuracy: 406/412 (99%)\n",
      "\n",
      "Train Epoch: 816 [0/1649 (0%)]\tLoss: 0.000732\n",
      "\n",
      "Test set: Average loss: 0.0632, Accuracy: 406/412 (99%)\n",
      "\n",
      "Train Epoch: 817 [0/1649 (0%)]\tLoss: 0.026288\n",
      "\n",
      "Test set: Average loss: 0.0631, Accuracy: 406/412 (99%)\n",
      "\n",
      "Train Epoch: 818 [0/1649 (0%)]\tLoss: 0.001236\n",
      "\n",
      "Test set: Average loss: 0.0625, Accuracy: 407/412 (99%)\n",
      "\n",
      "Train Epoch: 819 [0/1649 (0%)]\tLoss: 0.000433\n",
      "\n",
      "Test set: Average loss: 0.0638, Accuracy: 406/412 (99%)\n",
      "\n",
      "Train Epoch: 820 [0/1649 (0%)]\tLoss: 0.002255\n",
      "\n",
      "Test set: Average loss: 0.0632, Accuracy: 406/412 (99%)\n",
      "\n",
      "Train Epoch: 821 [0/1649 (0%)]\tLoss: 0.042709\n",
      "\n",
      "Test set: Average loss: 0.0626, Accuracy: 406/412 (99%)\n",
      "\n",
      "Train Epoch: 822 [0/1649 (0%)]\tLoss: 0.001228\n",
      "\n",
      "Test set: Average loss: 0.0621, Accuracy: 405/412 (98%)\n",
      "\n",
      "Train Epoch: 823 [0/1649 (0%)]\tLoss: 0.018802\n",
      "\n",
      "Test set: Average loss: 0.0655, Accuracy: 405/412 (98%)\n",
      "\n",
      "Train Epoch: 824 [0/1649 (0%)]\tLoss: 0.000470\n",
      "\n",
      "Test set: Average loss: 0.0692, Accuracy: 405/412 (98%)\n",
      "\n",
      "Train Epoch: 825 [0/1649 (0%)]\tLoss: 0.003918\n",
      "\n",
      "Test set: Average loss: 0.0723, Accuracy: 405/412 (98%)\n",
      "\n",
      "Train Epoch: 826 [0/1649 (0%)]\tLoss: 0.001855\n",
      "\n",
      "Test set: Average loss: 0.0741, Accuracy: 405/412 (98%)\n",
      "\n",
      "Train Epoch: 827 [0/1649 (0%)]\tLoss: 0.008894\n",
      "\n",
      "Test set: Average loss: 0.0729, Accuracy: 405/412 (98%)\n",
      "\n",
      "Train Epoch: 828 [0/1649 (0%)]\tLoss: 0.018511\n",
      "\n",
      "Test set: Average loss: 0.0693, Accuracy: 406/412 (99%)\n",
      "\n",
      "Train Epoch: 829 [0/1649 (0%)]\tLoss: 0.018940\n",
      "\n",
      "Test set: Average loss: 0.0675, Accuracy: 406/412 (99%)\n",
      "\n",
      "Train Epoch: 830 [0/1649 (0%)]\tLoss: 0.055415\n",
      "\n",
      "Test set: Average loss: 0.0714, Accuracy: 405/412 (98%)\n",
      "\n",
      "Train Epoch: 831 [0/1649 (0%)]\tLoss: 0.003515\n",
      "\n",
      "Test set: Average loss: 0.0778, Accuracy: 405/412 (98%)\n",
      "\n",
      "Train Epoch: 832 [0/1649 (0%)]\tLoss: 0.000479\n",
      "\n",
      "Test set: Average loss: 0.0859, Accuracy: 405/412 (98%)\n",
      "\n",
      "Train Epoch: 833 [0/1649 (0%)]\tLoss: 0.000945\n",
      "\n",
      "Test set: Average loss: 0.0998, Accuracy: 404/412 (98%)\n",
      "\n",
      "Train Epoch: 834 [0/1649 (0%)]\tLoss: 0.000275\n",
      "\n",
      "Test set: Average loss: 0.1190, Accuracy: 401/412 (97%)\n",
      "\n",
      "Train Epoch: 835 [0/1649 (0%)]\tLoss: 0.264055\n",
      "\n",
      "Test set: Average loss: 0.0764, Accuracy: 405/412 (98%)\n",
      "\n",
      "Train Epoch: 836 [0/1649 (0%)]\tLoss: 0.007452\n",
      "\n",
      "Test set: Average loss: 0.0572, Accuracy: 406/412 (99%)\n",
      "\n",
      "Train Epoch: 837 [0/1649 (0%)]\tLoss: 0.002204\n",
      "\n",
      "Test set: Average loss: 0.0461, Accuracy: 407/412 (99%)\n",
      "\n",
      "Train Epoch: 838 [0/1649 (0%)]\tLoss: 0.000433\n",
      "\n",
      "Test set: Average loss: 0.0423, Accuracy: 406/412 (99%)\n",
      "\n",
      "Train Epoch: 839 [0/1649 (0%)]\tLoss: 0.003231\n",
      "\n",
      "Test set: Average loss: 0.0460, Accuracy: 404/412 (98%)\n",
      "\n",
      "Train Epoch: 840 [0/1649 (0%)]\tLoss: 0.008189\n",
      "\n",
      "Test set: Average loss: 0.0506, Accuracy: 404/412 (98%)\n",
      "\n",
      "Train Epoch: 841 [0/1649 (0%)]\tLoss: 0.007992\n",
      "\n",
      "Test set: Average loss: 0.0588, Accuracy: 403/412 (98%)\n",
      "\n",
      "Train Epoch: 842 [0/1649 (0%)]\tLoss: 0.006499\n",
      "\n",
      "Test set: Average loss: 0.0683, Accuracy: 402/412 (98%)\n",
      "\n",
      "Train Epoch: 843 [0/1649 (0%)]\tLoss: 0.018433\n",
      "\n",
      "Test set: Average loss: 0.0807, Accuracy: 401/412 (97%)\n",
      "\n",
      "Train Epoch: 844 [0/1649 (0%)]\tLoss: 0.066384\n",
      "\n",
      "Test set: Average loss: 0.0900, Accuracy: 399/412 (97%)\n",
      "\n",
      "Train Epoch: 845 [0/1649 (0%)]\tLoss: 0.083790\n",
      "\n",
      "Test set: Average loss: 0.0914, Accuracy: 400/412 (97%)\n",
      "\n",
      "Train Epoch: 846 [0/1649 (0%)]\tLoss: 0.013914\n",
      "\n",
      "Test set: Average loss: 0.0870, Accuracy: 402/412 (98%)\n",
      "\n",
      "Train Epoch: 847 [0/1649 (0%)]\tLoss: 0.063586\n",
      "\n",
      "Test set: Average loss: 0.0893, Accuracy: 403/412 (98%)\n",
      "\n",
      "Train Epoch: 848 [0/1649 (0%)]\tLoss: 0.002213\n",
      "\n",
      "Test set: Average loss: 0.0899, Accuracy: 403/412 (98%)\n",
      "\n",
      "Train Epoch: 849 [0/1649 (0%)]\tLoss: 0.001085\n",
      "\n",
      "Test set: Average loss: 0.0935, Accuracy: 403/412 (98%)\n",
      "\n",
      "Train Epoch: 850 [0/1649 (0%)]\tLoss: 0.005213\n",
      "\n",
      "Test set: Average loss: 0.0984, Accuracy: 404/412 (98%)\n",
      "\n",
      "Train Epoch: 851 [0/1649 (0%)]\tLoss: 0.035142\n",
      "\n",
      "Test set: Average loss: 0.0914, Accuracy: 403/412 (98%)\n",
      "\n",
      "Train Epoch: 852 [0/1649 (0%)]\tLoss: 0.014596\n",
      "\n",
      "Test set: Average loss: 0.0869, Accuracy: 403/412 (98%)\n",
      "\n",
      "Train Epoch: 853 [0/1649 (0%)]\tLoss: 0.005026\n",
      "\n",
      "Test set: Average loss: 0.0844, Accuracy: 404/412 (98%)\n",
      "\n",
      "Train Epoch: 854 [0/1649 (0%)]\tLoss: 0.003127\n",
      "\n",
      "Test set: Average loss: 0.0829, Accuracy: 404/412 (98%)\n",
      "\n",
      "Train Epoch: 855 [0/1649 (0%)]\tLoss: 0.014032\n",
      "\n",
      "Test set: Average loss: 0.0802, Accuracy: 404/412 (98%)\n",
      "\n",
      "Train Epoch: 856 [0/1649 (0%)]\tLoss: 0.002263\n",
      "\n",
      "Test set: Average loss: 0.0777, Accuracy: 404/412 (98%)\n",
      "\n",
      "Train Epoch: 857 [0/1649 (0%)]\tLoss: 0.056490\n",
      "\n",
      "Test set: Average loss: 0.0674, Accuracy: 404/412 (98%)\n",
      "\n",
      "Train Epoch: 858 [0/1649 (0%)]\tLoss: 0.000194\n",
      "\n",
      "Test set: Average loss: 0.0598, Accuracy: 405/412 (98%)\n",
      "\n",
      "Train Epoch: 859 [0/1649 (0%)]\tLoss: 0.005468\n",
      "\n",
      "Test set: Average loss: 0.0551, Accuracy: 405/412 (98%)\n",
      "\n",
      "Train Epoch: 860 [0/1649 (0%)]\tLoss: 0.019930\n",
      "\n",
      "Test set: Average loss: 0.0615, Accuracy: 406/412 (99%)\n",
      "\n",
      "Train Epoch: 861 [0/1649 (0%)]\tLoss: 0.004473\n",
      "\n",
      "Test set: Average loss: 0.0696, Accuracy: 405/412 (98%)\n",
      "\n",
      "Train Epoch: 862 [0/1649 (0%)]\tLoss: 0.068615\n",
      "\n",
      "Test set: Average loss: 0.0740, Accuracy: 407/412 (99%)\n",
      "\n",
      "Train Epoch: 863 [0/1649 (0%)]\tLoss: 0.007594\n",
      "\n",
      "Test set: Average loss: 0.0832, Accuracy: 407/412 (99%)\n",
      "\n",
      "Train Epoch: 864 [0/1649 (0%)]\tLoss: 0.020334\n",
      "\n",
      "Test set: Average loss: 0.0974, Accuracy: 406/412 (99%)\n",
      "\n",
      "Train Epoch: 865 [0/1649 (0%)]\tLoss: 0.001512\n",
      "\n",
      "Test set: Average loss: 0.1140, Accuracy: 404/412 (98%)\n",
      "\n",
      "Train Epoch: 866 [0/1649 (0%)]\tLoss: 0.077465\n",
      "\n",
      "Test set: Average loss: 0.1141, Accuracy: 404/412 (98%)\n",
      "\n",
      "Train Epoch: 867 [0/1649 (0%)]\tLoss: 0.003715\n",
      "\n",
      "Test set: Average loss: 0.1144, Accuracy: 405/412 (98%)\n",
      "\n",
      "Train Epoch: 868 [0/1649 (0%)]\tLoss: 0.000269\n",
      "\n",
      "Test set: Average loss: 0.1151, Accuracy: 404/412 (98%)\n",
      "\n",
      "Train Epoch: 869 [0/1649 (0%)]\tLoss: 0.017015\n",
      "\n",
      "Test set: Average loss: 0.1103, Accuracy: 405/412 (98%)\n",
      "\n",
      "Train Epoch: 870 [0/1649 (0%)]\tLoss: 0.230811\n",
      "\n",
      "Test set: Average loss: 0.0737, Accuracy: 405/412 (98%)\n",
      "\n",
      "Train Epoch: 871 [0/1649 (0%)]\tLoss: 0.002202\n",
      "\n",
      "Test set: Average loss: 0.0615, Accuracy: 405/412 (98%)\n",
      "\n",
      "Train Epoch: 872 [0/1649 (0%)]\tLoss: 0.011870\n",
      "\n",
      "Test set: Average loss: 0.0569, Accuracy: 406/412 (99%)\n",
      "\n",
      "Train Epoch: 873 [0/1649 (0%)]\tLoss: 0.000911\n",
      "\n",
      "Test set: Average loss: 0.0629, Accuracy: 406/412 (99%)\n",
      "\n",
      "Train Epoch: 874 [0/1649 (0%)]\tLoss: 0.027725\n",
      "\n",
      "Test set: Average loss: 0.0631, Accuracy: 406/412 (99%)\n",
      "\n",
      "Train Epoch: 875 [0/1649 (0%)]\tLoss: 0.008855\n",
      "\n",
      "Test set: Average loss: 0.0642, Accuracy: 406/412 (99%)\n",
      "\n",
      "Train Epoch: 876 [0/1649 (0%)]\tLoss: 0.029170\n",
      "\n",
      "Test set: Average loss: 0.0650, Accuracy: 406/412 (99%)\n",
      "\n",
      "Train Epoch: 877 [0/1649 (0%)]\tLoss: 0.002488\n",
      "\n",
      "Test set: Average loss: 0.0668, Accuracy: 407/412 (99%)\n",
      "\n",
      "Train Epoch: 878 [0/1649 (0%)]\tLoss: 0.005563\n",
      "\n",
      "Test set: Average loss: 0.0694, Accuracy: 405/412 (98%)\n",
      "\n",
      "Train Epoch: 879 [0/1649 (0%)]\tLoss: 0.000369\n",
      "\n",
      "Test set: Average loss: 0.0730, Accuracy: 405/412 (98%)\n",
      "\n",
      "Train Epoch: 880 [0/1649 (0%)]\tLoss: 0.018647\n",
      "\n",
      "Test set: Average loss: 0.0768, Accuracy: 404/412 (98%)\n",
      "\n",
      "Train Epoch: 881 [0/1649 (0%)]\tLoss: 0.033815\n",
      "\n",
      "Test set: Average loss: 0.0752, Accuracy: 405/412 (98%)\n",
      "\n",
      "Train Epoch: 882 [0/1649 (0%)]\tLoss: 0.000622\n",
      "\n",
      "Test set: Average loss: 0.0747, Accuracy: 405/412 (98%)\n",
      "\n",
      "Train Epoch: 883 [0/1649 (0%)]\tLoss: 0.001942\n",
      "\n",
      "Test set: Average loss: 0.0750, Accuracy: 405/412 (98%)\n",
      "\n",
      "Train Epoch: 884 [0/1649 (0%)]\tLoss: 0.001625\n",
      "\n",
      "Test set: Average loss: 0.0749, Accuracy: 405/412 (98%)\n",
      "\n",
      "Train Epoch: 885 [0/1649 (0%)]\tLoss: 0.001458\n",
      "\n",
      "Test set: Average loss: 0.0746, Accuracy: 405/412 (98%)\n",
      "\n",
      "Train Epoch: 886 [0/1649 (0%)]\tLoss: 0.000140\n",
      "\n",
      "Test set: Average loss: 0.0743, Accuracy: 405/412 (98%)\n",
      "\n",
      "Train Epoch: 887 [0/1649 (0%)]\tLoss: 0.028214\n",
      "\n",
      "Test set: Average loss: 0.0768, Accuracy: 404/412 (98%)\n",
      "\n",
      "Train Epoch: 888 [0/1649 (0%)]\tLoss: 0.001564\n",
      "\n",
      "Test set: Average loss: 0.0791, Accuracy: 404/412 (98%)\n",
      "\n",
      "Train Epoch: 889 [0/1649 (0%)]\tLoss: 0.002727\n",
      "\n",
      "Test set: Average loss: 0.0811, Accuracy: 403/412 (98%)\n",
      "\n",
      "Train Epoch: 890 [0/1649 (0%)]\tLoss: 0.012497\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.0774, Accuracy: 404/412 (98%)\n",
      "\n",
      "Train Epoch: 891 [0/1649 (0%)]\tLoss: 0.021469\n",
      "\n",
      "Test set: Average loss: 0.0633, Accuracy: 407/412 (99%)\n",
      "\n",
      "Train Epoch: 892 [0/1649 (0%)]\tLoss: 0.001512\n",
      "\n",
      "Test set: Average loss: 0.0639, Accuracy: 407/412 (99%)\n",
      "\n",
      "Train Epoch: 893 [0/1649 (0%)]\tLoss: 0.005414\n",
      "\n",
      "Test set: Average loss: 0.0738, Accuracy: 403/412 (98%)\n",
      "\n",
      "Train Epoch: 894 [0/1649 (0%)]\tLoss: 0.002317\n",
      "\n",
      "Test set: Average loss: 0.0885, Accuracy: 403/412 (98%)\n",
      "\n",
      "Train Epoch: 895 [0/1649 (0%)]\tLoss: 0.013459\n",
      "\n",
      "Test set: Average loss: 0.1119, Accuracy: 400/412 (97%)\n",
      "\n",
      "Train Epoch: 896 [0/1649 (0%)]\tLoss: 0.007271\n",
      "\n",
      "Test set: Average loss: 0.1549, Accuracy: 396/412 (96%)\n",
      "\n",
      "Train Epoch: 897 [0/1649 (0%)]\tLoss: 0.008524\n",
      "\n",
      "Test set: Average loss: 0.1920, Accuracy: 396/412 (96%)\n",
      "\n",
      "Train Epoch: 898 [0/1649 (0%)]\tLoss: 0.070045\n",
      "\n",
      "Test set: Average loss: 0.0976, Accuracy: 405/412 (98%)\n",
      "\n",
      "Train Epoch: 899 [0/1649 (0%)]\tLoss: 0.095247\n",
      "\n",
      "Test set: Average loss: 0.0739, Accuracy: 407/412 (99%)\n",
      "\n",
      "Train Epoch: 900 [0/1649 (0%)]\tLoss: 0.004243\n",
      "\n",
      "Test set: Average loss: 0.0756, Accuracy: 405/412 (98%)\n",
      "\n",
      "Train Epoch: 901 [0/1649 (0%)]\tLoss: 0.012481\n",
      "\n",
      "Test set: Average loss: 0.1021, Accuracy: 403/412 (98%)\n",
      "\n",
      "Train Epoch: 902 [0/1649 (0%)]\tLoss: 0.000786\n",
      "\n",
      "Test set: Average loss: 0.1846, Accuracy: 395/412 (96%)\n",
      "\n",
      "Train Epoch: 903 [0/1649 (0%)]\tLoss: 0.110110\n",
      "\n",
      "Test set: Average loss: 0.3386, Accuracy: 381/412 (92%)\n",
      "\n",
      "Train Epoch: 904 [0/1649 (0%)]\tLoss: 0.041173\n",
      "\n",
      "Test set: Average loss: 0.4118, Accuracy: 376/412 (91%)\n",
      "\n",
      "Train Epoch: 905 [0/1649 (0%)]\tLoss: 0.014274\n",
      "\n",
      "Test set: Average loss: 0.3922, Accuracy: 379/412 (92%)\n",
      "\n",
      "Train Epoch: 906 [0/1649 (0%)]\tLoss: 0.193627\n",
      "\n",
      "Test set: Average loss: 0.0909, Accuracy: 403/412 (98%)\n",
      "\n",
      "Train Epoch: 907 [0/1649 (0%)]\tLoss: 0.001699\n",
      "\n",
      "Test set: Average loss: 0.1005, Accuracy: 401/412 (97%)\n",
      "\n",
      "Train Epoch: 908 [0/1649 (0%)]\tLoss: 0.019728\n",
      "\n",
      "Test set: Average loss: 0.1962, Accuracy: 389/412 (94%)\n",
      "\n",
      "Train Epoch: 909 [0/1649 (0%)]\tLoss: 0.015878\n",
      "\n",
      "Test set: Average loss: 0.4192, Accuracy: 376/412 (91%)\n",
      "\n",
      "Train Epoch: 910 [0/1649 (0%)]\tLoss: 0.214201\n",
      "\n",
      "Test set: Average loss: 0.4091, Accuracy: 376/412 (91%)\n",
      "\n",
      "Train Epoch: 911 [0/1649 (0%)]\tLoss: 0.017049\n",
      "\n",
      "Test set: Average loss: 0.3708, Accuracy: 380/412 (92%)\n",
      "\n",
      "Train Epoch: 912 [0/1649 (0%)]\tLoss: 0.000249\n",
      "\n",
      "Test set: Average loss: 0.3444, Accuracy: 380/412 (92%)\n",
      "\n",
      "Train Epoch: 913 [0/1649 (0%)]\tLoss: 0.217032\n",
      "\n",
      "Test set: Average loss: 0.1624, Accuracy: 393/412 (95%)\n",
      "\n",
      "Train Epoch: 914 [0/1649 (0%)]\tLoss: 0.045325\n",
      "\n",
      "Test set: Average loss: 0.0992, Accuracy: 404/412 (98%)\n",
      "\n",
      "Train Epoch: 915 [0/1649 (0%)]\tLoss: 0.026541\n",
      "\n",
      "Test set: Average loss: 0.1101, Accuracy: 400/412 (97%)\n",
      "\n",
      "Train Epoch: 916 [0/1649 (0%)]\tLoss: 0.016978\n",
      "\n",
      "Test set: Average loss: 0.2484, Accuracy: 387/412 (94%)\n",
      "\n",
      "Train Epoch: 917 [0/1649 (0%)]\tLoss: 0.044826\n",
      "\n",
      "Test set: Average loss: 0.4000, Accuracy: 374/412 (91%)\n",
      "\n",
      "Train Epoch: 918 [0/1649 (0%)]\tLoss: 0.014887\n",
      "\n",
      "Test set: Average loss: 0.5631, Accuracy: 366/412 (89%)\n",
      "\n",
      "Train Epoch: 919 [0/1649 (0%)]\tLoss: 0.016614\n",
      "\n",
      "Test set: Average loss: 0.6171, Accuracy: 364/412 (88%)\n",
      "\n",
      "Train Epoch: 920 [0/1649 (0%)]\tLoss: 0.257757\n",
      "\n",
      "Test set: Average loss: 0.3192, Accuracy: 382/412 (93%)\n",
      "\n",
      "Train Epoch: 921 [0/1649 (0%)]\tLoss: 0.049997\n",
      "\n",
      "Test set: Average loss: 0.1696, Accuracy: 394/412 (96%)\n",
      "\n",
      "Train Epoch: 922 [0/1649 (0%)]\tLoss: 0.001022\n",
      "\n",
      "Test set: Average loss: 0.1501, Accuracy: 399/412 (97%)\n",
      "\n",
      "Train Epoch: 923 [0/1649 (0%)]\tLoss: 0.021783\n",
      "\n",
      "Test set: Average loss: 0.2058, Accuracy: 390/412 (95%)\n",
      "\n",
      "Train Epoch: 924 [0/1649 (0%)]\tLoss: 0.096124\n",
      "\n",
      "Test set: Average loss: 0.2390, Accuracy: 386/412 (94%)\n",
      "\n",
      "Train Epoch: 925 [0/1649 (0%)]\tLoss: 0.042540\n",
      "\n",
      "Test set: Average loss: 0.2151, Accuracy: 389/412 (94%)\n",
      "\n",
      "Train Epoch: 926 [0/1649 (0%)]\tLoss: 0.196746\n",
      "\n",
      "Test set: Average loss: 0.1428, Accuracy: 395/412 (96%)\n",
      "\n",
      "Train Epoch: 927 [0/1649 (0%)]\tLoss: 0.190524\n",
      "\n",
      "Test set: Average loss: 0.0896, Accuracy: 402/412 (98%)\n",
      "\n",
      "Train Epoch: 928 [0/1649 (0%)]\tLoss: 0.021142\n",
      "\n",
      "Test set: Average loss: 0.0778, Accuracy: 404/412 (98%)\n",
      "\n",
      "Train Epoch: 929 [0/1649 (0%)]\tLoss: 0.013786\n",
      "\n",
      "Test set: Average loss: 0.0792, Accuracy: 404/412 (98%)\n",
      "\n",
      "Train Epoch: 930 [0/1649 (0%)]\tLoss: 0.000773\n",
      "\n",
      "Test set: Average loss: 0.0917, Accuracy: 402/412 (98%)\n",
      "\n",
      "Train Epoch: 931 [0/1649 (0%)]\tLoss: 0.034791\n",
      "\n",
      "Test set: Average loss: 0.1077, Accuracy: 400/412 (97%)\n",
      "\n",
      "Train Epoch: 932 [0/1649 (0%)]\tLoss: 0.048161\n",
      "\n",
      "Test set: Average loss: 0.1194, Accuracy: 396/412 (96%)\n",
      "\n",
      "Train Epoch: 933 [0/1649 (0%)]\tLoss: 0.016830\n",
      "\n",
      "Test set: Average loss: 0.1229, Accuracy: 395/412 (96%)\n",
      "\n",
      "Train Epoch: 934 [0/1649 (0%)]\tLoss: 0.140212\n",
      "\n",
      "Test set: Average loss: 0.1135, Accuracy: 397/412 (96%)\n",
      "\n",
      "Train Epoch: 935 [0/1649 (0%)]\tLoss: 0.005390\n",
      "\n",
      "Test set: Average loss: 0.1160, Accuracy: 397/412 (96%)\n",
      "\n",
      "Train Epoch: 936 [0/1649 (0%)]\tLoss: 0.013044\n",
      "\n",
      "Test set: Average loss: 0.1194, Accuracy: 398/412 (97%)\n",
      "\n",
      "Train Epoch: 937 [0/1649 (0%)]\tLoss: 0.007975\n",
      "\n",
      "Test set: Average loss: 0.1213, Accuracy: 398/412 (97%)\n",
      "\n",
      "Train Epoch: 938 [0/1649 (0%)]\tLoss: 0.029364\n",
      "\n",
      "Test set: Average loss: 0.1158, Accuracy: 398/412 (97%)\n",
      "\n",
      "Train Epoch: 939 [0/1649 (0%)]\tLoss: 0.013118\n",
      "\n",
      "Test set: Average loss: 0.1120, Accuracy: 400/412 (97%)\n",
      "\n",
      "Train Epoch: 940 [0/1649 (0%)]\tLoss: 0.038378\n",
      "\n",
      "Test set: Average loss: 0.0972, Accuracy: 401/412 (97%)\n",
      "\n",
      "Train Epoch: 941 [0/1649 (0%)]\tLoss: 0.068391\n",
      "\n",
      "Test set: Average loss: 0.0848, Accuracy: 402/412 (98%)\n",
      "\n",
      "Train Epoch: 942 [0/1649 (0%)]\tLoss: 0.014974\n",
      "\n",
      "Test set: Average loss: 0.0789, Accuracy: 403/412 (98%)\n",
      "\n",
      "Train Epoch: 943 [0/1649 (0%)]\tLoss: 0.005759\n",
      "\n",
      "Test set: Average loss: 0.0780, Accuracy: 401/412 (97%)\n",
      "\n",
      "Train Epoch: 944 [0/1649 (0%)]\tLoss: 0.013162\n",
      "\n",
      "Test set: Average loss: 0.0822, Accuracy: 401/412 (97%)\n",
      "\n",
      "Train Epoch: 945 [0/1649 (0%)]\tLoss: 0.022575\n",
      "\n",
      "Test set: Average loss: 0.0865, Accuracy: 401/412 (97%)\n",
      "\n",
      "Train Epoch: 946 [0/1649 (0%)]\tLoss: 0.120825\n",
      "\n",
      "Test set: Average loss: 0.1077, Accuracy: 400/412 (97%)\n",
      "\n",
      "Train Epoch: 947 [0/1649 (0%)]\tLoss: 0.040590\n",
      "\n",
      "Test set: Average loss: 0.1119, Accuracy: 400/412 (97%)\n",
      "\n",
      "Train Epoch: 948 [0/1649 (0%)]\tLoss: 0.036895\n",
      "\n",
      "Test set: Average loss: 0.1096, Accuracy: 401/412 (97%)\n",
      "\n",
      "Train Epoch: 949 [0/1649 (0%)]\tLoss: 0.087200\n",
      "\n",
      "Test set: Average loss: 0.0980, Accuracy: 402/412 (98%)\n",
      "\n",
      "Train Epoch: 950 [0/1649 (0%)]\tLoss: 0.016886\n",
      "\n",
      "Test set: Average loss: 0.0898, Accuracy: 404/412 (98%)\n",
      "\n",
      "Train Epoch: 951 [0/1649 (0%)]\tLoss: 0.066942\n",
      "\n",
      "Test set: Average loss: 0.0628, Accuracy: 404/412 (98%)\n",
      "\n",
      "Train Epoch: 952 [0/1649 (0%)]\tLoss: 0.008881\n",
      "\n",
      "Test set: Average loss: 0.0497, Accuracy: 405/412 (98%)\n",
      "\n",
      "Train Epoch: 953 [0/1649 (0%)]\tLoss: 0.019155\n",
      "\n",
      "Test set: Average loss: 0.0514, Accuracy: 406/412 (99%)\n",
      "\n",
      "Train Epoch: 954 [0/1649 (0%)]\tLoss: 0.003835\n",
      "\n",
      "Test set: Average loss: 0.0555, Accuracy: 405/412 (98%)\n",
      "\n",
      "Train Epoch: 955 [0/1649 (0%)]\tLoss: 0.012096\n",
      "\n",
      "Test set: Average loss: 0.0600, Accuracy: 402/412 (98%)\n",
      "\n",
      "Train Epoch: 956 [0/1649 (0%)]\tLoss: 0.009954\n",
      "\n",
      "Test set: Average loss: 0.0638, Accuracy: 401/412 (97%)\n",
      "\n",
      "Train Epoch: 957 [0/1649 (0%)]\tLoss: 0.315601\n",
      "\n",
      "Test set: Average loss: 0.0684, Accuracy: 401/412 (97%)\n",
      "\n",
      "Train Epoch: 958 [0/1649 (0%)]\tLoss: 0.003042\n",
      "\n",
      "Test set: Average loss: 0.0730, Accuracy: 399/412 (97%)\n",
      "\n",
      "Train Epoch: 959 [0/1649 (0%)]\tLoss: 0.146490\n",
      "\n",
      "Test set: Average loss: 0.0631, Accuracy: 401/412 (97%)\n",
      "\n",
      "Train Epoch: 960 [0/1649 (0%)]\tLoss: 0.037760\n",
      "\n",
      "Test set: Average loss: 0.0543, Accuracy: 402/412 (98%)\n",
      "\n",
      "Train Epoch: 961 [0/1649 (0%)]\tLoss: 0.065807\n",
      "\n",
      "Test set: Average loss: 0.0353, Accuracy: 407/412 (99%)\n",
      "\n",
      "Train Epoch: 962 [0/1649 (0%)]\tLoss: 0.007250\n",
      "\n",
      "Test set: Average loss: 0.0304, Accuracy: 407/412 (99%)\n",
      "\n",
      "Train Epoch: 963 [0/1649 (0%)]\tLoss: 0.142975\n",
      "\n",
      "Test set: Average loss: 0.0282, Accuracy: 408/412 (99%)\n",
      "\n",
      "Train Epoch: 964 [0/1649 (0%)]\tLoss: 0.004869\n",
      "\n",
      "Test set: Average loss: 0.0292, Accuracy: 409/412 (99%)\n",
      "\n",
      "Train Epoch: 965 [0/1649 (0%)]\tLoss: 0.056849\n",
      "\n",
      "Test set: Average loss: 0.0273, Accuracy: 408/412 (99%)\n",
      "\n",
      "Train Epoch: 966 [0/1649 (0%)]\tLoss: 0.003474\n",
      "\n",
      "Test set: Average loss: 0.0298, Accuracy: 408/412 (99%)\n",
      "\n",
      "Train Epoch: 967 [0/1649 (0%)]\tLoss: 0.005013\n",
      "\n",
      "Test set: Average loss: 0.0339, Accuracy: 408/412 (99%)\n",
      "\n",
      "Train Epoch: 968 [0/1649 (0%)]\tLoss: 0.020461\n",
      "\n",
      "Test set: Average loss: 0.0387, Accuracy: 408/412 (99%)\n",
      "\n",
      "Train Epoch: 969 [0/1649 (0%)]\tLoss: 0.031101\n",
      "\n",
      "Test set: Average loss: 0.0458, Accuracy: 404/412 (98%)\n",
      "\n",
      "Train Epoch: 970 [0/1649 (0%)]\tLoss: 0.013117\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.0546, Accuracy: 403/412 (98%)\n",
      "\n",
      "Train Epoch: 971 [0/1649 (0%)]\tLoss: 0.016202\n",
      "\n",
      "Test set: Average loss: 0.0626, Accuracy: 402/412 (98%)\n",
      "\n",
      "Train Epoch: 972 [0/1649 (0%)]\tLoss: 0.015361\n",
      "\n",
      "Test set: Average loss: 0.0714, Accuracy: 402/412 (98%)\n",
      "\n",
      "Train Epoch: 973 [0/1649 (0%)]\tLoss: 0.005087\n",
      "\n",
      "Test set: Average loss: 0.0806, Accuracy: 400/412 (97%)\n",
      "\n",
      "Train Epoch: 974 [0/1649 (0%)]\tLoss: 0.006869\n",
      "\n",
      "Test set: Average loss: 0.0888, Accuracy: 399/412 (97%)\n",
      "\n",
      "Train Epoch: 975 [0/1649 (0%)]\tLoss: 0.013616\n",
      "\n",
      "Test set: Average loss: 0.0980, Accuracy: 399/412 (97%)\n",
      "\n",
      "Train Epoch: 976 [0/1649 (0%)]\tLoss: 0.131586\n",
      "\n",
      "Test set: Average loss: 0.0721, Accuracy: 402/412 (98%)\n",
      "\n",
      "Train Epoch: 977 [0/1649 (0%)]\tLoss: 0.003794\n",
      "\n",
      "Test set: Average loss: 0.0592, Accuracy: 403/412 (98%)\n",
      "\n",
      "Train Epoch: 978 [0/1649 (0%)]\tLoss: 0.021480\n",
      "\n",
      "Test set: Average loss: 0.0515, Accuracy: 404/412 (98%)\n",
      "\n",
      "Train Epoch: 979 [0/1649 (0%)]\tLoss: 0.000632\n",
      "\n",
      "Test set: Average loss: 0.0474, Accuracy: 404/412 (98%)\n",
      "\n",
      "Train Epoch: 980 [0/1649 (0%)]\tLoss: 0.009647\n",
      "\n",
      "Test set: Average loss: 0.0442, Accuracy: 405/412 (98%)\n",
      "\n",
      "Train Epoch: 981 [0/1649 (0%)]\tLoss: 0.012918\n",
      "\n",
      "Test set: Average loss: 0.0418, Accuracy: 406/412 (99%)\n",
      "\n",
      "Train Epoch: 982 [0/1649 (0%)]\tLoss: 0.022285\n",
      "\n",
      "Test set: Average loss: 0.0388, Accuracy: 408/412 (99%)\n",
      "\n",
      "Train Epoch: 983 [0/1649 (0%)]\tLoss: 0.002063\n",
      "\n",
      "Test set: Average loss: 0.0369, Accuracy: 408/412 (99%)\n",
      "\n",
      "Train Epoch: 984 [0/1649 (0%)]\tLoss: 0.019080\n",
      "\n",
      "Test set: Average loss: 0.0335, Accuracy: 408/412 (99%)\n",
      "\n",
      "Train Epoch: 985 [0/1649 (0%)]\tLoss: 0.001551\n",
      "\n",
      "Test set: Average loss: 0.0321, Accuracy: 406/412 (99%)\n",
      "\n",
      "Train Epoch: 986 [0/1649 (0%)]\tLoss: 0.006054\n",
      "\n",
      "Test set: Average loss: 0.0306, Accuracy: 406/412 (99%)\n",
      "\n",
      "Train Epoch: 987 [0/1649 (0%)]\tLoss: 0.001603\n",
      "\n",
      "Test set: Average loss: 0.0315, Accuracy: 407/412 (99%)\n",
      "\n",
      "Train Epoch: 988 [0/1649 (0%)]\tLoss: 0.003465\n",
      "\n",
      "Test set: Average loss: 0.0335, Accuracy: 407/412 (99%)\n",
      "\n",
      "Train Epoch: 989 [0/1649 (0%)]\tLoss: 0.002020\n",
      "\n",
      "Test set: Average loss: 0.0357, Accuracy: 406/412 (99%)\n",
      "\n",
      "Train Epoch: 990 [0/1649 (0%)]\tLoss: 0.019007\n",
      "\n",
      "Test set: Average loss: 0.0313, Accuracy: 407/412 (99%)\n",
      "\n",
      "Train Epoch: 991 [0/1649 (0%)]\tLoss: 0.000916\n",
      "\n",
      "Test set: Average loss: 0.0292, Accuracy: 408/412 (99%)\n",
      "\n",
      "Train Epoch: 992 [0/1649 (0%)]\tLoss: 0.001120\n",
      "\n",
      "Test set: Average loss: 0.0275, Accuracy: 408/412 (99%)\n",
      "\n",
      "Train Epoch: 993 [0/1649 (0%)]\tLoss: 0.001710\n",
      "\n",
      "Test set: Average loss: 0.0259, Accuracy: 408/412 (99%)\n",
      "\n",
      "Train Epoch: 994 [0/1649 (0%)]\tLoss: 0.002499\n",
      "\n",
      "Test set: Average loss: 0.0248, Accuracy: 408/412 (99%)\n",
      "\n",
      "Train Epoch: 995 [0/1649 (0%)]\tLoss: 0.006350\n",
      "\n",
      "Test set: Average loss: 0.0225, Accuracy: 408/412 (99%)\n",
      "\n",
      "Train Epoch: 996 [0/1649 (0%)]\tLoss: 0.004184\n",
      "\n",
      "Test set: Average loss: 0.0215, Accuracy: 408/412 (99%)\n",
      "\n",
      "Train Epoch: 997 [0/1649 (0%)]\tLoss: 0.005593\n",
      "\n",
      "Test set: Average loss: 0.0207, Accuracy: 408/412 (99%)\n",
      "\n",
      "Train Epoch: 998 [0/1649 (0%)]\tLoss: 0.025518\n",
      "\n",
      "Test set: Average loss: 0.0203, Accuracy: 408/412 (99%)\n",
      "\n",
      "Train Epoch: 999 [0/1649 (0%)]\tLoss: 0.027461\n",
      "\n",
      "Test set: Average loss: 0.0187, Accuracy: 409/412 (99%)\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "epoch_arr = range(1000)\n",
    "train_loss = []\n",
    "test_loss = []\n",
    "max_test = 0\n",
    "\n",
    "#Entrainement\n",
    "for epoch in epoch_arr:\n",
    "    train_loss.append( train(model, dataloader_train, optimizer, epoch, F.nll_loss))\n",
    "    loss,test_prc = test(model, dataloader_test)\n",
    "    if test_prc > max_test:\n",
    "        max_test = test_prc\n",
    "        torch.save(model.state_dict(), './best.pth')\n",
    "    test_loss.append( loss )\n",
    "print(\"max acc : \",max_test)\n",
    "print(\"Used Seed: \", manualSeed)\n",
    "#Affichage des courbes de loss\n",
    "plt.plot(epoch_arr,train_loss,'b')\n",
    "plt.plot(epoch_arr,test_loss,'g')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On peut voir qu'avec cette architecture les résultats sont impressionnant et peuvent atteindre les 99%.\n",
    "\n",
    "## Utilisation du réseau\n",
    "\n",
    "Maintenant que nous avons un réseau foncitonnel il est temps de s'en servir !\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Chargement du dernier meilleur model\n",
    "model.load_state_dict(torch.load(\"./best.pth\"))\n",
    "def test_on(model,path):\n",
    "    model.eval()\n",
    "    #Normalisation de l'image\n",
    "    Trans = transforms.Compose([\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Normalize((0.5,), (0.5,)),\n",
    "            ])\n",
    "    im = Image.open(path).convert('L').resize((32,32))\n",
    "    #im.show()\n",
    "    #Conversion en variable pytorhc\n",
    "    im = torch.autograd.Variable(Trans(im).unsqueeze_(0))\n",
    "    #Evaluation\n",
    "    with torch.no_grad():\n",
    "            im = im.to(device)\n",
    "            output = model(im)\n",
    "            print(\"Output : \",output)\n",
    "            print(\"Output : \",output.argmax(dim=1, keepdim=True))\n",
    "            \n",
    "#Test sur une image\n",
    "#Il suffit de changer le chemin pour essayer sur une image.\n",
    "test_on(model,\"./datas/eval/image_1.jpg\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
